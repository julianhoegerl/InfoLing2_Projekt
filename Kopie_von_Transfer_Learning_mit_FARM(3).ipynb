{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kopie von Transfer Learning mit FARM.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "MQz1S2d5jfST",
        "nL8B9oqTg4f6",
        "lXbVD_NEhqZ-",
        "NoF8lgzEimL6",
        "aiUubEaJiBus",
        "cVnUyU9DhQo5"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0830f26be1aa49a89dfa8453cba50ff2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_32d056f1a4ab4bb6abad062c239422c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_30a9463bc8de4bf88920be1f9a6e2764",
              "IPY_MODEL_209f1f8b5dc440fa9356da4f4927186d",
              "IPY_MODEL_522fe391eec34dafb7890fb9a1e6f73f"
            ]
          }
        },
        "32d056f1a4ab4bb6abad062c239422c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "30a9463bc8de4bf88920be1f9a6e2764": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_524887716b33496dacc4809d49195395",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2bb70c15ee3b415e8b46ac21befd5934"
          }
        },
        "209f1f8b5dc440fa9356da4f4927186d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bea0684e78804375ba41baf84eff778a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d6af0e1d34b4f1f9edf6fc599121e2f"
          }
        },
        "522fe391eec34dafb7890fb9a1e6f73f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d4ce8ef393a4875b44e2c748e06f7d0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:19&lt;00:00, 26.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_61d239e13a144823a73c6b618cc167dc"
          }
        },
        "524887716b33496dacc4809d49195395": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2bb70c15ee3b415e8b46ac21befd5934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bea0684e78804375ba41baf84eff778a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d6af0e1d34b4f1f9edf6fc599121e2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d4ce8ef393a4875b44e2c748e06f7d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "61d239e13a144823a73c6b618cc167dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4950f810cc3443f7aec3864b804ae314": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_359d316353404a69babc3e8ee962121f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4eb05ea7f28346e8bd04015843114a03",
              "IPY_MODEL_8aeeb2a73d0840018f3c67491eec839f",
              "IPY_MODEL_b649d3ccef0f4884bbb7b8dc7568685c"
            ]
          }
        },
        "359d316353404a69babc3e8ee962121f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4eb05ea7f28346e8bd04015843114a03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_444c735b9d044deab97a68f091ea59d4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_45d19caf311b4dcab0f4e7912de1103e"
          }
        },
        "8aeeb2a73d0840018f3c67491eec839f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2117200f5f0543cba63706287df23506",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 481,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 481,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_316de909f6174ae0905b30f11ddb4e37"
          }
        },
        "b649d3ccef0f4884bbb7b8dc7568685c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fadf3411d6f34d078d08d4d94fb8b019",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 481/481 [00:00&lt;00:00, 9.26kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0ec4a0a22667454bab85754ccd047f65"
          }
        },
        "444c735b9d044deab97a68f091ea59d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "45d19caf311b4dcab0f4e7912de1103e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2117200f5f0543cba63706287df23506": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "316de909f6174ae0905b30f11ddb4e37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fadf3411d6f34d078d08d4d94fb8b019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0ec4a0a22667454bab85754ccd047f65": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bbe6e5166e04e55bea73dc0b4d0c8b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bdf3752447a5492ab1b4d7aa69e34b6f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_0e5a3f794484409785ff99bca51c5641",
              "IPY_MODEL_d4f96deb78ab488387b53d4a240a6c0a",
              "IPY_MODEL_5ae9d962b77442c09c2112e73531c258"
            ]
          }
        },
        "bdf3752447a5492ab1b4d7aa69e34b6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0e5a3f794484409785ff99bca51c5641": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4e7285357db74b8fb4666ae680110b37",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_cd2356c2f6074faf9976870a94d8fdbd"
          }
        },
        "d4f96deb78ab488387b53d4a240a6c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1f0f76ac520a43bb9a088176c9619957",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_02702af4050644ce8b77c2a912acf916"
          }
        },
        "5ae9d962b77442c09c2112e73531c258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e0ab53b9dd8c40008314311b0783b8fe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:00&lt;00:00, 2.12MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8a4d18ef8d39483ab3d9859403537607"
          }
        },
        "4e7285357db74b8fb4666ae680110b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "cd2356c2f6074faf9976870a94d8fdbd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f0f76ac520a43bb9a088176c9619957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "02702af4050644ce8b77c2a912acf916": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e0ab53b9dd8c40008314311b0783b8fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8a4d18ef8d39483ab3d9859403537607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ec0b57aeb674e2c8ba3fa98d5308e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_64d72d59559749b991797817556417db",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_179e0d583a9e467599091a311f394563",
              "IPY_MODEL_cb9f3636a659460d8324360fe17da62d",
              "IPY_MODEL_0ad6462262ca444a87d458172d3bd12b"
            ]
          }
        },
        "64d72d59559749b991797817556417db": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "179e0d583a9e467599091a311f394563": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_23ad46a3a7814db7bb1e3dfd1d6f8629",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_261123e8c3b142b8bf2806dc73479cdf"
          }
        },
        "cb9f3636a659460d8324360fe17da62d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_81a7ab9e096642d79ea304c52fb568f6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71878b4d7618434f85a58608f070fdc9"
          }
        },
        "0ad6462262ca444a87d458172d3bd12b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e36e402b2bd4bd89b8a0b2807a11137",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 479kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e909645f869144d0956b42106edcbc60"
          }
        },
        "23ad46a3a7814db7bb1e3dfd1d6f8629": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "261123e8c3b142b8bf2806dc73479cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "81a7ab9e096642d79ea304c52fb568f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71878b4d7618434f85a58608f070fdc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e36e402b2bd4bd89b8a0b2807a11137": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e909645f869144d0956b42106edcbc60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aef42849e58540af83f299cc692cc013": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f582181a9ed24c2a8e334e4c42e14370",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3d87f799341749f6af3762fed0a80388",
              "IPY_MODEL_6902f84f878d4e8b8681c8693d0221cb",
              "IPY_MODEL_a28aeab5d8314d0a8be9f2bdf5112590"
            ]
          }
        },
        "f582181a9ed24c2a8e334e4c42e14370": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3d87f799341749f6af3762fed0a80388": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cdde26d446ca4386bddff5de2bf683a5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d63603143e0648bc9e80837df005422b"
          }
        },
        "6902f84f878d4e8b8681c8693d0221cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8bfeb3acdbd24694bd47d7a42c128634",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 501200538,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 501200538,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_05819d037b48424d94cb0c39a8668e1b"
          }
        },
        "a28aeab5d8314d0a8be9f2bdf5112590": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_08da8df8dad7423bbb78cd6137078993",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 501M/501M [00:16&lt;00:00, 31.3MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a14c5a2fdd674aeca7aac36fd97d62e6"
          }
        },
        "cdde26d446ca4386bddff5de2bf683a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d63603143e0648bc9e80837df005422b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8bfeb3acdbd24694bd47d7a42c128634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "05819d037b48424d94cb0c39a8668e1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "08da8df8dad7423bbb78cd6137078993": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a14c5a2fdd674aeca7aac36fd97d62e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cac347724a8d46d3ab01c099b10797d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1d43b82458924221bdb278b6c8241d4c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e2c155a6ffa94f4fb2d4be86b72230ec",
              "IPY_MODEL_de6dbda986d94875895db63f49ac7781",
              "IPY_MODEL_23740a4966a24caf8a66827a9fe29510"
            ]
          }
        },
        "1d43b82458924221bdb278b6c8241d4c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e2c155a6ffa94f4fb2d4be86b72230ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_91b4ac4f53034f07bdf3f5a69d0c6dbd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a3a855ce8ff46d093fcfdb2ba3325a6"
          }
        },
        "de6dbda986d94875895db63f49ac7781": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_d5a5390d39a347d3980f1a09f80cba19",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 684,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 684,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d7b07cc2c114fcdb69ce24bc1273dc8"
          }
        },
        "23740a4966a24caf8a66827a9fe29510": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a5b8873f60304ef288bad933e46a6e58",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 684/684 [00:00&lt;00:00, 14.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_786516831dd64420b685b3100393c8f7"
          }
        },
        "91b4ac4f53034f07bdf3f5a69d0c6dbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a3a855ce8ff46d093fcfdb2ba3325a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d5a5390d39a347d3980f1a09f80cba19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d7b07cc2c114fcdb69ce24bc1273dc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a5b8873f60304ef288bad933e46a6e58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "786516831dd64420b685b3100393c8f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88bcdd4ef93648719ee6abff7ea75268": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_201301b151394e2aa96f8b692b085955",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b6bbde1da38e42279125ee459b8f969c",
              "IPY_MODEL_480aa1092c064c00ba1a4d5bc1e30f07",
              "IPY_MODEL_b072b0fc5ebc421fbe1437e68506d02f"
            ]
          }
        },
        "201301b151394e2aa96f8b692b085955": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6bbde1da38e42279125ee459b8f969c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cbbc22c9ba764724af6c2647c2918635",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e9ad53b659144594a9aee7d831b47140"
          }
        },
        "480aa1092c064c00ba1a4d5bc1e30f07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_527334f00e1d4b79afc65ddd3b61c3f7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 760289,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 760289,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c52d85b64a024712a9b4f311d351892b"
          }
        },
        "b072b0fc5ebc421fbe1437e68506d02f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a02d24898b0645798a9ff8d684222889",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 760k/760k [00:00&lt;00:00, 680kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c2a1de7722b410fbf205c48333c25b1"
          }
        },
        "cbbc22c9ba764724af6c2647c2918635": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e9ad53b659144594a9aee7d831b47140": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "527334f00e1d4b79afc65ddd3b61c3f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c52d85b64a024712a9b4f311d351892b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a02d24898b0645798a9ff8d684222889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c2a1de7722b410fbf205c48333c25b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4f8f89f624a44138aac17569e5fe592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_78c5935ff6414d23ac8d8823b1db18f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_68a4942929d1443994db197cc206f813",
              "IPY_MODEL_9a713a114f8d4f56ba882ec4e59bcdab",
              "IPY_MODEL_a645f44068404c8caf46c40da1382a52"
            ]
          }
        },
        "78c5935ff6414d23ac8d8823b1db18f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68a4942929d1443994db197cc206f813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78bc8b44153f4845900a50203bf3daaf",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5a72b8368d24445cbab255cc3537b187"
          }
        },
        "9a713a114f8d4f56ba882ec4e59bcdab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_636e649439b840da9d58d89020b58932",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 47376696,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 47376696,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_79b4547356e84ff4a75726886cdec7e8"
          }
        },
        "a645f44068404c8caf46c40da1382a52": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_956e9145036b478fb0f8250551325363",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 47.4M/47.4M [00:02&lt;00:00, 22.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_43e48c5929cb40e482455b59f4fe9d41"
          }
        },
        "78bc8b44153f4845900a50203bf3daaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5a72b8368d24445cbab255cc3537b187": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "636e649439b840da9d58d89020b58932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "79b4547356e84ff4a75726886cdec7e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "956e9145036b478fb0f8250551325363": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "43e48c5929cb40e482455b59f4fe9d41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0f760ebcc9444df80201dc5a29a6cae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f55ae31f277b42ee938c6e561db1dd7a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_460832ea307643ddb43542f199831ce8",
              "IPY_MODEL_411fb158675247338153ab208f5a1e92",
              "IPY_MODEL_b06e1e6ab24d48138781830efec40478"
            ]
          }
        },
        "f55ae31f277b42ee938c6e561db1dd7a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "460832ea307643ddb43542f199831ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4e75c92688942c48e492d77e13e6f67",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_575844d0cf84470c847435720ff06e62"
          }
        },
        "411fb158675247338153ab208f5a1e92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f95b1349a41d44a5bf629f78b9cf0cb0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 442,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 442,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_493734283b314c0dbf016ddd15b25c04"
          }
        },
        "b06e1e6ab24d48138781830efec40478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f94097a322c84cf18a2cb47f97b5c01f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 442/442 [00:00&lt;00:00, 12.1kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4900b2b2906d4a91aff9e9e6ea4b57e5"
          }
        },
        "c4e75c92688942c48e492d77e13e6f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "575844d0cf84470c847435720ff06e62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f95b1349a41d44a5bf629f78b9cf0cb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "493734283b314c0dbf016ddd15b25c04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f94097a322c84cf18a2cb47f97b5c01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4900b2b2906d4a91aff9e9e6ea4b57e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91e916586f77476084dc4fdc6c66bc62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_30176b44a609422fbe42214b602cc983",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_35dd7a3645634f6397ac6505bc64fe89",
              "IPY_MODEL_405215c0ff564a39a5303baedacc9322",
              "IPY_MODEL_6776cbb6f02e4ba180701c66252b2737"
            ]
          }
        },
        "30176b44a609422fbe42214b602cc983": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "35dd7a3645634f6397ac6505bc64fe89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8d099074d3e2491ab1f95c6ce79fc6a2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c73370b8e5b4317b6734dfe678a6574"
          }
        },
        "405215c0ff564a39a5303baedacc9322": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e84866fe3d3645d4aa104d4578c8867c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 267967963,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 267967963,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_124b8f50fc2d422f8c76ad5413277b8b"
          }
        },
        "6776cbb6f02e4ba180701c66252b2737": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_99b737b71e6f4d9a93d932f8a40da266",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 268M/268M [00:09&lt;00:00, 30.0MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6c00e7738c2b4828a9d526892f3e371e"
          }
        },
        "8d099074d3e2491ab1f95c6ce79fc6a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c73370b8e5b4317b6734dfe678a6574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e84866fe3d3645d4aa104d4578c8867c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "124b8f50fc2d422f8c76ad5413277b8b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "99b737b71e6f4d9a93d932f8a40da266": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6c00e7738c2b4828a9d526892f3e371e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54d8411d066440249716876c4b7ba478": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_474864b66b2d4127a26d1029a5e414a5",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5147e3150eb84951ba338f447e7a86cb",
              "IPY_MODEL_5f0c2f516d8e40daa2838efb1f2ee4d4",
              "IPY_MODEL_e740d1d29f9a4ee2af1da224886163f8"
            ]
          }
        },
        "474864b66b2d4127a26d1029a5e414a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5147e3150eb84951ba338f447e7a86cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f723b0257d0a4c24a8c97fcbf6eba6f4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Epoch:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_773eb33aa4d249298921c5184cafd715"
          }
        },
        "5f0c2f516d8e40daa2838efb1f2ee4d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_fe61ff43a2f94ceea8607e044c8c4e49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6be315a181e84f37b30d11ff17dc55b3"
          }
        },
        "e740d1d29f9a4ee2af1da224886163f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f0ba1299e8aa4ff6bffd9a8a9d52bf30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/3 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d1b15f28d2524856a2f299de860e5aa1"
          }
        },
        "f723b0257d0a4c24a8c97fcbf6eba6f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "773eb33aa4d249298921c5184cafd715": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fe61ff43a2f94ceea8607e044c8c4e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6be315a181e84f37b30d11ff17dc55b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0ba1299e8aa4ff6bffd9a8a9d52bf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d1b15f28d2524856a2f299de860e5aa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "db11a4bb6c60498695b2134cb7b5123b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0044dea262cf49c6ac787aa04ea77534",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eb2558efba444fa5af5d3de729342621",
              "IPY_MODEL_e64a0871df34452796f7e6b2d9573a1f",
              "IPY_MODEL_c4aa63ad4b594090aac499014fde3171"
            ]
          }
        },
        "0044dea262cf49c6ac787aa04ea77534": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb2558efba444fa5af5d3de729342621": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4f5f9112204348099026bd9808de275f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Iteration:   0%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ad402ec4ecf74732821481b402ba5227"
          }
        },
        "e64a0871df34452796f7e6b2d9573a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_873041efa4fc4f909c393926a4f0bace",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_86bcd3203fdf456ab8edb2d0a647b057"
          }
        },
        "c4aa63ad4b594090aac499014fde3171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2aebb694daf04a2e8fef6c6842aad212",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_849b1f3c7a3c43688bcde12efadeb036"
          }
        },
        "4f5f9112204348099026bd9808de275f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ad402ec4ecf74732821481b402ba5227": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "873041efa4fc4f909c393926a4f0bace": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "86bcd3203fdf456ab8edb2d0a647b057": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2aebb694daf04a2e8fef6c6842aad212": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "849b1f3c7a3c43688bcde12efadeb036": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTThkpiIXlJP"
      },
      "source": [
        "# Transfer Learning mit FARM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ipd2E0WSPDW"
      },
      "source": [
        "## Ziele\n",
        "\n",
        "\n",
        "*   BERT und Transfer Learning\n",
        "*   Einführung in FARM\n",
        "\n",
        "*   Wie funktioniert das Fine-Tuning eines BERT-Modells?\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7ivyIhQUc92"
      },
      "source": [
        "## BERT und Transfer Learning\n",
        "Transfer Learning ist eine Machine Learning-Methode, bei der ein Modell, das für einen bestimmten Task trainiert wurde, als Ausgangspunkt für ein Modell für einen anderen Task verwendet wird.\n",
        "\n",
        "Die Idee hinter diesem Konzept ist, dass man das Erlernte von einem Problem auf ein anderes überträgt. Wenn man z.B. Java als erste Programmiersprache gelernt hat, fällt es uns leichter, Python oder eine andere Programmiersprache zu erlernen. Denn die grundlegenden Programmierkonzepte aus Java/OOP können leicht auf jede andere Programmiersprache übertragen werden. Man muss also nicht von Null beginnnen, sondern kann auf existierendem Wissen aufbauen. Ähnlich verhält es sich auch mit dem Transfer Learning von Sprachmodellen wie BERT. Existierende BERT-Modelle wurden hauptsächlich auf der Wikipedia trainiert. Möchte man allerdings Textklassifikationen in bestimmten Domänen durchführen, ist die Wikipedia mit ihrem Vokabular nicht repräsentativ genug. Daher nutzt man das Fine-Tuning von vortrainierten BERT-Modellen, um sie an den neuen Task/das neue Problem anzupassen. Durch diesen Schritt erhofft man sich bessere Performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYna70JXkjFk"
      },
      "source": [
        "## FARM \n",
        "(**F**ramework for **A**dapting **R**epresentation **M**odels)\n",
        "![farm_logo](https://github.com/deepset-ai/FARM/raw/master/docs/img/farm_logo_text_right_wide.png?raw=true)\n",
        "... ermöglicht uns, das Transfer Learning mit BERT (und anderen Sprachmodellen) umzusetzen. Damit kann man einfach und schnell Modelle für Tasks wie Text Classification, NER und Question Answering erstellen:\n",
        "![task_table](https://miro.medium.com/max/3840/1*0RYwLSOMegTKfhnyTwkjIQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPltDefXjSiJ"
      },
      "source": [
        "# Fine-Tuning eines BERT-Modells mit FARM (adapted from FARM-Tutorial 1)\n",
        "\n",
        "Welcome to the FARM building blocks tutorial! There are many different ways to make use of this repository, but in this notebook, we will be going through the most import building blocks that will help you harvest the rewards of a successfully trained NLP model.\n",
        "\n",
        "Happy FARMing!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2cj67ZBjYSC"
      },
      "source": [
        "## 1) Text Classification\n",
        "\n",
        "GermEval 2018 (GermEval2018) (https://projects.fzai.h-da.de/iggsa/) is an open data set containing texts that need to be classified by whether they are offensive or not. There are a set of coarse and fine labels, but here we will only be looking at the coarse set which labels each example as either OFFENSE or OTHER. To tackle this task, we are going to build a classifier that is composed of Google's BERT language model and a feed forward neural network prediction head."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MQz1S2d5jfST"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeIWk6_4jiQ2",
        "outputId": "bf067b38-666e-4a20-a37a-5812440a160a"
      },
      "source": [
        "# Install FARM\n",
        "!pip install torch==1.6.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install farm==0.5.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.6.0+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.6.0%2Bcu101-cp37-cp37m-linux_x86_64.whl (708.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 708.0 MB 11 kB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (1.19.5)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cu101) (0.16.0)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu102 requires torch==1.9.0, but you have torch 1.6.0+cu101 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.6.0+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.6.0+cu101\n",
            "Collecting farm==0.5.0\n",
            "  Downloading farm-0.5.0-py3-none-any.whl (207 kB)\n",
            "\u001b[K     |████████████████████████████████| 207 kB 5.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.4.1)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.3.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (2.23.0)\n",
            "Collecting dotmap==1.3.0\n",
            "  Downloading dotmap-1.3.0-py3-none-any.whl (8.9 kB)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.0)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (0.37.0)\n",
            "Collecting flask-cors\n",
            "  Downloading Flask_Cors-3.0.10-py2.py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (5.4.8)\n",
            "Collecting boto3\n",
            "  Downloading boto3-1.18.43-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 45.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (57.4.0)\n",
            "Collecting mlflow==1.0.0\n",
            "  Downloading mlflow-1.0.0-py3-none-any.whl (47.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 47.7 MB 37 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (4.62.0)\n",
            "Collecting transformers==3.3.1\n",
            "  Downloading transformers-3.3.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 38.2 MB/s \n",
            "\u001b[?25hCollecting flask-restplus\n",
            "  Downloading flask_restplus-0.13.0-py2.py3-none-any.whl (2.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.5 MB 49.9 MB/s \n",
            "\u001b[?25hCollecting Werkzeug==0.16.1\n",
            "  Downloading Werkzeug-0.16.1-py2.py3-none-any.whl (327 kB)\n",
            "\u001b[K     |████████████████████████████████| 327 kB 50.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch<1.7,>1.5 in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.6.0+cu101)\n",
            "Collecting seqeval==0.0.12\n",
            "  Downloading seqeval-0.0.12.tar.gz (21 kB)\n",
            "Requirement already satisfied: flask in /usr/local/lib/python3.7/dist-packages (from farm==0.5.0) (1.1.4)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (7.1.2)\n",
            "Collecting simplejson\n",
            "  Downloading simplejson-3.17.5-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (129 kB)\n",
            "\u001b[K     |████████████████████████████████| 129 kB 46.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (0.3)\n",
            "Collecting gitpython>=2.1.0\n",
            "  Downloading GitPython-3.1.18-py3-none-any.whl (170 kB)\n",
            "\u001b[K     |████████████████████████████████| 170 kB 46.6 MB/s \n",
            "\u001b[?25hCollecting docker>=3.6.0\n",
            "  Downloading docker-5.0.2-py2.py3-none-any.whl (145 kB)\n",
            "\u001b[K     |████████████████████████████████| 145 kB 49.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.1.5)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (3.17.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (3.13)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (2.8.2)\n",
            "Collecting querystring-parser\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.19.5)\n",
            "Requirement already satisfied: sqlparse in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (0.4.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.4.22)\n",
            "Collecting databricks-cli>=0.8.0\n",
            "  Downloading databricks-cli-0.15.0.tar.gz (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 3.5 MB/s \n",
            "\u001b[?25hCollecting alembic\n",
            "  Downloading alembic-1.7.1-py3-none-any.whl (208 kB)\n",
            "\u001b[K     |████████████████████████████████| 208 kB 45.1 MB/s \n",
            "\u001b[?25hCollecting gunicorn\n",
            "  Downloading gunicorn-20.1.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.7/dist-packages (from mlflow==1.0.0->farm==0.5.0) (1.3.0)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.7/dist-packages (from seqeval==0.0.12->farm==0.5.0) (2.6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (3.0.12)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 39.3 MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 48.5 MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.8.1.rc2\n",
            "  Downloading tokenizers-0.8.1rc2-cp37-cp37m-manylinux1_x86_64.whl (3.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0 MB 36.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.3.1->farm==0.5.0) (21.0)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.7/dist-packages (from databricks-cli>=0.8.0->mlflow==1.0.0->farm==0.5.0) (0.8.9)\n",
            "Collecting websocket-client>=0.32.0\n",
            "  Downloading websocket_client-1.2.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=3.7.4.0 in /usr/local/lib/python3.7/dist-packages (from gitpython>=2.1.0->mlflow==1.0.0->farm==0.5.0) (3.7.4.3)\n",
            "Collecting gitdb<5,>=4.0.1\n",
            "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\n",
            "\u001b[K     |████████████████████████████████| 63 kB 1.7 MB/s \n",
            "\u001b[?25hCollecting smmap<5,>=3.0.1\n",
            "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->farm==0.5.0) (3.0.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch<1.7,>1.5->farm==0.5.0) (0.16.0)\n",
            "Collecting Mako\n",
            "  Downloading Mako-1.1.5-py2.py3-none-any.whl (75 kB)\n",
            "\u001b[K     |████████████████████████████████| 75 kB 3.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow==1.0.0->farm==0.5.0) (4.6.4)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from alembic->mlflow==1.0.0->farm==0.5.0) (5.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.7/dist-packages (from sqlalchemy->mlflow==1.0.0->farm==0.5.0) (1.1.1)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.0 MB/s \n",
            "\u001b[?25hCollecting botocore<1.22.0,>=1.21.43\n",
            "  Downloading botocore-1.21.43-py3-none-any.whl (7.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.9 MB 28.1 MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask->farm==0.5.0) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask->farm==0.5.0) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask->farm==0.5.0) (2.0.1)\n",
            "Collecting aniso8601>=0.82\n",
            "  Downloading aniso8601-9.0.1-py2.py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.5.0) (2018.9)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from flask-restplus->farm==0.5.0) (2.6.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->alembic->mlflow==1.0.0->farm==0.5.0) (3.5.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.3.1->farm==0.5.0) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3.3.1->farm==0.5.0) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->farm==0.5.0) (0.22.2.post1)\n",
            "Building wheels for collected packages: seqeval, databricks-cli\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-py3-none-any.whl size=7434 sha256=f39a33ae94846890d550cc574716fdb4a713fadc1d3814c806f1f4bf8e945aff\n",
            "  Stored in directory: /root/.cache/pip/wheels/dc/cc/62/a3b81f92d35a80e39eb9b2a9d8b31abac54c02b21b2d466edc\n",
            "  Building wheel for databricks-cli (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for databricks-cli: filename=databricks_cli-0.15.0-py3-none-any.whl size=105260 sha256=db549382f2c25b2692d084bea60f25f3c2bea9939ed04e7f9722cd4813794abc\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/ba/75/284f9a90ff7a010bb23b9798f2e9a19dd9fe619379c917bff4\n",
            "Successfully built seqeval databricks-cli\n",
            "Installing collected packages: urllib3, smmap, jmespath, Werkzeug, websocket-client, Mako, gitdb, botocore, tokenizers, simplejson, sentencepiece, sacremoses, s3transfer, querystring-parser, gunicorn, gitpython, docker, databricks-cli, aniso8601, alembic, transformers, seqeval, mlflow, flask-restplus, flask-cors, dotmap, boto3, farm\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 1.0.1\n",
            "    Uninstalling Werkzeug-1.0.1:\n",
            "      Successfully uninstalled Werkzeug-1.0.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed Mako-1.1.5 Werkzeug-0.16.1 alembic-1.7.1 aniso8601-9.0.1 boto3-1.18.43 botocore-1.21.43 databricks-cli-0.15.0 docker-5.0.2 dotmap-1.3.0 farm-0.5.0 flask-cors-3.0.10 flask-restplus-0.13.0 gitdb-4.0.7 gitpython-3.1.18 gunicorn-20.1.0 jmespath-0.10.0 mlflow-1.0.0 querystring-parser-1.2.4 s3transfer-0.5.0 sacremoses-0.0.45 sentencepiece-0.1.96 seqeval-0.0.12 simplejson-3.17.5 smmap-4.0.0 tokenizers-0.8.1rc2 transformers-3.3.1 urllib3-1.25.11 websocket-client-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6RKA1bxkKij",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec460999-7e77-45d3-e4ab-884c29e96713"
      },
      "source": [
        "# Here are the imports we need\n",
        "\n",
        "import torch\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger\n",
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/17/2021 09:49:24 - INFO - farm.modeling.prediction_head -   Better speed can be achieved with apex installed from https://www.github.com/nvidia/apex .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XL-on42YOWwC",
        "outputId": "c9172b50-1571-4bc3-94e5-c8a683643e52"
      },
      "source": [
        "# Farm allows simple logging of many parameters & metrics. Let's use the MLflow framework to track our experiment ...\n",
        "# You will see your results on https://public-mlflow.deepset.ai/\n",
        "ml_logger = MLFlowLogger(tracking_uri=\"https://public-mlflow.deepset.ai/\")\n",
        "ml_logger.init_experiment(experiment_name=\"Public_FARM\", run_name=\"Tutorial1_Colab\")\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " __          __  _                            _        \n",
            " \\ \\        / / | |                          | |       \n",
            "  \\ \\  /\\  / /__| | ___ ___  _ __ ___   ___  | |_ ___  \n",
            "   \\ \\/  \\/ / _ \\ |/ __/ _ \\| '_ ` _ \\ / _ \\ | __/ _ \\ \n",
            "    \\  /\\  /  __/ | (_| (_) | | | | | |  __/ | || (_) |\n",
            "     \\/  \\/ \\___|_|\\___\\___/|_| |_| |_|\\___|  \\__\\___/ \n",
            "  ______      _____  __  __  \n",
            " |  ____/\\   |  __ \\|  \\/  |              _.-^-._    .--.\n",
            " | |__ /  \\  | |__) | \\  / |           .-'   _   '-. |__|\n",
            " |  __/ /\\ \\ |  _  /| |\\/| |          /     |_|     \\|  |\n",
            " | | / ____ \\| | \\ \\| |  | |         /               \\  |\n",
            " |_|/_/    \\_\\_|  \\_\\_|  |_|        /|     _____     |\\ |\n",
            "                                     |    |==|==|    |  |\n",
            "|---||---|---|---|---|---|---|---|---|    |--|--|    |  |\n",
            "|---||---|---|---|---|---|---|---|---|    |==|==|    |  |\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6uTw7w3kPcJ",
        "outputId": "63966dce-1c3c-4fec-8535-a14416e440a5"
      },
      "source": [
        "# We need to fetch the right device to drive the growth of our model\n",
        "# Make sure that you have gpu turned on in this notebook by going to\n",
        "# Runtime>Change runtime type and select GPU as Hardware accelerator.\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Devices available: {}\".format(device))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Devices available: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPogG9KLk-Mv"
      },
      "source": [
        "### Data Handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMQtJfq775KM"
      },
      "source": [
        "In FARM the Processor contains the functions which handle the conversion from file or request to PyTorch Datasets. In essence, it prepares data to be consumed by the modelling components. This is done in stages to allow for easier debugging. It should be able to handle file input or requests. This class contains everything that needs to be customized when adapting a new dataset. Custom datasets can be handled by extending the Processor (e.g. see CONLLProcessor).\n",
        "\n",
        "The DataSilo is a generic class that stores the train, dev and test data sets. It calls upon the methods from the Processor to do the loading and then exposes a DataLoader for each set. In cases where there is not a separate dev file, it will create one by slicing the train set.\n",
        "![data_handling](https://farm.deepset.ai/_images/data_silo_no_bg.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bu6FaHBbm1Kp"
      },
      "source": [
        "## distilbert-base-uncased-finetuned-sst-2-english"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-2k0Zock2J5",
        "outputId": "1935d44b-3be7-4a72-c16f-80acdb216881"
      },
      "source": [
        "# Here we initialize a tokenizer that will be used for preprocessing text\n",
        "# This is the BERT Tokenizer which uses the byte pair encoding method.\n",
        "# It is currently loaded with a German model\n",
        "\n",
        "tokenizer = Tokenizer.load(\n",
        "    pretrained_model_name_or_path=\"distilbert-base-uncased-finetuned-sst-2-english\",\n",
        "    do_lower_case=False)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:09:10 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'DistilBertTokenizer'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08ycfnEIlJa4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79b0d336-83d8-4090-e190-c821bac4a4bb"
      },
      "source": [
        "# In order to prepare the data for the model, we need a set of\n",
        "# functions to transform data files into PyTorch Datasets.\n",
        "# We group these together in Processor objects.\n",
        "# We will need a new Processor object for each new source of data.\n",
        "# The abstract class can be found in farm.data_handling.processor.Processor\n",
        "# TOXIC = 1\n",
        "# OTHER = 0\n",
        "LABEL_LIST = [\"0\", \"1\"]\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=128,\n",
        "                                        warmup = 600,\n",
        "                                        train_filename=\"train.tsv\",\n",
        "                                        dev_filename=\"test_with_solutions.tsv\",\n",
        "                                        test_filename=\"impermium_verification_labels.tsv\",\n",
        "                                        data_dir=\"../content\",\n",
        "                                        label_list=LABEL_LIST,\n",
        "                                        metric=\"f1_macro\",\n",
        "                                        text_column_name=\"Comment\",\n",
        "                                        label_column_name=\"Insult\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:09:12 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='tokenizer' was already logged with value='BertTokenizer' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value 'DistilBertTokenizer'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zds83m5klLW8",
        "outputId": "78bcb0fd-312a-4cee-ad99-372d15355cf7"
      },
      "source": [
        "# We need a DataSilo in order to keep our train, dev and test sets separate.\n",
        "# The DataSilo will call the functions in the Processor to generate these sets.\n",
        "# From the DataSilo, we can fetch a PyTorch DataLoader object which will\n",
        "# be passed on to the model.\n",
        "# Here is a good place to define a batch size for the model\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:09:12 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "09/16/2021 10:09:12 - INFO - farm.data_handler.data_silo -   Loading train set from: ../content/train.tsv \n",
            "09/16/2021 10:09:12 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 3947 dictionaries to pytorch datasets (chunksize = 790)...\n",
            "09/16/2021 10:09:12 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:09:12 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:09:12 - INFO - farm.data_handler.data_silo -   / \\\n",
            "09/16/2021 10:09:12 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/train.tsv:   0%|          | 0/3947 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:09:14 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:09:14 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 216-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"How the fuck do you have Orange Beef but not Orange chicken?\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', '[UNK]', 'the', 'fuck', 'do', 'you', 'have', '[UNK]', '[UNK]', 'but', 'not', '[UNK]', 'chicken', '?', '\"']\n",
            " \toffsets: [0, 1, 5, 9, 14, 17, 21, 26, 33, 38, 42, 46, 53, 60, 61]\n",
            " \tstart_of_word: [True, False, True, True, True, True, True, True, True, True, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 100, 1996, 6616, 2079, 2017, 2031, 100, 100, 2021, 2025, 100, 7975, 1029, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:09:14 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 227-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"The Korem foundation will never see another dollar from me.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', '[UNK]', '[UNK]', 'foundation', 'will', 'never', 'see', 'another', 'dollar', 'from', 'me', '.', '\"']\n",
            " \toffsets: [0, 1, 5, 11, 22, 27, 33, 37, 45, 52, 57, 59, 60]\n",
            " \tstart_of_word: [True, False, True, True, True, True, True, True, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 100, 100, 3192, 2097, 2196, 2156, 2178, 7922, 2013, 2033, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/train.tsv: 100%|██████████| 3947/3947 [00:10<00:00, 369.19 Dicts/s]\n",
            "09/16/2021 10:09:23 - INFO - farm.data_handler.data_silo -   Loading dev set from: ../content/test_with_solutions.tsv\n",
            "09/16/2021 10:09:23 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2647 dictionaries to pytorch datasets (chunksize = 530)...\n",
            "09/16/2021 10:09:23 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:09:23 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:09:23 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/16/2021 10:09:23 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv:   0%|          | 0/2647 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:09:26 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:09:26 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 257-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"You are a loser.\\xa0 Always whining about the ownership.\\xa0 It is not society's fault you still live in your momma's basement and you are overweight.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', '[UNK]', 'are', 'a', 'loser', '.', '\\\\', 'x', '##a', '##0', '[UNK]', 'w', '##hini', '##ng', 'about', 'the', 'ownership', '.', '\\\\', 'x', '##a', '##0', '[UNK]', 'is', 'not', 'society', \"'\", 's', 'fault', 'you', 'still', 'live', 'in', 'your', 'momma', \"'\", 's', 'basement', 'and', 'you', 'are', 'over', '##weight', '.', '\"']\n",
            " \toffsets: [0, 1, 5, 9, 11, 16, 17, 18, 19, 20, 22, 29, 30, 34, 37, 43, 47, 56, 57, 58, 59, 60, 62, 65, 68, 72, 79, 80, 82, 88, 92, 98, 103, 106, 111, 116, 117, 119, 128, 132, 136, 140, 144, 150, 151]\n",
            " \tstart_of_word: [True, False, True, True, True, False, False, False, False, False, True, True, False, False, True, True, True, False, False, False, False, False, True, True, True, True, False, False, True, True, True, True, True, True, True, False, False, True, True, True, True, True, False, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 100, 2024, 1037, 10916, 1012, 1032, 1060, 2050, 2692, 100, 1059, 20535, 3070, 2055, 1996, 6095, 1012, 1032, 1060, 2050, 2692, 100, 2003, 2025, 2554, 1005, 1055, 6346, 2017, 2145, 2444, 1999, 2115, 23603, 1005, 1055, 8102, 1998, 2017, 2024, 2058, 11179, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:09:26 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 409-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"I know. I called it a while ago when I had a bug in my ear. Fuck Luongo, I would take Backstrom and his one year left way before him\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', '[UNK]', 'know', '.', '[UNK]', 'called', 'it', 'a', 'while', 'ago', 'when', '[UNK]', 'had', 'a', 'bug', 'in', 'my', 'ear', '.', '[UNK]', '[UNK]', ',', '[UNK]', 'would', 'take', '[UNK]', 'and', 'his', 'one', 'year', 'left', 'way', 'before', 'him', '\"']\n",
            " \toffsets: [0, 1, 3, 7, 9, 11, 18, 21, 23, 29, 33, 38, 40, 44, 46, 50, 53, 56, 59, 61, 66, 67, 74, 76, 82, 87, 97, 101, 105, 109, 114, 119, 123, 130, 133]\n",
            " \tstart_of_word: [True, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 100, 2113, 1012, 100, 2170, 2009, 1037, 2096, 3283, 2043, 100, 2018, 1037, 11829, 1999, 2026, 4540, 1012, 100, 100, 1010, 100, 2052, 2202, 100, 1998, 2010, 2028, 2095, 2187, 2126, 2077, 2032, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv: 100%|██████████| 2647/2647 [00:07<00:00, 334.56 Dicts/s]\n",
            "09/16/2021 10:09:31 - INFO - farm.data_handler.data_silo -   Loading test set from: ../content/impermium_verification_set.tsv\n",
            "09/16/2021 10:09:31 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2235 dictionaries to pytorch datasets (chunksize = 447)...\n",
            "09/16/2021 10:09:31 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:09:31 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:09:31 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/16/2021 10:09:31 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/impermium_verification_set.tsv:   0%|          | 0/2235 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:09:32 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:09:32 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 61-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"What kind of porn do you watch? \\xa0This isn't porn. \\xa0\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', '[UNK]', 'kind', 'of', 'porn', 'do', 'you', 'watch', '?', '\\\\', '[UNK]', 'isn', \"'\", 't', 'porn', '.', '\\\\', 'x', '##a', '##0', '\"']\n",
            " \toffsets: [0, 1, 6, 11, 14, 19, 22, 26, 31, 33, 34, 42, 45, 46, 48, 52, 54, 55, 56, 57, 58]\n",
            " \tstart_of_word: [True, False, True, True, True, True, True, True, False, True, False, True, False, False, True, False, True, False, False, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 100, 2785, 1997, 22555, 2079, 2017, 3422, 1029, 1032, 100, 3475, 1005, 1056, 22555, 1012, 1032, 1060, 2050, 2692, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:09:32 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 224-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"FUCK ROSS FUCK SAIGON AND FUCK U BITCH ASS NIGGA WHO THE FUCK CARES ABOUT MUSIC............ITS ART IMITATING LIFE\\xa0\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '[UNK]', '[UNK]', '[UNK]', '[UNK]', '\\\\', 'x', '##a', '##0', '\"']\n",
            " \toffsets: [0, 1, 6, 11, 16, 23, 27, 32, 34, 40, 44, 50, 54, 58, 63, 69, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 96, 100, 110, 111, 112, 113, 114, 115]\n",
            " \tstart_of_word: [True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, False, False, False, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 100, 1012, 1012, 1012, 1012, 1012, 1012, 1012, 1012, 1012, 1012, 1012, 1012, 100, 100, 100, 100, 1032, 1060, 2050, 2692, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/impermium_verification_set.tsv: 100%|██████████| 2235/2235 [00:03<00:00, 620.32 Dicts/s]\n",
            "09/16/2021 10:09:35 - INFO - farm.data_handler.data_silo -   Examples in train: 3947\n",
            "09/16/2021 10:09:35 - INFO - farm.data_handler.data_silo -   Examples in dev  : 2647\n",
            "09/16/2021 10:09:35 - INFO - farm.data_handler.data_silo -   Examples in test : 2235\n",
            "09/16/2021 10:09:35 - INFO - farm.data_handler.data_silo -   \n",
            "09/16/2021 10:09:35 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
            "09/16/2021 10:09:35 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 43.271598682543704\n",
            "09/16/2021 10:09:35 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.07246009627565239\n",
            "09/16/2021 10:09:35 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='ave_seq_len' was already logged with value='44.46693691411198' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '43.271598682543704'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YG8toIFclN2F"
      },
      "source": [
        "### Modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cw4CJvz5lRbj"
      },
      "source": [
        "![modeling](https://farm.deepset.ai/_images/adaptive_model_no_bg.jpg)\n",
        "In FARM, we make a strong distinction between the language model and prediction head so that you can mix and match different building blocks for your needs.\n",
        "\n",
        "For example, in the transfer learning paradigm, you might have the one language model that you will be using for both document classification and NER. Or perhaps you have a pretrained language model which you would like to adapt to your domain, then use it for a downstream task such as question answering. \n",
        "\n",
        "All this is possible within FARM and requires only the replacement of a few modular components, as we shall see below.\n",
        "\n",
        "Let's first have a look at how we might set up a model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4TaqNaTlVmm",
        "outputId": "378f1c91-e985-4e27-9770-3c71dcda9bfb"
      },
      "source": [
        "# The language model is the foundation on which modern NLP systems are built.\n",
        "# They encapsulate a general understanding of sentence semantics\n",
        "# and are not specific to any one task.\n",
        "\n",
        "# Here we are using Google's BERT model as implemented by HuggingFace. \n",
        "# The model being loaded is a German model that we trained. \n",
        "# You can also change the MODEL_NAME_OR_PATH to point to a BERT model that you\n",
        "# have saved or download one connected to the HuggingFace repository.\n",
        "# See farm.modeling.language_model.PRETRAINED_MODEL_ARCHIVE_MAP for a list of\n",
        "# available models\n",
        "\n",
        "MODEL_NAME_OR_PATH = \"distilbert-base-uncased-finetuned-sst-2-english\"\n",
        "# MODEL_NAME_OR_PATH = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "language_model = LanguageModel.load(MODEL_NAME_OR_PATH)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:09:38 - INFO - farm.modeling.language_model -   Automatically detected language from language model name: english\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKpqm6solWce",
        "outputId": "856f3b56-d24f-49d0-d53c-00de86ca673e"
      },
      "source": [
        "# A prediction head is a model that processes the output of the language model\n",
        "# for a specific task.\n",
        "# Prediction heads will look different depending on whether you're doing text classification\n",
        "# Named Entity Recognition (NER), question answering or some other task.\n",
        "# They should generate logits over the available prediction classes and contain methods\n",
        "# to convert these logits to losses or predictions \n",
        "\n",
        "# Here we use TextClassificationHead which receives a single fixed length sentence vector\n",
        "# and processes it using a feed forward neural network. layer_dims is a list of dimensions:\n",
        "# [input_dims, hidden_1_dims, hidden_2_dims ..., output_dims]\n",
        "\n",
        "# Here by default we have a single layer network.\n",
        "# It takes in a vector of length 768 (the default size of BERT's output).\n",
        "# It outputs a vector of length 2 (the number of classes in the GermEval18 (coarse) dataset)\n",
        "\n",
        "prediction_head = TextClassificationHead(num_labels=len(LABEL_LIST), class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:09:38 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/16/2021 10:09:38 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6810969 1.8804762]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQL1HGo2lZEo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5362dea5-e24d-43a4-8064-21ef7860de51"
      },
      "source": [
        "# The language model and prediction head are coupled together in the Adaptive Model.\n",
        "# This class takes care of model saving and loading and also coordinates\n",
        "# cases where there is more than one prediction head.\n",
        "\n",
        "# EMBEDS_DROPOUT_PROB is the probability that an element of the output vector from the\n",
        "# language model will be set to zero.\n",
        "# EMBEDS_DROPOUT_PROB = 0.1 distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "# EMBEDS_DROPOUT_PROB = 0.01\n",
        "# EMBEDS_DROPOUT_PROB = 0.2 distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:09:38 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='lm_type' was already logged with value='Bert' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value 'DistilBert'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UE861jLalax1"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4db05tC7lcKy",
        "outputId": "af7be9af-1a88-4981-bbc9-e8599b113a97"
      },
      "source": [
        "# Here we initialize a Bert Adam optimizer that has a linear warmup and warmdown\n",
        "# Here you can set learning rate, the warmup proportion and number of epochs to train for\n",
        "\n",
        "#LEARNING_RATE = 2e-5 # distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "#LEARNING_RATE = 1e-7\n",
        "LEARNING_RATE = 1e-5  # distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "\n",
        "N_EPOCHS = 3\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:09:38 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
            "09/16/2021 10:09:38 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/16/2021 10:09:38 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 37.2, 'num_training_steps': 372}'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rpkluUz3lfJn"
      },
      "source": [
        "# Training loop handled by this\n",
        "# It will also trigger evaluation during training using the dev data\n",
        "# and after training using the test data.\n",
        "\n",
        "# Set N_GPU to a positive value if CUDA is available\n",
        "N_GPU = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device, \n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KWLMesyre1FB",
        "outputId": "4c256e55-db04-447d-b9b0-8de93aa4b3a1"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 16 10:09:39 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   52C    P0    60W / 149W |   5737MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuSTk5zAlc0A",
        "outputId": "591f57de-7909-4420-e9e3-659ee7b4806e"
      },
      "source": [
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:09:39 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/2 (Cur. train loss: 0.8731):  81%|████████  | 100/124 [01:04<00:15,  1.56it/s]\n",
            "Evaluating:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 83/83 [00:18<00:00,  4.45it/s]\n",
            "09/16/2021 10:11:02 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:11:02 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:11:02 - INFO - farm.eval -   loss: 0.41216496120635904\n",
            "09/16/2021 10:11:02 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:11:02 - INFO - farm.eval -   f1_macro: 0.7998908782420109\n",
            "09/16/2021 10:11:02 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9271    0.8398    0.8813      1954\n",
            "           1     0.6431    0.8139    0.7185       693\n",
            "\n",
            "    accuracy                         0.8330      2647\n",
            "   macro avg     0.7851    0.8268    0.7999      2647\n",
            "weighted avg     0.8528    0.8330    0.8387      2647\n",
            "\n",
            "Train epoch 0/2 (Cur. train loss: 0.1658): 100%|██████████| 124/124 [01:37<00:00,  1.27it/s]\n",
            "Train epoch 1/2 (Cur. train loss: 0.2793):  61%|██████▏   | 76/124 [00:48<00:30,  1.58it/s]\n",
            "Evaluating:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 83/83 [00:18<00:00,  4.42it/s]\n",
            "09/16/2021 10:12:25 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:12:25 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:12:25 - INFO - farm.eval -   loss: 0.4232881651944289\n",
            "09/16/2021 10:12:25 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:12:25 - INFO - farm.eval -   f1_macro: 0.8123933363274013\n",
            "09/16/2021 10:12:25 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9221    0.8664    0.8934      1954\n",
            "           1     0.6782    0.7937    0.7314       693\n",
            "\n",
            "    accuracy                         0.8474      2647\n",
            "   macro avg     0.8001    0.8300    0.8124      2647\n",
            "weighted avg     0.8582    0.8474    0.8510      2647\n",
            "\n",
            "Train epoch 1/2 (Cur. train loss: 0.3028): 100%|██████████| 124/124 [01:38<00:00,  1.26it/s]\n",
            "Train epoch 2/2 (Cur. train loss: 0.1919):  42%|████▏     | 52/124 [00:33<00:45,  1.58it/s]\n",
            "Evaluating:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 83/83 [00:18<00:00,  4.45it/s]\n",
            "09/16/2021 10:13:47 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:13:47 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:13:48 - INFO - farm.eval -   loss: 0.5169469592343379\n",
            "09/16/2021 10:13:48 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:13:48 - INFO - farm.eval -   f1_macro: 0.8145525878731181\n",
            "09/16/2021 10:13:48 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9141    0.8828    0.8982      1954\n",
            "           1     0.6987    0.7662    0.7309       693\n",
            "\n",
            "    accuracy                         0.8523      2647\n",
            "   macro avg     0.8064    0.8245    0.8146      2647\n",
            "weighted avg     0.8577    0.8523    0.8544      2647\n",
            "\n",
            "Train epoch 2/2 (Cur. train loss: 0.1356): 100%|██████████| 124/124 [01:37<00:00,  1.27it/s]\n",
            "Evaluating: 100%|██████████| 70/70 [00:15<00:00,  4.46it/s]\n",
            "09/16/2021 10:14:48 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 372 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:14:48 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:14:48 - INFO - farm.eval -   loss: 1.2220806446118109\n",
            "09/16/2021 10:14:48 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:14:49 - INFO - farm.eval -   f1_macro: 0.7382891077978937\n",
            "09/16/2021 10:14:49 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7050    0.8731    0.7801      1158\n",
            "           1     0.8165    0.6072    0.6965      1077\n",
            "\n",
            "    accuracy                         0.7450      2235\n",
            "   macro avg     0.7608    0.7401    0.7383      2235\n",
            "weighted avg     0.7587    0.7450    0.7398      2235\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0r8b3etug_F4",
        "outputId": "5194e84a-ee9c-495b-8ea5-91fa2ec68753"
      },
      "source": [
        "# Test your model on a sample (Inference)\n",
        "from farm.infer import Inferencer\n",
        "from pprint import PrettyPrinter\n",
        "\n",
        "infer_model = Inferencer(processor=processor, model=model, task_type=\"text_classification\", gpu=True)\n",
        "\n",
        "basic_texts = [\n",
        "    {\"text\": \"Martin is an idiot\"},\n",
        "    {\"text\": \"Martin Müller plays Voleyball in Berlin\"},\n",
        "]\n",
        "result = infer_model.inference_from_dicts(dicts=basic_texts)\n",
        "PrettyPrinter().pprint(result)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:14:49 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n",
            "09/16/2021 10:14:49 - INFO - farm.infer -   Got ya 1 parallel workers to do inference ...\n",
            "09/16/2021 10:14:49 - INFO - farm.infer -    0 \n",
            "09/16/2021 10:14:49 - INFO - farm.infer -   /w\\\n",
            "09/16/2021 10:14:49 - INFO - farm.infer -   /'\\\n",
            "09/16/2021 10:14:49 - INFO - farm.infer -   \n",
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:14:49 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:14:49 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 0-0\n",
            "Clear Text: \n",
            " \ttext: Martin is an idiot\n",
            "Tokenized: \n",
            " \ttokens: ['[UNK]', 'is', 'an', 'idiot']\n",
            " \toffsets: [0, 7, 10, 13]\n",
            " \tstart_of_word: [True, True, True, True]\n",
            "Features: \n",
            " \tinput_ids: [101, 100, 2003, 2019, 10041, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:14:49 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 1-0\n",
            "Clear Text: \n",
            " \ttext: Martin Müller plays Voleyball in Berlin\n",
            "Tokenized: \n",
            " \ttokens: ['[UNK]', '[UNK]', 'plays', '[UNK]', 'in', '[UNK]']\n",
            " \toffsets: [0, 7, 14, 20, 30, 33]\n",
            " \tstart_of_word: [True, True, True, True, True, True]\n",
            "Features: \n",
            " \tinput_ids: [101, 100, 100, 3248, 100, 1999, 100, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "_____________________________________________________\n",
            "Inferencing Samples: 100%|██████████| 1/1 [00:00<00:00, 34.96 Batches/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'predictions': [{'context': 'Martin is an idiot',\n",
            "                   'end': None,\n",
            "                   'label': '1',\n",
            "                   'probability': 0.99127847,\n",
            "                   'start': None},\n",
            "                  {'context': 'Martin Müller plays Voleyball in Berlin',\n",
            "                   'end': None,\n",
            "                   'label': '0',\n",
            "                   'probability': 0.9728008,\n",
            "                   'start': None}],\n",
            "  'task': 'text_classification'}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiT5IEsV1BhU"
      },
      "source": [
        "#model.save('../data/detecting-insults-in-social-commentary/model')\n",
        "#processor.save('../data/detecting-insults-in-social-commentary/processor')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RGvyT2i5WX-1"
      },
      "source": [
        "## Aufgabe\n",
        "Verwenden Sie den imdb-Datensatz aus der letzten Sitzung und nutzen Sie ein englisches BERT-Modell (z.B. ```bert-base-uncased```), um es für die Sentiment-Analyse von Film-Reviews finezutunen. Bilden Sie Gruppen und gehen Sie wie folgt vor:\n",
        "\n",
        "1. Verwenden Sie ein Subset des Datensatzes. Grund: Es ist unklar, wie viel die (kostenlose) Google Colab-GPU zu leisten im Stande ist. Verwenden Sie innerhalb der Gruppe unterschiedliche Samplezahlen des Datensatzes und testen Sie aus, wo die Grenzen liegen. \n",
        "2. Adjustieren Sie verschiedene Parameter (Learning Rate, Dropout Rate ...), um Unterschiede in der Performance festzustellen.\n",
        "3. Speichern Sie das fine-getunte BERT-Modell ab: \n",
        "```python\n",
        "model.save('path/to/directory')\n",
        "processor.save('path/to/directory')\n",
        "```\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFXvXYB4WkNw"
      },
      "source": [
        "## BERT <br>\n",
        "https://huggingface.co/bert-base-uncased "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3k-z8wSLWlBx",
        "outputId": "a49f5892-3267-4178-dd2f-91f096962212"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "# Here we initialize a tokenizer that will be used for preprocessing text\n",
        "# This is the BERT Tokenizer which uses the byte pair encoding method.\n",
        "# It is currently loaded with a German model\n",
        "\n",
        "#tokenizer = Tokenizer.load(\n",
        "#    pretrained_model_name_or_path=\"finiteautomata/bertweet-base-sentiment-analysis\",\n",
        "#    do_lower_case=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "\n",
        "# In order to prepare the data for the model, we need a set of\n",
        "# functions to transform data files into PyTorch Datasets.\n",
        "# We group these together in Processor objects.\n",
        "# We will need a new Processor object for each new source of data.\n",
        "# The abstract class can be found in farm.data_handling.processor.Processor\n",
        "# TOXIC = 1\n",
        "# OTHER = 0\n",
        "LABEL_LIST = [\"0\", \"1\"]\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=128,\n",
        "                                        warmup = 600,\n",
        "                                        train_filename=\"train.tsv\",\n",
        "                                        dev_filename=\"test_with_solutions.tsv\",\n",
        "                                        test_filename=\"impermium_verification_labels.tsv\",\n",
        "                                        data_dir=\"../content\",\n",
        "                                        label_list=LABEL_LIST,\n",
        "                                        metric=\"f1_macro\",\n",
        "                                        text_column_name=\"Comment\",\n",
        "                                        label_column_name=\"Insult\")\n",
        "\n",
        "# We need a DataSilo in order to keep our train, dev and test sets separate.\n",
        "# The DataSilo will call the functions in the Processor to generate these sets.\n",
        "# From the DataSilo, we can fetch a PyTorch DataLoader object which will\n",
        "# be passed on to the model.\n",
        "# Here is a good place to define a batch size for the model\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "# The language model is the foundation on which modern NLP systems are built.\n",
        "# They encapsulate a general understanding of sentence semantics\n",
        "# and are not specific to any one task.\n",
        "\n",
        "# Here we are using Google's BERT model as implemented by HuggingFace. \n",
        "# The model being loaded is a German model that we trained. \n",
        "# You can also change the MODEL_NAME_OR_PATH to point to a BERT model that you\n",
        "# have saved or download one connected to the HuggingFace repository.\n",
        "# See farm.modeling.language_model.PRETRAINED_MODEL_ARCHIVE_MAP for a list of\n",
        "# available models\n",
        "\n",
        "MODEL_NAME_OR_PATH = \"bert-base-uncased\"\n",
        "# MODEL_NAME_OR_PATH = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "language_model = LanguageModel.load(MODEL_NAME_OR_PATH)\n",
        "\n",
        "# A prediction head is a model that processes the output of the language model\n",
        "# for a specific task.\n",
        "# Prediction heads will look different depending on whether you're doing text classification\n",
        "# Named Entity Recognition (NER), question answering or some other task.\n",
        "# They should generate logits over the available prediction classes and contain methods\n",
        "# to convert these logits to losses or predictions \n",
        "\n",
        "# Here we use TextClassificationHead which receives a single fixed length sentence vector\n",
        "# and processes it using a feed forward neural network. layer_dims is a list of dimensions:\n",
        "# [input_dims, hidden_1_dims, hidden_2_dims ..., output_dims]\n",
        "\n",
        "# Here by default we have a single layer network.\n",
        "# It takes in a vector of length 768 (the default size of BERT's output).\n",
        "# It outputs a vector of length 2 (the number of classes in the GermEval18 (coarse) dataset)\n",
        "\n",
        "prediction_head = TextClassificationHead(num_labels=len(LABEL_LIST), class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"))\n",
        "\n",
        "# The language model and prediction head are coupled together in the Adaptive Model.\n",
        "# This class takes care of model saving and loading and also coordinates\n",
        "# cases where there is more than one prediction head.\n",
        "\n",
        "# EMBEDS_DROPOUT_PROB is the probability that an element of the output vector from the\n",
        "# language model will be set to zero.\n",
        "# EMBEDS_DROPOUT_PROB = 0.1 distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "# EMBEDS_DROPOUT_PROB = 0.01\n",
        "# EMBEDS_DROPOUT_PROB = 0.2 distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device)\n",
        "\n",
        "# Here we initialize a Bert Adam optimizer that has a linear warmup and warmdown\n",
        "# Here you can set learning rate, the warmup proportion and number of epochs to train for\n",
        "\n",
        "#LEARNING_RATE = 2e-5 # distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "#LEARNING_RATE = 1e-7\n",
        "LEARNING_RATE = 1e-5  # distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "\n",
        "N_EPOCHS = 3\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS)\n",
        "\n",
        "# Training loop handled by this\n",
        "# It will also trigger evaluation during training using the dev data\n",
        "# and after training using the test data.\n",
        "\n",
        "# Set N_GPU to a positive value if CUDA is available\n",
        "N_GPU = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device, \n",
        ")\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:14:50 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "09/16/2021 10:14:50 - INFO - farm.data_handler.data_silo -   Loading train set from: ../content/train.tsv \n",
            "09/16/2021 10:14:50 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 3947 dictionaries to pytorch datasets (chunksize = 790)...\n",
            "09/16/2021 10:14:50 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:14:50 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:14:50 - INFO - farm.data_handler.data_silo -   / \\\n",
            "09/16/2021 10:14:50 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/train.tsv:   0%|          | 0/3947 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:14:53 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:14:53 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 235-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"@SlipResistantShoes\\xa0In a few years, they'll make a damn movie about it?\\n\\xa0\\nUncle Daddy Rides Again?\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', '@', 'slip', '##res', '##istan', '##ts', '##hoe', '##s', '\\\\', 'x', '##a', '##0', '##in', 'a', 'few', 'years', ',', 'they', \"'\", 'll', 'make', 'a', 'damn', 'movie', 'about', 'it', '?', '\\\\', 'n', '\\\\', 'x', '##a', '##0', '\\\\', 'nun', '##cle', 'daddy', 'rides', 'again', '?', '\"']\n",
            " \toffsets: [0, 1, 2, 6, 9, 14, 16, 19, 20, 21, 22, 23, 24, 27, 29, 33, 38, 40, 44, 45, 48, 53, 55, 60, 66, 72, 74, 75, 76, 77, 78, 79, 80, 81, 82, 85, 89, 95, 101, 106, 107]\n",
            " \tstart_of_word: [True, False, False, False, False, False, False, False, False, False, False, False, False, True, True, True, False, True, False, False, True, True, True, True, True, True, False, False, False, False, False, False, False, False, False, False, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 1030, 7540, 6072, 23137, 3215, 14490, 2015, 1032, 1060, 2050, 2692, 2378, 1037, 2261, 2086, 1010, 2027, 1005, 2222, 2191, 1037, 4365, 3185, 2055, 2009, 1029, 1032, 1050, 1032, 1060, 2050, 2692, 1032, 16634, 14321, 8600, 12271, 2153, 1029, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:14:53 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 40-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"You are a liar.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'you', 'are', 'a', 'liar', '.', '\"']\n",
            " \toffsets: [0, 1, 5, 9, 11, 15, 16]\n",
            " \tstart_of_word: [True, False, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 2017, 2024, 1037, 16374, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/train.tsv: 100%|██████████| 3947/3947 [00:13<00:00, 284.03 Dicts/s]\n",
            "09/16/2021 10:15:04 - INFO - farm.data_handler.data_silo -   Loading dev set from: ../content/test_with_solutions.tsv\n",
            "09/16/2021 10:15:04 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2647 dictionaries to pytorch datasets (chunksize = 530)...\n",
            "09/16/2021 10:15:04 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:15:04 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:15:04 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/16/2021 10:15:04 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv:   0%|          | 0/2647 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:15:07 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:15:07 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 384-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"@NCSteve 3.0 @dopper0189\\\\n\\\\n If I could dry hump your post I would\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', '@', 'nc', '##ste', '##ve', '3', '.', '0', '@', 'do', '##pper', '##01', '##8', '##9', '\\\\', '\\\\', 'n', '\\\\', '\\\\', 'n', 'if', 'i', 'could', 'dry', 'hum', '##p', 'your', 'post', 'i', 'would', '\"']\n",
            " \toffsets: [0, 1, 2, 4, 7, 10, 11, 12, 14, 15, 17, 21, 23, 24, 25, 26, 27, 28, 29, 30, 32, 35, 37, 43, 47, 50, 52, 57, 62, 64, 69]\n",
            " \tstart_of_word: [True, False, False, False, False, True, False, False, True, False, False, False, False, False, False, False, False, False, False, False, True, True, True, True, True, False, True, True, True, True, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 1030, 13316, 13473, 3726, 1017, 1012, 1014, 1030, 2079, 18620, 24096, 2620, 2683, 1032, 1032, 1050, 1032, 1032, 1050, 2065, 1045, 2071, 4318, 14910, 2361, 2115, 2695, 1045, 2052, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:15:07 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 175-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"Sadly its not just NJ. The whole visa system is rotten from head to toe, and hopelessly broken. There just arent enough people out there to investigate all the complaints and abuses that are so prevalent in the visa system, and so it has become a place of widespread fraud, abuse, dehumanization and exploitation. Sadder still is that companies dont realize that when they hire visa holders that they are helping to contribute to the problem. NJ just so happens to have stumbled across the tip of the iceberg.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'sadly', 'its', 'not', 'just', 'nj', '.', 'the', 'whole', 'visa', 'system', 'is', 'rotten', 'from', 'head', 'to', 'toe', ',', 'and', 'hopeless', '##ly', 'broken', '.', 'there', 'just', 'aren', '##t', 'enough', 'people', 'out', 'there', 'to', 'investigate', 'all', 'the', 'complaints', 'and', 'abuses', 'that', 'are', 'so', 'prevalent', 'in', 'the', 'visa', 'system', ',', 'and', 'so', 'it', 'has', 'become', 'a', 'place', 'of', 'widespread', 'fraud', ',', 'abuse', ',', 'de', '##hum', '##ani', '##zation', 'and', 'exploitation', '.', 'sad', '##der', 'still', 'is', 'that', 'companies', 'don', '##t', 'realize', 'that', 'when', 'they', 'hire', 'visa', 'holders', 'that', 'they', 'are', 'helping', 'to', 'contribute', 'to', 'the', 'problem', '.', 'nj', 'just', 'so', 'happens', 'to', 'have', 'stumbled', 'across', 'the', 'tip', 'of', 'the', 'ice', '##berg', '.', '\"']\n",
            " \toffsets: [0, 1, 7, 11, 15, 20, 22, 24, 28, 34, 39, 46, 49, 56, 61, 66, 69, 72, 74, 78, 86, 89, 95, 97, 103, 108, 112, 114, 121, 128, 132, 138, 141, 153, 157, 161, 172, 176, 183, 188, 192, 195, 205, 208, 212, 217, 223, 225, 229, 232, 235, 239, 246, 248, 254, 257, 268, 273, 275, 280, 282, 284, 287, 290, 297, 301, 313, 315, 318, 322, 328, 331, 336, 346, 349, 351, 359, 364, 369, 374, 379, 384, 392, 397, 402, 406, 414, 417, 428, 431, 435, 442, 444, 447, 452, 455, 463, 466, 471, 480, 487, 491, 495, 498, 502, 505, 509, 510]\n",
            " \tstart_of_word: [True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, True, False, True, False, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, True, False, True, False, False, False, True, True, False, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 13718, 2049, 2025, 2074, 19193, 1012, 1996, 2878, 9425, 2291, 2003, 11083, 2013, 2132, 2000, 11756, 1010, 1998, 20625, 2135, 3714, 1012, 2045, 2074, 4995, 2102, 2438, 2111, 2041, 2045, 2000, 8556, 2035, 1996, 10821, 1998, 21078, 2008, 2024, 2061, 15157, 1999, 1996, 9425, 2291, 1010, 1998, 2061, 2009, 2038, 2468, 1037, 2173, 1997, 6923, 9861, 1010, 6905, 1010, 2139, 28600, 7088, 9276, 1998, 14427, 1012, 6517, 4063, 2145, 2003, 2008, 3316, 2123, 2102, 5382, 2008, 2043, 2027, 10887, 9425, 13304, 2008, 2027, 2024, 5094, 2000, 9002, 2000, 1996, 3291, 1012, 19193, 2074, 2061, 6433, 2000, 2031, 9845, 2408, 1996, 5955, 1997, 1996, 3256, 4059, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv: 100%|██████████| 2647/2647 [00:10<00:00, 248.13 Dicts/s]\n",
            "09/16/2021 10:15:15 - INFO - farm.data_handler.data_silo -   Loading test set from: ../content/impermium_verification_set.tsv\n",
            "09/16/2021 10:15:15 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2235 dictionaries to pytorch datasets (chunksize = 447)...\n",
            "09/16/2021 10:15:15 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:15:15 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:15:15 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/16/2021 10:15:15 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/impermium_verification_set.tsv:   0%|          | 0/2235 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:15:16 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:15:16 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 377-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"michigan currently has felons on their team practicing as we speak. Are you dumb?\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'michigan', 'currently', 'has', 'fe', '##lon', '##s', 'on', 'their', 'team', 'practicing', 'as', 'we', 'speak', '.', 'are', 'you', 'dumb', '?', '\"']\n",
            " \toffsets: [0, 1, 10, 20, 24, 26, 29, 31, 34, 40, 45, 56, 59, 62, 67, 69, 73, 77, 81, 82]\n",
            " \tstart_of_word: [True, False, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 4174, 2747, 2038, 10768, 7811, 2015, 2006, 2037, 2136, 12560, 2004, 2057, 3713, 1012, 2024, 2017, 12873, 1029, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:15:16 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 55-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"man i 100% agree with you Shaunie fake ass with them even fake ass tear can cry me a river the bitch just like them to other rats are trying to save face \"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'man', 'i', '100', '%', 'agree', 'with', 'you', 'shaun', '##ie', 'fake', 'ass', 'with', 'them', 'even', 'fake', 'ass', 'tear', 'can', 'cry', 'me', 'a', 'river', 'the', 'bitch', 'just', 'like', 'them', 'to', 'other', 'rats', 'are', 'trying', 'to', 'save', 'face', '\"']\n",
            " \toffsets: [0, 1, 5, 7, 10, 12, 18, 23, 27, 32, 35, 40, 44, 49, 54, 59, 64, 68, 73, 77, 81, 84, 86, 92, 96, 102, 107, 112, 117, 120, 126, 131, 135, 142, 145, 150, 155]\n",
            " \tstart_of_word: [True, False, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 2158, 1045, 2531, 1003, 5993, 2007, 2017, 16845, 2666, 8275, 4632, 2007, 2068, 2130, 8275, 4632, 7697, 2064, 5390, 2033, 1037, 2314, 1996, 7743, 2074, 2066, 2068, 2000, 2060, 11432, 2024, 2667, 2000, 3828, 2227, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/impermium_verification_set.tsv: 100%|██████████| 2235/2235 [00:05<00:00, 445.14 Dicts/s]\n",
            "09/16/2021 10:15:20 - INFO - farm.data_handler.data_silo -   Examples in train: 3947\n",
            "09/16/2021 10:15:20 - INFO - farm.data_handler.data_silo -   Examples in dev  : 2647\n",
            "09/16/2021 10:15:20 - INFO - farm.data_handler.data_silo -   Examples in test : 2235\n",
            "09/16/2021 10:15:20 - INFO - farm.data_handler.data_silo -   \n",
            "09/16/2021 10:15:20 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
            "09/16/2021 10:15:20 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 44.46693691411198\n",
            "09/16/2021 10:15:20 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.07904737775525715\n",
            "09/16/2021 10:15:24 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/16/2021 10:15:24 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/16/2021 10:15:24 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6810969 1.8804762]\n",
            "09/16/2021 10:15:24 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
            "09/16/2021 10:15:24 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/16/2021 10:15:24 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 37.2, 'num_training_steps': 372}'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 16 10:15:25 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   55C    P0    60W / 149W |   5919MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:15:25 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/2 (Cur. train loss: 0.4456):  81%|████████  | 100/124 [02:06<00:30,  1.27s/it]\n",
            "Evaluating:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  28%|██▊       | 23/83 [00:10<00:27,  2.21it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 46/83 [00:20<00:16,  2.21it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 83/83 [00:37<00:00,  2.22it/s]\n",
            "09/16/2021 10:18:10 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:18:10 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:18:11 - INFO - farm.eval -   loss: 0.34402813783536823\n",
            "09/16/2021 10:18:11 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:18:11 - INFO - farm.eval -   f1_macro: 0.8431281784327074\n",
            "09/16/2021 10:18:11 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9332    0.8936    0.9129      1954\n",
            "           1     0.7320    0.8196    0.7733       693\n",
            "\n",
            "    accuracy                         0.8742      2647\n",
            "   macro avg     0.8326    0.8566    0.8431      2647\n",
            "weighted avg     0.8805    0.8742    0.8764      2647\n",
            "\n",
            "Train epoch 0/2 (Cur. train loss: 0.2946): 100%|██████████| 124/124 [03:13<00:00,  1.56s/it]\n",
            "Train epoch 1/2 (Cur. train loss: 0.2131):  61%|██████▏   | 76/124 [01:35<01:00,  1.25s/it]\n",
            "Evaluating:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  28%|██▊       | 23/83 [00:10<00:27,  2.21it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 46/83 [00:20<00:16,  2.22it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 83/83 [00:37<00:00,  2.22it/s]\n",
            "09/16/2021 10:20:53 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:20:53 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:20:53 - INFO - farm.eval -   loss: 0.3462052761855376\n",
            "09/16/2021 10:20:53 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:20:53 - INFO - farm.eval -   f1_macro: 0.8441652185998251\n",
            "09/16/2021 10:20:53 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9493    0.8721    0.9090      1954\n",
            "           1     0.7066    0.8687    0.7793       693\n",
            "\n",
            "    accuracy                         0.8712      2647\n",
            "   macro avg     0.8279    0.8704    0.8442      2647\n",
            "weighted avg     0.8858    0.8712    0.8751      2647\n",
            "\n",
            "Train epoch 1/2 (Cur. train loss: 0.2481): 100%|██████████| 124/124 [03:12<00:00,  1.55s/it]\n",
            "Train epoch 2/2 (Cur. train loss: 0.1784):  42%|████▏     | 52/124 [01:05<01:30,  1.25s/it]\n",
            "Evaluating:   0%|          | 0/83 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating:  28%|██▊       | 23/83 [00:10<00:27,  2.21it/s]\u001b[A\n",
            "Evaluating:  55%|█████▌    | 46/83 [00:20<00:16,  2.21it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 83/83 [00:37<00:00,  2.22it/s]\n",
            "09/16/2021 10:23:36 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:23:36 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:23:36 - INFO - farm.eval -   loss: 0.4409701095061524\n",
            "09/16/2021 10:23:36 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:23:36 - INFO - farm.eval -   f1_macro: 0.850027999695878\n",
            "09/16/2021 10:23:36 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9255    0.9150    0.9202      1954\n",
            "           1     0.7678    0.7922    0.7798       693\n",
            "\n",
            "    accuracy                         0.8829      2647\n",
            "   macro avg     0.8466    0.8536    0.8500      2647\n",
            "weighted avg     0.8842    0.8829    0.8835      2647\n",
            "\n",
            "Train epoch 2/2 (Cur. train loss: 0.0903): 100%|██████████| 124/124 [03:12<00:00,  1.55s/it]\n",
            "Evaluating: 100%|██████████| 70/70 [00:31<00:00,  2.22it/s]\n",
            "09/16/2021 10:25:36 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 372 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:25:36 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:25:36 - INFO - farm.eval -   loss: 1.1099447418912678\n",
            "09/16/2021 10:25:36 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:25:36 - INFO - farm.eval -   f1_macro: 0.7766588203943863\n",
            "09/16/2021 10:25:36 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.7333    0.9119    0.8129      1158\n",
            "           1     0.8717    0.6435    0.7404      1077\n",
            "\n",
            "    accuracy                         0.7826      2235\n",
            "   macro avg     0.8025    0.7777    0.7767      2235\n",
            "weighted avg     0.8000    0.7826    0.7780      2235\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUcVSIrkjl2P"
      },
      "source": [
        "### BERT: k-fold cross validation attempt"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7chxqrlCjpTY"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score,recall_score,precision_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# splitte die daten einfach manuell für k-fold cross validation\n",
        "X_train = train.Comment.Values\n",
        "y_train = train.Insult.Values\n",
        "\n",
        "# Aufteilen des train.csv Datensatzes für k-fold cross validation\n",
        "\n",
        "#train = pd.read_csv(\"../content/train.csv\")\n",
        "\n",
        "#X  = train.Comment.values\n",
        "#y = train.Insult.values\n",
        "\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAI1dfqwJ0dN",
        "outputId": "1ed5ca63-abf3-4f8c-eb54-0a1f7d8fd53d"
      },
      "source": [
        "logger = logging.getLogger(__name__)\n",
        "xval_folds = 5\n",
        "xval_stratification = True\n",
        "\n",
        "set_all_seeds(seed=42)\n",
        "device, n_gpu = initialize_device_settings(use_cuda=True)\n",
        "n_epochs = 20\n",
        "batch_size = 32\n",
        "evaluate_every = 100\n",
        "dev_split = 0.1\n",
        "# For xval the dev_stratification parameter must not be None: with None, the devset cannot be created\n",
        "# using the default method of only splitting by the available chunks as initial train set for each fold\n",
        "# is just a single chunk!\n",
        "dev_stratification = True\n",
        "lang_model = \"bert-base-uncased\"\n",
        "do_lower_case = True\n",
        "use_amp = None"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/17/2021 11:03:58 - INFO - farm.utils -   device: cuda n_gpu: 1, distributed training: False, automatic mixed precision training: None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOUZSsECWbXj",
        "outputId": "eb6d5c99-d0b8-457b-ad10-2b9dd26fefb2"
      },
      "source": [
        "# 1.Create a tokenizer\n",
        "tokenizer = Tokenizer.load(\n",
        "    pretrained_model_name_or_path=lang_model,\n",
        "    do_lower_case=do_lower_case)\n",
        "\n",
        "def mymetrics(preds, labels):\n",
        "    acc = simple_accuracy(preds, labels).get(\"acc\")\n",
        "    f1other = f1_score(y_true=labels, y_pred=preds, pos_label=\"0\")\n",
        "    f1offense = f1_score(y_true=labels, y_pred=preds, pos_label=\"1\")\n",
        "    f1macro = f1_score(y_true=labels, y_pred=preds, average=\"macro\")\n",
        "    f1micro = f1_score(y_true=labels, y_pred=preds, average=\"micro\")\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    return {\n",
        "        \"acc\": acc,\n",
        "        \"f1_other\": f1other,\n",
        "        \"f1_offense\": f1offense,\n",
        "        \"f1_macro\": f1macro,\n",
        "        \"f1_micro\": f1micro,\n",
        "        \"mcc\": mcc\n",
        "    }\n",
        "register_metrics('mymetrics', mymetrics)\n",
        "metric = 'mymetrics'\n",
        "\n",
        "label_list = [\"0\", \"1\"]\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=128,\n",
        "                                        data_dir=Path(\"../content\"),\n",
        "                                        train_filename=\"train.tsv\",\n",
        "                                        dev_filename=\"test_with_solutions.tsv\",\n",
        "                                        test_filename=\"impermium_verification_labels.tsv\",\n",
        "                                        label_list=label_list,\n",
        "                                        metric=metric,\n",
        "                                        dev_split=dev_split,\n",
        "                                        dev_stratification=dev_stratification,\n",
        "                                        label_column_name=\"Insult\",\n",
        "                                        text_column_name=\"Comment\"\n",
        "                                        )"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/17/2021 11:04:01 - INFO - farm.modeling.tokenization -   Loading tokenizer of type 'BertTokenizer'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmEkfI_2XYX-",
        "outputId": "349be155-06cd-469a-ff3c-8d4b69c02c88"
      },
      "source": [
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=batch_size)\n",
        "\n",
        "silos = DataSiloForCrossVal.make(data_silo,\n",
        "                                  sets=[\"train\", \"dev\"],\n",
        "                                  n_splits=xval_folds)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/17/2021 11:04:04 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "09/17/2021 11:04:04 - INFO - farm.data_handler.data_silo -   Loading train set from: ../content/train.tsv \n",
            "09/17/2021 11:04:04 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 3947 dictionaries to pytorch datasets (chunksize = 790)...\n",
            "09/17/2021 11:04:04 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/17/2021 11:04:04 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/17/2021 11:04:04 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/17/2021 11:04:04 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/train.tsv:   0%|          | 0/3947 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/17/2021 11:04:07 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/17/2021 11:04:07 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 293-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"We'll leave the fanaticism to morons like you, criminal.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'we', \"'\", 'll', 'leave', 'the', 'fan', '##atic', '##ism', 'to', 'mor', '##ons', 'like', 'you', ',', 'criminal', '.', '\"']\n",
            " \toffsets: [0, 1, 3, 4, 7, 13, 17, 20, 24, 28, 31, 34, 38, 43, 46, 48, 56, 57]\n",
            " \tstart_of_word: [True, False, False, False, True, True, True, False, False, True, True, False, True, True, False, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 2057, 1005, 2222, 2681, 1996, 5470, 12070, 2964, 2000, 22822, 5644, 2066, 2017, 1010, 4735, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "09/17/2021 11:04:07 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 31-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"A good article, which, for all the good it will do, could have been delivered to a brick wall.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'a', 'good', 'article', ',', 'which', ',', 'for', 'all', 'the', 'good', 'it', 'will', 'do', ',', 'could', 'have', 'been', 'delivered', 'to', 'a', 'brick', 'wall', '.', '\"']\n",
            " \toffsets: [0, 1, 3, 8, 15, 17, 22, 24, 28, 32, 36, 41, 44, 49, 51, 53, 59, 64, 69, 79, 82, 84, 90, 94, 95]\n",
            " \tstart_of_word: [True, False, True, True, False, True, False, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 1037, 2204, 3720, 1010, 2029, 1010, 2005, 2035, 1996, 2204, 2009, 2097, 2079, 1010, 2071, 2031, 2042, 5359, 2000, 1037, 5318, 2813, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/train.tsv: 100%|██████████| 3947/3947 [00:14<00:00, 280.65 Dicts/s]\n",
            "09/17/2021 11:04:18 - INFO - farm.data_handler.data_silo -   Loading dev set from: ../content/test_with_solutions.tsv\n",
            "09/17/2021 11:04:19 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2647 dictionaries to pytorch datasets (chunksize = 530)...\n",
            "09/17/2021 11:04:19 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/17/2021 11:04:19 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/17/2021 11:04:19 - INFO - farm.data_handler.data_silo -   / \\\n",
            "09/17/2021 11:04:19 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv:   0%|          | 0/2647 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/17/2021 11:04:22 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/17/2021 11:04:22 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 382-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"I know. I come here to tell you that you are a...piece of...shit.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'i', 'know', '.', 'i', 'come', 'here', 'to', 'tell', 'you', 'that', 'you', 'are', 'a', '.', '.', '.', 'piece', 'of', '.', '.', '.', 'shit', '.', '\"']\n",
            " \toffsets: [0, 1, 3, 7, 9, 11, 16, 21, 24, 29, 33, 38, 42, 46, 47, 48, 49, 50, 56, 58, 59, 60, 61, 65, 66]\n",
            " \tstart_of_word: [True, False, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, False, False, False, False, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 1045, 2113, 1012, 1045, 2272, 2182, 2000, 2425, 2017, 2008, 2017, 2024, 1037, 1012, 1012, 1012, 3538, 1997, 1012, 1012, 1012, 4485, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "09/17/2021 11:04:22 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 7-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"How about we accept facts and patiently wait for you to back up your claim.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'how', 'about', 'we', 'accept', 'facts', 'and', 'patiently', 'wait', 'for', 'you', 'to', 'back', 'up', 'your', 'claim', '.', '\"']\n",
            " \toffsets: [0, 1, 5, 11, 14, 21, 27, 31, 41, 46, 50, 54, 57, 62, 65, 70, 75, 76]\n",
            " \tstart_of_word: [True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 2129, 2055, 2057, 5138, 8866, 1998, 19080, 3524, 2005, 2017, 2000, 2067, 2039, 2115, 4366, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv: 100%|██████████| 2647/2647 [00:10<00:00, 256.97 Dicts/s]\n",
            "09/17/2021 11:04:29 - INFO - farm.data_handler.data_silo -   Loading test set from: ../content/impermium_verification_labels.tsv\n",
            "09/17/2021 11:04:29 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2235 dictionaries to pytorch datasets (chunksize = 447)...\n",
            "09/17/2021 11:04:29 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/17/2021 11:04:29 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/17/2021 11:04:29 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/17/2021 11:04:29 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/impermium_verification_labels.tsv:   0%|          | 0/2235 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/17/2021 11:04:30 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/17/2021 11:04:30 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 230-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"Screw you Bodine. \"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'screw', 'you', 'bo', '##dine', '.', '\"']\n",
            " \toffsets: [0, 1, 7, 11, 13, 17, 19]\n",
            " \tstart_of_word: [True, False, True, True, False, False, True]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 11224, 2017, 8945, 10672, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "09/17/2021 11:04:30 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 377-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"michigan currently has felons on their team practicing as we speak. Are you dumb?\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'michigan', 'currently', 'has', 'fe', '##lon', '##s', 'on', 'their', 'team', 'practicing', 'as', 'we', 'speak', '.', 'are', 'you', 'dumb', '?', '\"']\n",
            " \toffsets: [0, 1, 10, 20, 24, 26, 29, 31, 34, 40, 45, 56, 59, 62, 67, 69, 73, 77, 81, 82]\n",
            " \tstart_of_word: [True, False, True, True, True, False, False, True, True, True, True, True, True, True, False, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 4174, 2747, 2038, 10768, 7811, 2015, 2006, 2037, 2136, 12560, 2004, 2057, 3713, 1012, 2024, 2017, 12873, 1029, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/impermium_verification_labels.tsv: 100%|██████████| 2235/2235 [00:04<00:00, 471.14 Dicts/s]\n",
            "09/17/2021 11:04:34 - INFO - farm.data_handler.data_silo -   Examples in train: 3947\n",
            "09/17/2021 11:04:34 - INFO - farm.data_handler.data_silo -   Examples in dev  : 2647\n",
            "09/17/2021 11:04:34 - INFO - farm.data_handler.data_silo -   Examples in test : 2235\n",
            "09/17/2021 11:04:34 - INFO - farm.data_handler.data_silo -   \n",
            "09/17/2021 11:04:34 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
            "09/17/2021 11:04:34 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 44.46693691411198\n",
            "09/17/2021 11:04:34 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.07904737775525715\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z6ZvKMYgXtFs"
      },
      "source": [
        "def train_on_split(silo_to_use, n_fold, save_dir):\n",
        "        logger.info(f\"############ Crossvalidation: Fold {n_fold} of {xval_folds} ############\")\n",
        "        logger.info(f\"Fold training   samples: {len(silo_to_use.data['train'])}\")\n",
        "        logger.info(f\"Fold dev        samples: {len(silo_to_use.data['dev'])}\")\n",
        "        logger.info(f\"Fold testing    samples: {len(silo_to_use.data['test'])}\")\n",
        "        logger.info( \"Total number of samples: \"\n",
        "                    f\"{len(silo_to_use.data['train'])+len(silo_to_use.data['dev'])+len(silo_to_use.data['test'])}\")\n",
        "\n",
        "        # Create an AdaptiveModel\n",
        "        # a) which consists of a pretrained language model as a basis\n",
        "        language_model = LanguageModel.load(lang_model)\n",
        "        # b) and a prediction head on top that is suited for our task => Text classification\n",
        "        prediction_head = TextClassificationHead(\n",
        "            class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"),\n",
        "            num_labels=len(label_list))\n",
        "\n",
        "        model = AdaptiveModel(\n",
        "            language_model=language_model,\n",
        "            prediction_heads=[prediction_head],\n",
        "            embeds_dropout_prob=0.2,\n",
        "            lm_output_types=[\"per_sequence\"],\n",
        "            device=device)\n",
        "\n",
        "        # Create an optimizer\n",
        "        model, optimizer, lr_schedule = initialize_optimizer(\n",
        "            model=model,\n",
        "            learning_rate=0.5e-5,\n",
        "            device=device,\n",
        "            n_batches=len(silo_to_use.loaders[\"train\"]),\n",
        "            n_epochs=n_epochs,\n",
        "            use_amp=use_amp)\n",
        "\n",
        "        # Feed everything to the Trainer, which keeps care of growing our model into powerful plant and evaluates it from time to time\n",
        "        # Also create an EarlyStopping instance and pass it on to the trainer\n",
        "\n",
        "        # An early stopping instance can be used to save the model that performs best on the dev set\n",
        "        # according to some metric and stop training when no improvement is happening for some iterations.\n",
        "        # NOTE: Using a different save directory for each fold, allows us afterwards to use the\n",
        "        # nfolds best models in an ensemble!\n",
        "        save_dir = Path(str(save_dir) + f\"-{n_fold}\")\n",
        "        earlystopping = EarlyStopping(\n",
        "            metric=\"f1_offense\", mode=\"max\",   # use the metric from our own metrics function instead of loss\n",
        "            save_dir=save_dir,  # where to save the best model\n",
        "            patience=5    # number of evaluations to wait for improvement before terminating the training\n",
        "        )\n",
        "\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            optimizer=optimizer,\n",
        "            data_silo=silo_to_use,\n",
        "            epochs=n_epochs,\n",
        "            n_gpu=n_gpu,\n",
        "            lr_schedule=lr_schedule,\n",
        "            evaluate_every=evaluate_every,\n",
        "            device=device,\n",
        "            early_stopping=earlystopping,\n",
        "            evaluator_test=False)\n",
        "\n",
        "        # train it\n",
        "        trainer.train()\n",
        "\n",
        "        return trainer.model"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "0830f26be1aa49a89dfa8453cba50ff2",
            "32d056f1a4ab4bb6abad062c239422c2",
            "30a9463bc8de4bf88920be1f9a6e2764",
            "209f1f8b5dc440fa9356da4f4927186d",
            "522fe391eec34dafb7890fb9a1e6f73f",
            "524887716b33496dacc4809d49195395",
            "2bb70c15ee3b415e8b46ac21befd5934",
            "bea0684e78804375ba41baf84eff778a",
            "5d6af0e1d34b4f1f9edf6fc599121e2f",
            "7d4ce8ef393a4875b44e2c748e06f7d0",
            "61d239e13a144823a73c6b618cc167dc"
          ]
        },
        "id": "Fain3HWeX1ni",
        "outputId": "3b74fa96-1578-48f6-f7fd-d17badb2e21a"
      },
      "source": [
        "allresults = []\n",
        "bestfold = None\n",
        "bestf1_offense = -1\n",
        "save_dir = Path(\"saved_models/bert-doc-tutorial-es\")\n",
        "for num_fold, silo in enumerate(silos):\n",
        "    mlflow.start_run(run_name=f\"fold-{num_fold + 1}-of-{len(silos)}\", nested=True)\n",
        "    model = train_on_split(silo, num_fold, save_dir)\n",
        "\n",
        "    # do eval on test set here (and not in Trainer),\n",
        "    #  so that we can easily store the actual preds and labels for a \"global\" eval across all folds.\n",
        "    evaluator_test = Evaluator(\n",
        "        data_loader=silo.get_data_loader(\"test\"),\n",
        "        tasks=silo.processor.tasks,\n",
        "        device=device\n",
        "    )\n",
        "    result = evaluator_test.eval(model, return_preds_and_labels=True)\n",
        "    evaluator_test.log_results(result, \"Test\", steps=len(silo.get_data_loader(\"test\")), num_fold=num_fold)\n",
        "\n",
        "    allresults.append(result)\n",
        "\n",
        "    # keep track of best fold\n",
        "    f1_offense = result[0][\"f1_offense\"]\n",
        "    if f1_offense > bestf1_offense:\n",
        "        bestf1_offense = f1_offense\n",
        "        bestfold = num_fold\n",
        "    mlflow.end_run()\n",
        "    # emtpy cache to avoid memory leak and cuda OOM across multiple folds\n",
        "    model.cpu()\n",
        "    torch.cuda.empty_cache()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/17/2021 11:04:45 - INFO - __main__ -   ############ Crossvalidation: Fold 0 of 5 ############\n",
            "09/17/2021 11:04:45 - INFO - __main__ -   Fold training   samples: 4748\n",
            "09/17/2021 11:04:45 - INFO - __main__ -   Fold dev        samples: 527\n",
            "09/17/2021 11:04:45 - INFO - __main__ -   Fold testing    samples: 1319\n",
            "09/17/2021 11:04:45 - INFO - __main__ -   Total number of samples: 6594\n",
            "09/17/2021 11:04:45 - INFO - filelock -   Lock 139741784311376 acquired on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0830f26be1aa49a89dfa8453cba50ff2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/17/2021 11:05:05 - INFO - filelock -   Lock 139741784311376 released on /root/.cache/torch/transformers/f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157.lock\n",
            "09/17/2021 11:05:08 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/17/2021 11:05:08 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/17/2021 11:05:08 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6810969 1.8804762]\n",
            "09/17/2021 11:05:11 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 5e-06}'\n",
            "09/17/2021 11:05:12 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/17/2021 11:05:12 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 298.0, 'num_training_steps': 2980}'\n",
            "09/17/2021 11:05:14 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/19 (Cur. train loss: 0.5275):  67%|██████▋   | 100/149 [02:15<01:04,  1.31s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:07:39 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:07:39 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:07:39 - INFO - farm.eval -   loss: 0.4641807988653599\n",
            "09/17/2021 11:07:39 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:07:40 - INFO - farm.eval -   acc: 0.8026565464895635\n",
            "09/17/2021 11:07:40 - INFO - farm.eval -   f1_other: 0.8579234972677595\n",
            "09/17/2021 11:07:41 - INFO - farm.eval -   f1_offense: 0.6770186335403727\n",
            "09/17/2021 11:07:41 - INFO - farm.eval -   f1_macro: 0.7674710654040662\n",
            "09/17/2021 11:07:42 - INFO - farm.eval -   f1_micro: 0.8026565464895635\n",
            "09/17/2021 11:07:42 - INFO - farm.eval -   mcc: 0.5550840093210863\n",
            "09/17/2021 11:07:42 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9235    0.8010    0.8579       392\n",
            "           1     0.5829    0.8074    0.6770       135\n",
            "\n",
            "    accuracy                         0.8027       527\n",
            "   macro avg     0.7532    0.8042    0.7675       527\n",
            "weighted avg     0.8363    0.8027    0.8116       527\n",
            "\n",
            "09/17/2021 11:07:42 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-0, eval=0.6770186335403727\n",
            "Train epoch 0/19 (Cur. train loss: 0.6241): 100%|██████████| 149/149 [03:33<00:00,  1.43s/it]\n",
            "Train epoch 1/19 (Cur. train loss: 0.1845):  34%|███▍      | 51/149 [01:08<02:06,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:10:05 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:10:05 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:10:05 - INFO - farm.eval -   loss: 0.3634918559434518\n",
            "09/17/2021 11:10:05 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:10:06 - INFO - farm.eval -   acc: 0.855787476280835\n",
            "09/17/2021 11:10:06 - INFO - farm.eval -   f1_other: 0.9012987012987013\n",
            "09/17/2021 11:10:07 - INFO - farm.eval -   f1_offense: 0.7323943661971831\n",
            "09/17/2021 11:10:07 - INFO - farm.eval -   f1_macro: 0.8168465337479422\n",
            "09/17/2021 11:10:08 - INFO - farm.eval -   f1_micro: 0.855787476280835\n",
            "09/17/2021 11:10:08 - INFO - farm.eval -   mcc: 0.6354668563198242\n",
            "09/17/2021 11:10:08 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9180    0.8852    0.9013       392\n",
            "           1     0.6980    0.7704    0.7324       135\n",
            "\n",
            "    accuracy                         0.8558       527\n",
            "   macro avg     0.8080    0.8278    0.8168       527\n",
            "weighted avg     0.8616    0.8558    0.8580       527\n",
            "\n",
            "09/17/2021 11:10:08 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-0, eval=0.7323943661971831\n",
            "Train epoch 1/19 (Cur. train loss: 0.3708): 100%|██████████| 149/149 [03:32<00:00,  1.43s/it]\n",
            "Train epoch 2/19 (Cur. train loss: 0.1033):   1%|▏         | 2/149 [00:02<03:07,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:12:32 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:12:32 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:12:32 - INFO - farm.eval -   loss: 0.33932703247106505\n",
            "09/17/2021 11:12:32 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:12:33 - INFO - farm.eval -   acc: 0.8481973434535104\n",
            "09/17/2021 11:12:33 - INFO - farm.eval -   f1_other: 0.8915989159891599\n",
            "09/17/2021 11:12:34 - INFO - farm.eval -   f1_offense: 0.7468354430379747\n",
            "09/17/2021 11:12:34 - INFO - farm.eval -   f1_macro: 0.8192171795135672\n",
            "09/17/2021 11:12:35 - INFO - farm.eval -   f1_micro: 0.8481973434535104\n",
            "09/17/2021 11:12:35 - INFO - farm.eval -   mcc: 0.6557543885241633\n",
            "09/17/2021 11:12:35 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9509    0.8393    0.8916       392\n",
            "           1     0.6519    0.8741    0.7468       135\n",
            "\n",
            "    accuracy                         0.8482       527\n",
            "   macro avg     0.8014    0.8567    0.8192       527\n",
            "weighted avg     0.8743    0.8482    0.8545       527\n",
            "\n",
            "09/17/2021 11:12:35 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-0, eval=0.7468354430379747\n",
            "Train epoch 2/19 (Cur. train loss: 0.0443):  68%|██████▊   | 102/149 [02:29<01:00,  1.30s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:14:58 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 400 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:14:58 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:14:59 - INFO - farm.eval -   loss: 0.35314865628048864\n",
            "09/17/2021 11:14:59 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:14:59 - INFO - farm.eval -   acc: 0.8652751423149905\n",
            "09/17/2021 11:15:00 - INFO - farm.eval -   f1_other: 0.905710491367862\n",
            "09/17/2021 11:15:00 - INFO - farm.eval -   f1_offense: 0.7641196013289037\n",
            "09/17/2021 11:15:01 - INFO - farm.eval -   f1_macro: 0.8349150463483828\n",
            "09/17/2021 11:15:01 - INFO - farm.eval -   f1_micro: 0.8652751423149905\n",
            "09/17/2021 11:15:02 - INFO - farm.eval -   mcc: 0.6782486712820132\n",
            "09/17/2021 11:15:02 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9446    0.8699    0.9057       392\n",
            "           1     0.6928    0.8519    0.7641       135\n",
            "\n",
            "    accuracy                         0.8653       527\n",
            "   macro avg     0.8187    0.8609    0.8349       527\n",
            "weighted avg     0.8801    0.8653    0.8694       527\n",
            "\n",
            "09/17/2021 11:15:02 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-0, eval=0.7641196013289037\n",
            "Train epoch 2/19 (Cur. train loss: 0.0396): 100%|██████████| 149/149 [03:44<00:00,  1.50s/it]\n",
            "Train epoch 3/19 (Cur. train loss: 0.2962):  36%|███▌      | 53/149 [01:10<02:04,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:17:24 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 500 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:17:24 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:17:25 - INFO - farm.eval -   loss: 0.5341185044066051\n",
            "09/17/2021 11:17:25 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:17:25 - INFO - farm.eval -   acc: 0.889943074003795\n",
            "09/17/2021 11:17:25 - INFO - farm.eval -   f1_other: 0.9280397022332506\n",
            "09/17/2021 11:17:26 - INFO - farm.eval -   f1_offense: 0.7661290322580645\n",
            "09/17/2021 11:17:26 - INFO - farm.eval -   f1_macro: 0.8470843672456576\n",
            "09/17/2021 11:17:27 - INFO - farm.eval -   f1_micro: 0.8899430740037951\n",
            "09/17/2021 11:17:27 - INFO - farm.eval -   mcc: 0.6996079134021821\n",
            "09/17/2021 11:17:27 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9034    0.9541    0.9280       392\n",
            "           1     0.8407    0.7037    0.7661       135\n",
            "\n",
            "    accuracy                         0.8899       527\n",
            "   macro avg     0.8720    0.8289    0.8471       527\n",
            "weighted avg     0.8873    0.8899    0.8866       527\n",
            "\n",
            "09/17/2021 11:17:27 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-0, eval=0.7661290322580645\n",
            "Train epoch 3/19 (Cur. train loss: 0.0090): 100%|██████████| 149/149 [03:31<00:00,  1.42s/it]\n",
            "Train epoch 4/19 (Cur. train loss: 0.0271):   3%|▎         | 4/149 [00:05<03:05,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:19:50 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 600 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:19:50 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:19:50 - INFO - farm.eval -   loss: 0.5768462250988217\n",
            "09/17/2021 11:19:50 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:19:51 - INFO - farm.eval -   acc: 0.889943074003795\n",
            "09/17/2021 11:19:51 - INFO - farm.eval -   f1_other: 0.9269521410579346\n",
            "09/17/2021 11:19:52 - INFO - farm.eval -   f1_offense: 0.7769230769230769\n",
            "09/17/2021 11:19:52 - INFO - farm.eval -   f1_macro: 0.8519376089905057\n",
            "09/17/2021 11:19:53 - INFO - farm.eval -   f1_micro: 0.8899430740037951\n",
            "09/17/2021 11:19:53 - INFO - farm.eval -   mcc: 0.7049370859111759\n",
            "09/17/2021 11:19:53 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9154    0.9388    0.9270       392\n",
            "           1     0.8080    0.7481    0.7769       135\n",
            "\n",
            "    accuracy                         0.8899       527\n",
            "   macro avg     0.8617    0.8435    0.8519       527\n",
            "weighted avg     0.8879    0.8899    0.8885       527\n",
            "\n",
            "09/17/2021 11:19:53 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-0, eval=0.7769230769230769\n",
            "Train epoch 4/19 (Cur. train loss: 0.0060):  70%|██████▉   | 104/149 [02:31<00:58,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:22:16 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 700 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:22:16 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:22:16 - INFO - farm.eval -   loss: 0.5849613727581117\n",
            "09/17/2021 11:22:16 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:22:17 - INFO - farm.eval -   acc: 0.8709677419354839\n",
            "09/17/2021 11:22:17 - INFO - farm.eval -   f1_other: 0.9109947643979057\n",
            "09/17/2021 11:22:18 - INFO - farm.eval -   f1_offense: 0.7655172413793104\n",
            "09/17/2021 11:22:18 - INFO - farm.eval -   f1_macro: 0.8382560028886081\n",
            "09/17/2021 11:22:19 - INFO - farm.eval -   f1_micro: 0.8709677419354839\n",
            "09/17/2021 11:22:19 - INFO - farm.eval -   mcc: 0.6801693799984886\n",
            "09/17/2021 11:22:19 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9355    0.8878    0.9110       392\n",
            "           1     0.7161    0.8222    0.7655       135\n",
            "\n",
            "    accuracy                         0.8710       527\n",
            "   macro avg     0.8258    0.8550    0.8383       527\n",
            "weighted avg     0.8793    0.8710    0.8737       527\n",
            "\n",
            "Train epoch 4/19 (Cur. train loss: 0.1821): 100%|██████████| 149/149 [03:41<00:00,  1.49s/it]\n",
            "Train epoch 5/19 (Cur. train loss: 0.0032):  37%|███▋      | 55/149 [01:12<02:00,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:24:39 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 800 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:24:39 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:24:40 - INFO - farm.eval -   loss: 0.6380599227078273\n",
            "09/17/2021 11:24:40 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:24:40 - INFO - farm.eval -   acc: 0.857685009487666\n",
            "09/17/2021 11:24:41 - INFO - farm.eval -   f1_other: 0.9022164276401564\n",
            "09/17/2021 11:24:41 - INFO - farm.eval -   f1_offense: 0.7386759581881533\n",
            "09/17/2021 11:24:42 - INFO - farm.eval -   f1_macro: 0.8204461929141549\n",
            "09/17/2021 11:24:42 - INFO - farm.eval -   f1_micro: 0.8576850094876661\n",
            "09/17/2021 11:24:43 - INFO - farm.eval -   mcc: 0.6434929259089995\n",
            "09/17/2021 11:24:43 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9227    0.8827    0.9022       392\n",
            "           1     0.6974    0.7852    0.7387       135\n",
            "\n",
            "    accuracy                         0.8577       527\n",
            "   macro avg     0.8100    0.8339    0.8204       527\n",
            "weighted avg     0.8650    0.8577    0.8603       527\n",
            "\n",
            "Train epoch 5/19 (Cur. train loss: 0.0024): 100%|██████████| 149/149 [03:28<00:00,  1.40s/it]\n",
            "Train epoch 6/19 (Cur. train loss: 0.0030):   4%|▍         | 6/149 [00:07<03:03,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:27:03 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 900 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:27:03 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:27:03 - INFO - farm.eval -   loss: 0.7246085494700147\n",
            "09/17/2021 11:27:03 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:27:04 - INFO - farm.eval -   acc: 0.8671726755218216\n",
            "09/17/2021 11:27:04 - INFO - farm.eval -   f1_other: 0.9102564102564102\n",
            "09/17/2021 11:27:05 - INFO - farm.eval -   f1_offense: 0.7445255474452555\n",
            "09/17/2021 11:27:05 - INFO - farm.eval -   f1_macro: 0.8273909788508329\n",
            "09/17/2021 11:27:06 - INFO - farm.eval -   f1_micro: 0.8671726755218218\n",
            "09/17/2021 11:27:06 - INFO - farm.eval -   mcc: 0.654935225808606\n",
            "09/17/2021 11:27:06 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9149    0.9056    0.9103       392\n",
            "           1     0.7338    0.7556    0.7445       135\n",
            "\n",
            "    accuracy                         0.8672       527\n",
            "   macro avg     0.8244    0.8306    0.8274       527\n",
            "weighted avg     0.8685    0.8672    0.8678       527\n",
            "\n",
            "Train epoch 6/19 (Cur. train loss: 0.0037):  71%|███████   | 106/149 [02:31<00:55,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:29:27 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1000 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:29:27 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:29:27 - INFO - farm.eval -   loss: 0.8286695869416847\n",
            "09/17/2021 11:29:27 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:29:28 - INFO - farm.eval -   acc: 0.8823529411764706\n",
            "09/17/2021 11:29:28 - INFO - farm.eval -   f1_other: 0.9228855721393036\n",
            "09/17/2021 11:29:29 - INFO - farm.eval -   f1_offense: 0.752\n",
            "09/17/2021 11:29:29 - INFO - farm.eval -   f1_macro: 0.8374427860696518\n",
            "09/17/2021 11:29:29 - INFO - farm.eval -   f1_micro: 0.8823529411764706\n",
            "09/17/2021 11:29:30 - INFO - farm.eval -   mcc: 0.6792622715541472\n",
            "09/17/2021 11:29:30 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9005    0.9464    0.9229       392\n",
            "           1     0.8174    0.6963    0.7520       135\n",
            "\n",
            "    accuracy                         0.8824       527\n",
            "   macro avg     0.8589    0.8214    0.8374       527\n",
            "weighted avg     0.8792    0.8824    0.8791       527\n",
            "\n",
            "Train epoch 6/19 (Cur. train loss: 0.0026): 100%|██████████| 149/149 [03:39<00:00,  1.47s/it]\n",
            "Train epoch 7/19 (Cur. train loss: 0.0014):  38%|███▊      | 57/149 [01:15<01:58,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:31:49 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:31:49 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:31:50 - INFO - farm.eval -   loss: 0.7572740167662134\n",
            "09/17/2021 11:31:50 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:31:50 - INFO - farm.eval -   acc: 0.8595825426944972\n",
            "09/17/2021 11:31:51 - INFO - farm.eval -   f1_other: 0.9043927648578811\n",
            "09/17/2021 11:31:51 - INFO - farm.eval -   f1_offense: 0.7357142857142858\n",
            "09/17/2021 11:31:52 - INFO - farm.eval -   f1_macro: 0.8200535252860834\n",
            "09/17/2021 11:31:52 - INFO - farm.eval -   f1_micro: 0.8595825426944972\n",
            "09/17/2021 11:31:53 - INFO - farm.eval -   mcc: 0.641030896357359\n",
            "09/17/2021 11:31:53 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9162    0.8929    0.9044       392\n",
            "           1     0.7103    0.7630    0.7357       135\n",
            "\n",
            "    accuracy                         0.8596       527\n",
            "   macro avg     0.8133    0.8279    0.8201       527\n",
            "weighted avg     0.8635    0.8596    0.8612       527\n",
            "\n",
            "Train epoch 7/19 (Cur. train loss: 0.0012): 100%|██████████| 149/149 [03:27<00:00,  1.39s/it]\n",
            "Train epoch 8/19 (Cur. train loss: 0.0009):   5%|▌         | 8/149 [00:10<02:59,  1.27s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:34:12 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:34:12 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:34:13 - INFO - farm.eval -   loss: 0.7849283096657984\n",
            "09/17/2021 11:34:13 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:34:13 - INFO - farm.eval -   acc: 0.8690702087286527\n",
            "09/17/2021 11:34:14 - INFO - farm.eval -   f1_other: 0.9111969111969113\n",
            "09/17/2021 11:34:14 - INFO - farm.eval -   f1_offense: 0.7509025270758122\n",
            "09/17/2021 11:34:15 - INFO - farm.eval -   f1_macro: 0.8310497191363617\n",
            "09/17/2021 11:34:15 - INFO - farm.eval -   f1_micro: 0.8690702087286527\n",
            "09/17/2021 11:34:16 - INFO - farm.eval -   mcc: 0.6625655770648093\n",
            "09/17/2021 11:34:16 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9195    0.9031    0.9112       392\n",
            "           1     0.7324    0.7704    0.7509       135\n",
            "\n",
            "    accuracy                         0.8691       527\n",
            "   macro avg     0.8259    0.8367    0.8310       527\n",
            "weighted avg     0.8716    0.8691    0.8701       527\n",
            "\n",
            "09/17/2021 11:34:16 - INFO - farm.train -   STOPPING EARLY AT EPOCH 8, STEP 8, EVALUATION 12\n",
            "Train epoch 8/19 (Cur. train loss: 0.0009):   5%|▌         | 8/149 [00:23<06:45,  2.88s/it]\n",
            "09/17/2021 11:34:16 - INFO - farm.train -   Restoring best model so far from saved_models/bert-doc-tutorial-es-0\n",
            "09/17/2021 11:34:18 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
            "09/17/2021 11:34:18 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
            "09/17/2021 11:34:18 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/17/2021 11:34:18 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6810969114303589, 1.8804762363433838]\n",
            "09/17/2021 11:34:18 - INFO - farm.modeling.prediction_head -   Loading prediction head from saved_models/bert-doc-tutorial-es-0/prediction_head_0.bin\n",
            "09/17/2021 11:34:19 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='lm_name' was already logged with value='bert-base-uncased' for run ID='7e378a14b0c54b978724a6df0534029a. Attempted logging new value 'saved_models/bert-doc-tutorial-es-0'.\n",
            "Evaluating: 100%|██████████| 42/42 [00:19<00:00,  2.16it/s]\n",
            "09/17/2021 11:34:39 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 42 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:34:39 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:34:39 - INFO - farm.eval -   loss: 0.7019780246290951\n",
            "09/17/2021 11:34:39 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:34:40 - INFO - farm.eval -   acc: 0.8658074298711145\n",
            "09/17/2021 11:34:40 - INFO - farm.eval -   f1_other: 0.9101978691019788\n",
            "09/17/2021 11:34:41 - INFO - farm.eval -   f1_offense: 0.7346326836581709\n",
            "09/17/2021 11:34:41 - INFO - farm.eval -   f1_macro: 0.8224152763800748\n",
            "09/17/2021 11:34:41 - INFO - farm.eval -   f1_micro: 0.8658074298711146\n",
            "09/17/2021 11:34:42 - INFO - farm.eval -   mcc: 0.6463398568875707\n",
            "09/17/2021 11:34:42 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8961    0.9247    0.9102       970\n",
            "           1     0.7704    0.7020    0.7346       349\n",
            "\n",
            "    accuracy                         0.8658      1319\n",
            "   macro avg     0.8333    0.8134    0.8224      1319\n",
            "weighted avg     0.8629    0.8658    0.8637      1319\n",
            "\n",
            "09/17/2021 11:34:44 - INFO - __main__ -   ############ Crossvalidation: Fold 1 of 5 ############\n",
            "09/17/2021 11:34:44 - INFO - __main__ -   Fold training   samples: 4748\n",
            "09/17/2021 11:34:44 - INFO - __main__ -   Fold dev        samples: 527\n",
            "09/17/2021 11:34:44 - INFO - __main__ -   Fold testing    samples: 1319\n",
            "09/17/2021 11:34:44 - INFO - __main__ -   Total number of samples: 6594\n",
            "09/17/2021 11:34:47 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/17/2021 11:34:47 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/17/2021 11:34:47 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6810969 1.8804762]\n",
            "09/17/2021 11:34:49 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 5e-06}'\n",
            "09/17/2021 11:34:49 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/17/2021 11:34:49 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 298.0, 'num_training_steps': 2980}'\n",
            "09/17/2021 11:34:51 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/19 (Cur. train loss: 0.4237):  67%|██████▋   | 100/149 [02:15<01:04,  1.31s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:37:16 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:37:16 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:37:16 - INFO - farm.eval -   loss: 0.5113869943926411\n",
            "09/17/2021 11:37:16 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:37:17 - INFO - farm.eval -   acc: 0.8368121442125237\n",
            "09/17/2021 11:37:17 - INFO - farm.eval -   f1_other: 0.8927680798004988\n",
            "09/17/2021 11:37:17 - INFO - farm.eval -   f1_offense: 0.6587301587301587\n",
            "09/17/2021 11:37:18 - INFO - farm.eval -   f1_macro: 0.7757491192653287\n",
            "09/17/2021 11:37:18 - INFO - farm.eval -   f1_micro: 0.8368121442125237\n",
            "09/17/2021 11:37:19 - INFO - farm.eval -   mcc: 0.5554015471816666\n",
            "09/17/2021 11:37:19 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.8710    0.9156    0.8928       391\n",
            "           1     0.7155    0.6103    0.6587       136\n",
            "\n",
            "    accuracy                         0.8368       527\n",
            "   macro avg     0.7933    0.7629    0.7757       527\n",
            "weighted avg     0.8309    0.8368    0.8324       527\n",
            "\n",
            "09/17/2021 11:37:19 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-1, eval=0.6587301587301587\n",
            "Train epoch 0/19 (Cur. train loss: 0.3756): 100%|██████████| 149/149 [03:32<00:00,  1.43s/it]\n",
            "Train epoch 1/19 (Cur. train loss: 0.3773):  34%|███▍      | 51/149 [01:07<02:06,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:39:41 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:39:41 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:39:41 - INFO - farm.eval -   loss: 0.3812028226182854\n",
            "09/17/2021 11:39:41 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:39:42 - INFO - farm.eval -   acc: 0.825426944971537\n",
            "09/17/2021 11:39:42 - INFO - farm.eval -   f1_other: 0.871866295264624\n",
            "09/17/2021 11:39:43 - INFO - farm.eval -   f1_offense: 0.7261904761904763\n",
            "09/17/2021 11:39:43 - INFO - farm.eval -   f1_macro: 0.7990283857275502\n",
            "09/17/2021 11:39:44 - INFO - farm.eval -   f1_micro: 0.825426944971537\n",
            "09/17/2021 11:39:44 - INFO - farm.eval -   mcc: 0.6290091464483243\n",
            "09/17/2021 11:39:44 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9572    0.8005    0.8719       391\n",
            "           1     0.6100    0.8971    0.7262       136\n",
            "\n",
            "    accuracy                         0.8254       527\n",
            "   macro avg     0.7836    0.8488    0.7990       527\n",
            "weighted avg     0.8676    0.8254    0.8343       527\n",
            "\n",
            "09/17/2021 11:39:44 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-1, eval=0.7261904761904763\n",
            "Train epoch 1/19 (Cur. train loss: 0.5206): 100%|██████████| 149/149 [03:30<00:00,  1.41s/it]\n",
            "Train epoch 2/19 (Cur. train loss: 0.1593):   1%|▏         | 2/149 [00:02<03:08,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:42:06 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:42:06 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:42:06 - INFO - farm.eval -   loss: 0.35141301607497505\n",
            "09/17/2021 11:42:06 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:42:07 - INFO - farm.eval -   acc: 0.8519924098671727\n",
            "09/17/2021 11:42:07 - INFO - farm.eval -   f1_other: 0.8951612903225806\n",
            "09/17/2021 11:42:08 - INFO - farm.eval -   f1_offense: 0.7483870967741936\n",
            "09/17/2021 11:42:08 - INFO - farm.eval -   f1_macro: 0.8217741935483871\n",
            "09/17/2021 11:42:09 - INFO - farm.eval -   f1_micro: 0.8519924098671727\n",
            "09/17/2021 11:42:09 - INFO - farm.eval -   mcc: 0.6556026522396634\n",
            "09/17/2021 11:42:09 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9433    0.8517    0.8952       391\n",
            "           1     0.6667    0.8529    0.7484       136\n",
            "\n",
            "    accuracy                         0.8520       527\n",
            "   macro avg     0.8050    0.8523    0.8218       527\n",
            "weighted avg     0.8719    0.8520    0.8573       527\n",
            "\n",
            "09/17/2021 11:42:09 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-1, eval=0.7483870967741936\n",
            "Train epoch 2/19 (Cur. train loss: 0.1402):  68%|██████▊   | 102/149 [02:28<01:00,  1.30s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:44:32 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 400 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:44:32 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:44:32 - INFO - farm.eval -   loss: 0.39583599974579786\n",
            "09/17/2021 11:44:32 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:44:33 - INFO - farm.eval -   acc: 0.872865275142315\n",
            "09/17/2021 11:44:33 - INFO - farm.eval -   f1_other: 0.9142125480153649\n",
            "09/17/2021 11:44:34 - INFO - farm.eval -   f1_offense: 0.7545787545787545\n",
            "09/17/2021 11:44:34 - INFO - farm.eval -   f1_macro: 0.8343956512970596\n",
            "09/17/2021 11:44:35 - INFO - farm.eval -   f1_micro: 0.872865275142315\n",
            "09/17/2021 11:44:35 - INFO - farm.eval -   mcc: 0.6688010278348098\n",
            "09/17/2021 11:44:35 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9154    0.9130    0.9142       391\n",
            "           1     0.7518    0.7574    0.7546       136\n",
            "\n",
            "    accuracy                         0.8729       527\n",
            "   macro avg     0.8336    0.8352    0.8344       527\n",
            "weighted avg     0.8732    0.8729    0.8730       527\n",
            "\n",
            "09/17/2021 11:44:35 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-1, eval=0.7545787545787545\n",
            "Train epoch 2/19 (Cur. train loss: 0.3260): 100%|██████████| 149/149 [03:43<00:00,  1.50s/it]\n",
            "Train epoch 3/19 (Cur. train loss: 0.0471):  36%|███▌      | 53/149 [01:10<02:03,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:46:57 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 500 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:46:57 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:46:58 - INFO - farm.eval -   loss: 0.47491638235168165\n",
            "09/17/2021 11:46:58 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:46:58 - INFO - farm.eval -   acc: 0.8785578747628083\n",
            "09/17/2021 11:46:58 - INFO - farm.eval -   f1_other: 0.9183673469387754\n",
            "09/17/2021 11:46:59 - INFO - farm.eval -   f1_offense: 0.7629629629629631\n",
            "09/17/2021 11:46:59 - INFO - farm.eval -   f1_macro: 0.8406651549508692\n",
            "09/17/2021 11:47:00 - INFO - farm.eval -   f1_micro: 0.8785578747628083\n",
            "09/17/2021 11:47:00 - INFO - farm.eval -   mcc: 0.6813701169079891\n",
            "09/17/2021 11:47:00 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9160    0.9207    0.9184       391\n",
            "           1     0.7687    0.7574    0.7630       136\n",
            "\n",
            "    accuracy                         0.8786       527\n",
            "   macro avg     0.8423    0.8390    0.8407       527\n",
            "weighted avg     0.8780    0.8786    0.8783       527\n",
            "\n",
            "09/17/2021 11:47:00 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-1, eval=0.7629629629629631\n",
            "Train epoch 3/19 (Cur. train loss: 0.1303): 100%|██████████| 149/149 [03:30<00:00,  1.41s/it]\n",
            "Train epoch 4/19 (Cur. train loss: 0.0098):   3%|▎         | 4/149 [00:05<03:05,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:49:22 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 600 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:49:22 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:49:23 - INFO - farm.eval -   loss: 0.47825082791598067\n",
            "09/17/2021 11:49:23 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:49:23 - INFO - farm.eval -   acc: 0.8918406072106262\n",
            "09/17/2021 11:49:23 - INFO - farm.eval -   f1_other: 0.926261319534282\n",
            "09/17/2021 11:49:24 - INFO - farm.eval -   f1_offense: 0.797153024911032\n",
            "09/17/2021 11:49:24 - INFO - farm.eval -   f1_macro: 0.861707172222657\n",
            "09/17/2021 11:49:25 - INFO - farm.eval -   f1_micro: 0.8918406072106262\n",
            "09/17/2021 11:49:25 - INFO - farm.eval -   mcc: 0.7242078627724613\n",
            "09/17/2021 11:49:25 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9372    0.9156    0.9263       391\n",
            "           1     0.7724    0.8235    0.7972       136\n",
            "\n",
            "    accuracy                         0.8918       527\n",
            "   macro avg     0.8548    0.8696    0.8617       527\n",
            "weighted avg     0.8947    0.8918    0.8929       527\n",
            "\n",
            "09/17/2021 11:49:25 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-1, eval=0.797153024911032\n",
            "Train epoch 4/19 (Cur. train loss: 0.0047):  70%|██████▉   | 104/149 [02:30<00:57,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:51:47 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 700 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:51:47 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:51:48 - INFO - farm.eval -   loss: 0.6305601827559932\n",
            "09/17/2021 11:51:48 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:51:48 - INFO - farm.eval -   acc: 0.8861480075901328\n",
            "09/17/2021 11:51:49 - INFO - farm.eval -   f1_other: 0.9242424242424242\n",
            "09/17/2021 11:51:49 - INFO - farm.eval -   f1_offense: 0.7709923664122137\n",
            "09/17/2021 11:51:50 - INFO - farm.eval -   f1_macro: 0.847617395327319\n",
            "09/17/2021 11:51:50 - INFO - farm.eval -   f1_micro: 0.8861480075901328\n",
            "09/17/2021 11:51:51 - INFO - farm.eval -   mcc: 0.6962795240700618\n",
            "09/17/2021 11:51:51 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9127    0.9361    0.9242       391\n",
            "           1     0.8016    0.7426    0.7710       136\n",
            "\n",
            "    accuracy                         0.8861       527\n",
            "   macro avg     0.8572    0.8394    0.8476       527\n",
            "weighted avg     0.8840    0.8861    0.8847       527\n",
            "\n",
            "Train epoch 4/19 (Cur. train loss: 0.0091): 100%|██████████| 149/149 [03:40<00:00,  1.48s/it]\n",
            "Train epoch 5/19 (Cur. train loss: 0.0025):  37%|███▋      | 55/149 [01:12<02:00,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:54:10 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 800 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:54:10 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:54:11 - INFO - farm.eval -   loss: 0.6145237937597894\n",
            "09/17/2021 11:54:11 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:54:11 - INFO - farm.eval -   acc: 0.8804554079696395\n",
            "09/17/2021 11:54:12 - INFO - farm.eval -   f1_other: 0.9187096774193548\n",
            "09/17/2021 11:54:12 - INFO - farm.eval -   f1_offense: 0.7741935483870968\n",
            "09/17/2021 11:54:13 - INFO - farm.eval -   f1_macro: 0.8464516129032258\n",
            "09/17/2021 11:54:13 - INFO - farm.eval -   f1_micro: 0.8804554079696395\n",
            "09/17/2021 11:54:14 - INFO - farm.eval -   mcc: 0.6933763872029368\n",
            "09/17/2021 11:54:14 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9271    0.9105    0.9187       391\n",
            "           1     0.7552    0.7941    0.7742       136\n",
            "\n",
            "    accuracy                         0.8805       527\n",
            "   macro avg     0.8412    0.8523    0.8465       527\n",
            "weighted avg     0.8827    0.8805    0.8814       527\n",
            "\n",
            "Train epoch 5/19 (Cur. train loss: 0.0030): 100%|██████████| 149/149 [03:28<00:00,  1.40s/it]\n",
            "Train epoch 6/19 (Cur. train loss: 0.0026):   4%|▍         | 6/149 [00:07<03:02,  1.27s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:56:33 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 900 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:56:33 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:56:34 - INFO - farm.eval -   loss: 0.6691760078100824\n",
            "09/17/2021 11:56:34 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:56:34 - INFO - farm.eval -   acc: 0.888045540796964\n",
            "09/17/2021 11:56:35 - INFO - farm.eval -   f1_other: 0.9250317662007624\n",
            "09/17/2021 11:56:35 - INFO - farm.eval -   f1_offense: 0.7790262172284643\n",
            "09/17/2021 11:56:36 - INFO - farm.eval -   f1_macro: 0.8520289917146133\n",
            "09/17/2021 11:56:36 - INFO - farm.eval -   f1_micro: 0.8880455407969639\n",
            "09/17/2021 11:56:37 - INFO - farm.eval -   mcc: 0.7043146771833868\n",
            "09/17/2021 11:56:37 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9192    0.9309    0.9250       391\n",
            "           1     0.7939    0.7647    0.7790       136\n",
            "\n",
            "    accuracy                         0.8880       527\n",
            "   macro avg     0.8565    0.8478    0.8520       527\n",
            "weighted avg     0.8869    0.8880    0.8874       527\n",
            "\n",
            "Train epoch 6/19 (Cur. train loss: 0.0026):  71%|███████   | 106/149 [02:31<00:55,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 11:58:57 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1000 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 11:58:57 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 11:58:58 - INFO - farm.eval -   loss: 0.6374484775640933\n",
            "09/17/2021 11:58:58 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 11:58:58 - INFO - farm.eval -   acc: 0.888045540796964\n",
            "09/17/2021 11:58:59 - INFO - farm.eval -   f1_other: 0.9238709677419354\n",
            "09/17/2021 11:58:59 - INFO - farm.eval -   f1_offense: 0.7885304659498207\n",
            "09/17/2021 11:59:00 - INFO - farm.eval -   f1_macro: 0.8562007168458781\n",
            "09/17/2021 11:59:00 - INFO - farm.eval -   f1_micro: 0.8880455407969639\n",
            "09/17/2021 11:59:00 - INFO - farm.eval -   mcc: 0.7128815305816039\n",
            "09/17/2021 11:59:00 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9323    0.9156    0.9239       391\n",
            "           1     0.7692    0.8088    0.7885       136\n",
            "\n",
            "    accuracy                         0.8880       527\n",
            "   macro avg     0.8508    0.8622    0.8562       527\n",
            "weighted avg     0.8902    0.8880    0.8889       527\n",
            "\n",
            "Train epoch 6/19 (Cur. train loss: 0.0016): 100%|██████████| 149/149 [03:39<00:00,  1.47s/it]\n",
            "Train epoch 7/19 (Cur. train loss: 0.0029):  38%|███▊      | 57/149 [01:15<01:57,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 12:01:20 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 12:01:20 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 12:01:20 - INFO - farm.eval -   loss: 0.7437116106728222\n",
            "09/17/2021 12:01:20 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 12:01:21 - INFO - farm.eval -   acc: 0.8861480075901328\n",
            "09/17/2021 12:01:21 - INFO - farm.eval -   f1_other: 0.9242424242424242\n",
            "09/17/2021 12:01:22 - INFO - farm.eval -   f1_offense: 0.7709923664122137\n",
            "09/17/2021 12:01:22 - INFO - farm.eval -   f1_macro: 0.847617395327319\n",
            "09/17/2021 12:01:23 - INFO - farm.eval -   f1_micro: 0.8861480075901328\n",
            "09/17/2021 12:01:23 - INFO - farm.eval -   mcc: 0.6962795240700618\n",
            "09/17/2021 12:01:23 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9127    0.9361    0.9242       391\n",
            "           1     0.8016    0.7426    0.7710       136\n",
            "\n",
            "    accuracy                         0.8861       527\n",
            "   macro avg     0.8572    0.8394    0.8476       527\n",
            "weighted avg     0.8840    0.8861    0.8847       527\n",
            "\n",
            "Train epoch 7/19 (Cur. train loss: 0.0014): 100%|██████████| 149/149 [03:28<00:00,  1.40s/it]\n",
            "Train epoch 8/19 (Cur. train loss: 0.0016):   5%|▌         | 8/149 [00:10<03:00,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 12:03:43 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 1200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 12:03:43 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 12:03:44 - INFO - farm.eval -   loss: 0.6685994448426552\n",
            "09/17/2021 12:03:44 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 12:03:44 - INFO - farm.eval -   acc: 0.8823529411764706\n",
            "09/17/2021 12:03:45 - INFO - farm.eval -   f1_other: 0.9194805194805195\n",
            "09/17/2021 12:03:45 - INFO - farm.eval -   f1_offense: 0.7816901408450704\n",
            "09/17/2021 12:03:46 - INFO - farm.eval -   f1_macro: 0.8505853301627949\n",
            "09/17/2021 12:03:46 - INFO - farm.eval -   f1_micro: 0.8823529411764706\n",
            "09/17/2021 12:03:46 - INFO - farm.eval -   mcc: 0.7025418255407738\n",
            "09/17/2021 12:03:46 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9340    0.9054    0.9195       391\n",
            "           1     0.7500    0.8162    0.7817       136\n",
            "\n",
            "    accuracy                         0.8824       527\n",
            "   macro avg     0.8420    0.8608    0.8506       527\n",
            "weighted avg     0.8865    0.8824    0.8839       527\n",
            "\n",
            "09/17/2021 12:03:46 - INFO - farm.train -   STOPPING EARLY AT EPOCH 8, STEP 8, EVALUATION 12\n",
            "Train epoch 8/19 (Cur. train loss: 0.0016):   5%|▌         | 8/149 [00:23<06:48,  2.90s/it]\n",
            "09/17/2021 12:03:46 - INFO - farm.train -   Restoring best model so far from saved_models/bert-doc-tutorial-es-1\n",
            "09/17/2021 12:03:49 - INFO - farm.modeling.adaptive_model -   Found files for loading 1 prediction heads\n",
            "09/17/2021 12:03:49 - WARNING - farm.modeling.prediction_head -   `layer_dims` will be deprecated in future releases\n",
            "09/17/2021 12:03:49 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/17/2021 12:03:49 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6810969114303589, 1.8804762363433838]\n",
            "09/17/2021 12:03:49 - INFO - farm.modeling.prediction_head -   Loading prediction head from saved_models/bert-doc-tutorial-es-1/prediction_head_0.bin\n",
            "09/17/2021 12:03:50 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='lm_name' was already logged with value='bert-base-uncased' for run ID='c9bad58b8082477fb09229a25f463ccd. Attempted logging new value 'saved_models/bert-doc-tutorial-es-1'.\n",
            "Evaluating: 100%|██████████| 42/42 [00:19<00:00,  2.16it/s]\n",
            "09/17/2021 12:04:10 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | FOLD: 1 | TEST SET | AFTER 42 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 12:04:10 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 12:04:10 - INFO - farm.eval -   loss: 0.47255903905239227\n",
            "09/17/2021 12:04:10 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 12:04:11 - INFO - farm.eval -   acc: 0.8984078847611827\n",
            "09/17/2021 12:04:11 - INFO - farm.eval -   f1_other: 0.9312820512820513\n",
            "09/17/2021 12:04:12 - INFO - farm.eval -   f1_offense: 0.805232558139535\n",
            "09/17/2021 12:04:12 - INFO - farm.eval -   f1_macro: 0.8682573047107931\n",
            "09/17/2021 12:04:12 - INFO - farm.eval -   f1_micro: 0.8984078847611827\n",
            "09/17/2021 12:04:13 - INFO - farm.eval -   mcc: 0.7366766533813193\n",
            "09/17/2021 12:04:13 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9265    0.9361    0.9313       970\n",
            "           1     0.8171    0.7937    0.8052       349\n",
            "\n",
            "    accuracy                         0.8984      1319\n",
            "   macro avg     0.8718    0.8649    0.8683      1319\n",
            "weighted avg     0.8976    0.8984    0.8979      1319\n",
            "\n",
            "09/17/2021 12:04:15 - INFO - __main__ -   ############ Crossvalidation: Fold 2 of 5 ############\n",
            "09/17/2021 12:04:15 - INFO - __main__ -   Fold training   samples: 4748\n",
            "09/17/2021 12:04:15 - INFO - __main__ -   Fold dev        samples: 527\n",
            "09/17/2021 12:04:15 - INFO - __main__ -   Fold testing    samples: 1319\n",
            "09/17/2021 12:04:15 - INFO - __main__ -   Total number of samples: 6594\n",
            "09/17/2021 12:04:18 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/17/2021 12:04:18 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/17/2021 12:04:18 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6810969 1.8804762]\n",
            "09/17/2021 12:04:19 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 5e-06}'\n",
            "09/17/2021 12:04:20 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/17/2021 12:04:20 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 298.0, 'num_training_steps': 2980}'\n",
            "09/17/2021 12:04:22 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/19 (Cur. train loss: 0.5350):  67%|██████▋   | 100/149 [02:15<01:04,  1.31s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 12:06:47 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 12:06:47 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 12:06:47 - INFO - farm.eval -   loss: 0.5294552989431305\n",
            "09/17/2021 12:06:47 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 12:06:48 - INFO - farm.eval -   acc: 0.8026565464895635\n",
            "09/17/2021 12:06:48 - INFO - farm.eval -   f1_other: 0.8602150537634408\n",
            "09/17/2021 12:06:49 - INFO - farm.eval -   f1_offense: 0.6645161290322581\n",
            "09/17/2021 12:06:49 - INFO - farm.eval -   f1_macro: 0.7623655913978494\n",
            "09/17/2021 12:06:50 - INFO - farm.eval -   f1_micro: 0.8026565464895635\n",
            "09/17/2021 12:06:50 - INFO - farm.eval -   mcc: 0.5488897114230235\n",
            "09/17/2021 12:06:50 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9302    0.8000    0.8602       400\n",
            "           1     0.5628    0.8110    0.6645       127\n",
            "\n",
            "    accuracy                         0.8027       527\n",
            "   macro avg     0.7465    0.8055    0.7624       527\n",
            "weighted avg     0.8417    0.8027    0.8131       527\n",
            "\n",
            "09/17/2021 12:06:50 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-2, eval=0.6645161290322581\n",
            "Train epoch 0/19 (Cur. train loss: 0.4202): 100%|██████████| 149/149 [03:33<00:00,  1.43s/it]\n",
            "Train epoch 1/19 (Cur. train loss: 0.4683):  34%|███▍      | 51/149 [01:08<02:06,  1.29s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 12:09:12 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 12:09:12 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 12:09:13 - INFO - farm.eval -   loss: 0.3505963980586072\n",
            "09/17/2021 12:09:13 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 12:09:13 - INFO - farm.eval -   acc: 0.8330170777988615\n",
            "09/17/2021 12:09:14 - INFO - farm.eval -   f1_other: 0.8839050131926122\n",
            "09/17/2021 12:09:14 - INFO - farm.eval -   f1_offense: 0.7027027027027027\n",
            "09/17/2021 12:09:15 - INFO - farm.eval -   f1_macro: 0.7933038579476575\n",
            "09/17/2021 12:09:15 - INFO - farm.eval -   f1_micro: 0.8330170777988615\n",
            "09/17/2021 12:09:16 - INFO - farm.eval -   mcc: 0.6014700407460885\n",
            "09/17/2021 12:09:16 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9358    0.8375    0.8839       400\n",
            "           1     0.6154    0.8189    0.7027       127\n",
            "\n",
            "    accuracy                         0.8330       527\n",
            "   macro avg     0.7756    0.8282    0.7933       527\n",
            "weighted avg     0.8585    0.8330    0.8402       527\n",
            "\n",
            "09/17/2021 12:09:16 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-2, eval=0.7027027027027027\n",
            "Train epoch 1/19 (Cur. train loss: 0.2662): 100%|██████████| 149/149 [03:30<00:00,  1.41s/it]\n",
            "Train epoch 2/19 (Cur. train loss: 0.2759):   1%|▏         | 2/149 [00:02<03:08,  1.28s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 12:11:38 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 300 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 12:11:38 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 12:11:38 - INFO - farm.eval -   loss: 0.3333580670365799\n",
            "09/17/2021 12:11:38 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 12:11:39 - INFO - farm.eval -   acc: 0.8690702087286527\n",
            "09/17/2021 12:11:39 - INFO - farm.eval -   f1_other: 0.9116517285531371\n",
            "09/17/2021 12:11:40 - INFO - farm.eval -   f1_offense: 0.7472527472527473\n",
            "09/17/2021 12:11:40 - INFO - farm.eval -   f1_macro: 0.8294522379029422\n",
            "09/17/2021 12:11:41 - INFO - farm.eval -   f1_micro: 0.8690702087286527\n",
            "09/17/2021 12:11:41 - INFO - farm.eval -   mcc: 0.6623993861482949\n",
            "09/17/2021 12:11:41 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9344    0.8900    0.9117       400\n",
            "           1     0.6986    0.8031    0.7473       127\n",
            "\n",
            "    accuracy                         0.8691       527\n",
            "   macro avg     0.8165    0.8466    0.8295       527\n",
            "weighted avg     0.8776    0.8691    0.8720       527\n",
            "\n",
            "09/17/2021 12:11:41 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-2, eval=0.7472527472527473\n",
            "Train epoch 2/19 (Cur. train loss: 0.2277):  68%|██████▊   | 102/149 [02:28<01:00,  1.30s/it]\n",
            "Evaluating: 100%|██████████| 17/17 [00:07<00:00,  2.19it/s]\n",
            "09/17/2021 12:14:04 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 400 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/17/2021 12:14:04 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/17/2021 12:14:05 - INFO - farm.eval -   loss: 0.3723042343780257\n",
            "09/17/2021 12:14:05 - INFO - farm.eval -   task_name: text_classification\n",
            "09/17/2021 12:14:05 - INFO - farm.eval -   acc: 0.8956356736242884\n",
            "09/17/2021 12:14:05 - INFO - farm.eval -   f1_other: 0.9313358302122346\n",
            "09/17/2021 12:14:06 - INFO - farm.eval -   f1_offense: 0.782608695652174\n",
            "09/17/2021 12:14:06 - INFO - farm.eval -   f1_macro: 0.8569722629322043\n",
            "09/17/2021 12:14:07 - INFO - farm.eval -   f1_micro: 0.8956356736242884\n",
            "09/17/2021 12:14:07 - INFO - farm.eval -   mcc: 0.7139555938051301\n",
            "09/17/2021 12:14:07 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9302    0.9325    0.9313       400\n",
            "           1     0.7857    0.7795    0.7826       127\n",
            "\n",
            "    accuracy                         0.8956       527\n",
            "   macro avg     0.8579    0.8560    0.8570       527\n",
            "weighted avg     0.8954    0.8956    0.8955       527\n",
            "\n",
            "09/17/2021 12:14:07 - INFO - farm.train -   Saving current best model to saved_models/bert-doc-tutorial-es-2, eval=0.782608695652174\n",
            "Train epoch 2/19 (Cur. train loss: 0.0750): 100%|██████████| 149/149 [03:43<00:00,  1.50s/it]\n",
            "Train epoch 3/19 (Cur. train loss: 0.0623):  34%|███▎      | 50/149 [01:06<02:08,  1.30s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZWmAfvMo5f6",
        "outputId": "0e0ec467-2251-443e-aa87-4797c2999a48"
      },
      "source": [
        "X_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3157,), (3157,))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nL8B9oqTg4f6"
      },
      "source": [
        "## RoBERTa <br>\n",
        "https://huggingface.co/roberta-base "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "4950f810cc3443f7aec3864b804ae314",
            "359d316353404a69babc3e8ee962121f",
            "4eb05ea7f28346e8bd04015843114a03",
            "8aeeb2a73d0840018f3c67491eec839f",
            "b649d3ccef0f4884bbb7b8dc7568685c",
            "444c735b9d044deab97a68f091ea59d4",
            "45d19caf311b4dcab0f4e7912de1103e",
            "2117200f5f0543cba63706287df23506",
            "316de909f6174ae0905b30f11ddb4e37",
            "fadf3411d6f34d078d08d4d94fb8b019",
            "0ec4a0a22667454bab85754ccd047f65",
            "5bbe6e5166e04e55bea73dc0b4d0c8b2",
            "bdf3752447a5492ab1b4d7aa69e34b6f",
            "0e5a3f794484409785ff99bca51c5641",
            "d4f96deb78ab488387b53d4a240a6c0a",
            "5ae9d962b77442c09c2112e73531c258",
            "4e7285357db74b8fb4666ae680110b37",
            "cd2356c2f6074faf9976870a94d8fdbd",
            "1f0f76ac520a43bb9a088176c9619957",
            "02702af4050644ce8b77c2a912acf916",
            "e0ab53b9dd8c40008314311b0783b8fe",
            "8a4d18ef8d39483ab3d9859403537607",
            "6ec0b57aeb674e2c8ba3fa98d5308e11",
            "64d72d59559749b991797817556417db",
            "179e0d583a9e467599091a311f394563",
            "cb9f3636a659460d8324360fe17da62d",
            "0ad6462262ca444a87d458172d3bd12b",
            "23ad46a3a7814db7bb1e3dfd1d6f8629",
            "261123e8c3b142b8bf2806dc73479cdf",
            "81a7ab9e096642d79ea304c52fb568f6",
            "71878b4d7618434f85a58608f070fdc9",
            "7e36e402b2bd4bd89b8a0b2807a11137",
            "e909645f869144d0956b42106edcbc60",
            "aef42849e58540af83f299cc692cc013",
            "f582181a9ed24c2a8e334e4c42e14370",
            "3d87f799341749f6af3762fed0a80388",
            "6902f84f878d4e8b8681c8693d0221cb",
            "a28aeab5d8314d0a8be9f2bdf5112590",
            "cdde26d446ca4386bddff5de2bf683a5",
            "d63603143e0648bc9e80837df005422b",
            "8bfeb3acdbd24694bd47d7a42c128634",
            "05819d037b48424d94cb0c39a8668e1b",
            "08da8df8dad7423bbb78cd6137078993",
            "a14c5a2fdd674aeca7aac36fd97d62e6"
          ]
        },
        "id": "0JUahj_Hg6NA",
        "outputId": "be03136d-fc0a-4c6d-eecf-423d9ec0f18c"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "# Here we initialize a tokenizer that will be used for preprocessing text\n",
        "# This is the BERT Tokenizer which uses the byte pair encoding method.\n",
        "# It is currently loaded with a German model\n",
        "\n",
        "#tokenizer = Tokenizer.load(\n",
        "#    pretrained_model_name_or_path=\"finiteautomata/bertweet-base-sentiment-analysis\",\n",
        "#    do_lower_case=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\")\n",
        "\n",
        "# In order to prepare the data for the model, we need a set of\n",
        "# functions to transform data files into PyTorch Datasets.\n",
        "# We group these together in Processor objects.\n",
        "# We will need a new Processor object for each new source of data.\n",
        "# The abstract class can be found in farm.data_handling.processor.Processor\n",
        "# TOXIC = 1\n",
        "# OTHER = 0\n",
        "LABEL_LIST = [\"0\", \"1\"]\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=128,\n",
        "                                        warmup = 600,\n",
        "                                        train_filename=\"train.tsv\",\n",
        "                                        dev_filename=\"test_with_solutions.tsv\",\n",
        "                                        test_filename=\"impermium_verification_labels.tsv\",\n",
        "                                        data_dir=\"../content\",\n",
        "                                        label_list=LABEL_LIST,\n",
        "                                        metric=\"f1_macro\",\n",
        "                                        text_column_name=\"Comment\",\n",
        "                                        label_column_name=\"Insult\")\n",
        "\n",
        "# We need a DataSilo in order to keep our train, dev and test sets separate.\n",
        "# The DataSilo will call the functions in the Processor to generate these sets.\n",
        "# From the DataSilo, we can fetch a PyTorch DataLoader object which will\n",
        "# be passed on to the model.\n",
        "# Here is a good place to define a batch size for the model\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "# The language model is the foundation on which modern NLP systems are built.\n",
        "# They encapsulate a general understanding of sentence semantics\n",
        "# and are not specific to any one task.\n",
        "\n",
        "# Here we are using Google's BERT model as implemented by HuggingFace. \n",
        "# The model being loaded is a German model that we trained. \n",
        "# You can also change the MODEL_NAME_OR_PATH to point to a BERT model that you\n",
        "# have saved or download one connected to the HuggingFace repository.\n",
        "# See farm.modeling.language_model.PRETRAINED_MODEL_ARCHIVE_MAP for a list of\n",
        "# available models\n",
        "\n",
        "MODEL_NAME_OR_PATH = \"roberta-base\"\n",
        "# MODEL_NAME_OR_PATH = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "language_model = LanguageModel.load(MODEL_NAME_OR_PATH)\n",
        "\n",
        "# A prediction head is a model that processes the output of the language model\n",
        "# for a specific task.\n",
        "# Prediction heads will look different depending on whether you're doing text classification\n",
        "# Named Entity Recognition (NER), question answering or some other task.\n",
        "# They should generate logits over the available prediction classes and contain methods\n",
        "# to convert these logits to losses or predictions \n",
        "\n",
        "# Here we use TextClassificationHead which receives a single fixed length sentence vector\n",
        "# and processes it using a feed forward neural network. layer_dims is a list of dimensions:\n",
        "# [input_dims, hidden_1_dims, hidden_2_dims ..., output_dims]\n",
        "\n",
        "# Here by default we have a single layer network.\n",
        "# It takes in a vector of length 768 (the default size of BERT's output).\n",
        "# It outputs a vector of length 2 (the number of classes in the GermEval18 (coarse) dataset)\n",
        "\n",
        "prediction_head = TextClassificationHead(num_labels=len(LABEL_LIST), class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"))\n",
        "\n",
        "# The language model and prediction head are coupled together in the Adaptive Model.\n",
        "# This class takes care of model saving and loading and also coordinates\n",
        "# cases where there is more than one prediction head.\n",
        "\n",
        "# EMBEDS_DROPOUT_PROB is the probability that an element of the output vector from the\n",
        "# language model will be set to zero.\n",
        "# EMBEDS_DROPOUT_PROB = 0.1 distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "# EMBEDS_DROPOUT_PROB = 0.01\n",
        "# EMBEDS_DROPOUT_PROB = 0.2 distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device)\n",
        "\n",
        "# Here we initialize a Bert Adam optimizer that has a linear warmup and warmdown\n",
        "# Here you can set learning rate, the warmup proportion and number of epochs to train for\n",
        "\n",
        "#LEARNING_RATE = 2e-5 # distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "#LEARNING_RATE = 1e-7\n",
        "LEARNING_RATE = 1e-5  # distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "\n",
        "N_EPOCHS = 3\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS)\n",
        "\n",
        "# Training loop handled by this\n",
        "# It will also trigger evaluation during training using the dev data\n",
        "# and after training using the test data.\n",
        "\n",
        "# Set N_GPU to a positive value if CUDA is available\n",
        "N_GPU = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device, \n",
        ")\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:25:36 - INFO - filelock -   Lock 139649219672016 acquired on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4950f810cc3443f7aec3864b804ae314",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:25:37 - INFO - filelock -   Lock 139649219672016 released on /root/.cache/torch/transformers/e1a2a406b5a05063c31f4dfdee7608986ba7c6393f7f79db5e69dcd197208534.117c81977c5979de8c088352e74ec6e70f5c66096c28b61d3c50101609b39690.lock\n",
            "09/16/2021 10:25:37 - INFO - filelock -   Lock 139649218496720 acquired on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5bbe6e5166e04e55bea73dc0b4d0c8b2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:25:38 - INFO - filelock -   Lock 139649218496720 released on /root/.cache/torch/transformers/d0c5776499adc1ded22493fae699da0971c1ee4c2587111707a4d177d20257a2.ef00af9e673c7160b4d41cfda1f48c5f4cba57d5142754525572a846a1ab1b9b.lock\n",
            "09/16/2021 10:25:38 - INFO - filelock -   Lock 139649522597264 acquired on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6ec0b57aeb674e2c8ba3fa98d5308e11",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:25:39 - INFO - filelock -   Lock 139649522597264 released on /root/.cache/torch/transformers/b35e7cd126cd4229a746b5d5c29a749e8e84438b14bcdb575950584fe33207e8.70bec105b4158ed9a1747fea67a43f5dee97855c64d62b6ec3742f4cfdb5feda.lock\n",
            "09/16/2021 10:25:39 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='tokenizer' was already logged with value='BertTokenizer' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value 'RobertaTokenizer'.\n",
            "09/16/2021 10:25:39 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "09/16/2021 10:25:39 - INFO - farm.data_handler.data_silo -   Loading train set from: ../content/train.tsv \n",
            "09/16/2021 10:25:39 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 3947 dictionaries to pytorch datasets (chunksize = 790)...\n",
            "09/16/2021 10:25:39 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:25:39 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:25:39 - INFO - farm.data_handler.data_silo -   / \\\n",
            "09/16/2021 10:25:39 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/train.tsv:   0%|          | 0/3947 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:25:42 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:25:42 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 319-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"The thing that keep the world from nuclear was was the understanding that a nuclear war could not be won.\\\\xc2\\\\xa0 Even if one side was able to blow up the majority of weapons on the other side, the other side would still have enough to blow the other side up.\\\\xc2\\\\xa0 There is a point that one can reduce the number of weapons to where nuclear war can be won by one side.\\\\xc2\\\\xa0 I dont know exactly where the line is but if we cut too far, we actually could be creating a world far more dangerous than one with each side having 10000 warheads. \"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'The', 'Ġthing', 'Ġthat', 'Ġkeep', 'Ġthe', 'Ġworld', 'Ġfrom', 'Ġnuclear', 'Ġwas', 'Ġwas', 'Ġthe', 'Ġunderstanding', 'Ġthat', 'Ġa', 'Ġnuclear', 'Ġwar', 'Ġcould', 'Ġnot', 'Ġbe', 'Ġwon', '.', '\\\\\\\\', 'xc', '2', '\\\\\\\\', 'xa', '0', 'ĠEven', 'Ġif', 'Ġone', 'Ġside', 'Ġwas', 'Ġable', 'Ġto', 'Ġblow', 'Ġup', 'Ġthe', 'Ġmajority', 'Ġof', 'Ġweapons', 'Ġon', 'Ġthe', 'Ġother', 'Ġside', ',', 'Ġthe', 'Ġother', 'Ġside', 'Ġwould', 'Ġstill', 'Ġhave', 'Ġenough', 'Ġto', 'Ġblow', 'Ġthe', 'Ġother', 'Ġside', 'Ġup', '.', '\\\\\\\\', 'xc', '2', '\\\\\\\\', 'xa', '0', 'ĠThere', 'Ġis', 'Ġa', 'Ġpoint', 'Ġthat', 'Ġone', 'Ġcan', 'Ġreduce', 'Ġthe', 'Ġnumber', 'Ġof', 'Ġweapons', 'Ġto', 'Ġwhere', 'Ġnuclear', 'Ġwar', 'Ġcan', 'Ġbe', 'Ġwon', 'Ġby', 'Ġone', 'Ġside', '.', '\\\\\\\\', 'xc', '2', '\\\\\\\\', 'xa', '0', 'ĠI', 'Ġdont', 'Ġknow', 'Ġexactly', 'Ġwhere', 'Ġthe', 'Ġline', 'Ġis', 'Ġbut', 'Ġif', 'Ġwe', 'Ġcut', 'Ġtoo', 'Ġfar', ',', 'Ġwe', 'Ġactually', 'Ġcould', 'Ġbe', 'Ġcreating', 'Ġa', 'Ġworld', 'Ġfar', 'Ġmore', 'Ġdangerous', 'Ġthan', 'Ġone', 'Ġwith', 'Ġeach', 'Ġside', 'Ġhaving']\n",
            " \toffsets: [0, 1, 5, 11, 16, 21, 25, 31, 36, 44, 48, 52, 56, 70, 75, 77, 85, 89, 95, 99, 102, 105, 106, 108, 110, 111, 113, 115, 117, 122, 125, 129, 134, 138, 143, 146, 151, 154, 158, 167, 170, 178, 181, 185, 191, 195, 197, 201, 207, 212, 218, 224, 229, 236, 239, 244, 248, 254, 259, 261, 262, 264, 266, 267, 269, 271, 273, 279, 282, 284, 290, 295, 299, 303, 310, 314, 321, 324, 332, 335, 341, 349, 353, 357, 360, 364, 367, 371, 375, 376, 378, 380, 381, 383, 385, 387, 389, 394, 399, 407, 413, 417, 422, 425, 429, 432, 435, 439, 443, 446, 448, 451, 460, 466, 469, 478, 480, 486, 490, 495, 505, 510, 514, 519, 524, 529]\n",
            " \tstart_of_word: [True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True]\n",
            "Features: \n",
            " \tinput_ids: [0, 113, 133, 631, 14, 489, 5, 232, 31, 1748, 21, 21, 5, 2969, 14, 10, 1748, 997, 115, 45, 28, 351, 4, 48669, 45421, 176, 48669, 43409, 288, 1648, 114, 65, 526, 21, 441, 7, 4627, 62, 5, 1647, 9, 2398, 15, 5, 97, 526, 6, 5, 97, 526, 74, 202, 33, 615, 7, 4627, 5, 97, 526, 62, 4, 48669, 45421, 176, 48669, 43409, 288, 345, 16, 10, 477, 14, 65, 64, 1888, 5, 346, 9, 2398, 7, 147, 1748, 997, 64, 28, 351, 30, 65, 526, 4, 48669, 45421, 176, 48669, 43409, 288, 38, 33976, 216, 2230, 147, 5, 516, 16, 53, 114, 52, 847, 350, 444, 6, 52, 888, 115, 28, 2351, 10, 232, 444, 55, 2702, 87, 65, 19, 349, 526, 519, 2]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:25:42 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 684-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"Mane she stupid as fuck thinking everybody pose be nice to her fat out of shape ass they go hard at beyonce why would people not diss  her fat ass\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'M', 'ane', 'Ġshe', 'Ġstupid', 'Ġas', 'Ġfuck', 'Ġthinking', 'Ġeverybody', 'Ġpose', 'Ġbe', 'Ġnice', 'Ġto', 'Ġher', 'Ġfat', 'Ġout', 'Ġof', 'Ġshape', 'Ġass', 'Ġthey', 'Ġgo', 'Ġhard', 'Ġat', 'Ġbe', 'yon', 'ce', 'Ġwhy', 'Ġwould', 'Ġpeople', 'Ġnot', 'Ġdiss', 'Ġher', 'Ġfat', 'Ġass', '\"']\n",
            " \toffsets: [0, 1, 2, 6, 10, 17, 20, 25, 34, 44, 49, 52, 57, 60, 64, 68, 72, 75, 81, 85, 90, 93, 98, 101, 103, 106, 109, 113, 119, 126, 130, 136, 140, 144, 147]\n",
            " \tstart_of_word: [True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True, True, True, True, True, False]\n",
            "Features: \n",
            " \tinput_ids: [0, 113, 448, 1728, 79, 12103, 25, 26536, 2053, 3370, 7277, 28, 2579, 7, 69, 5886, 66, 9, 3989, 8446, 51, 213, 543, 23, 28, 21743, 1755, 596, 74, 82, 45, 14863, 69, 5886, 8446, 113, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/train.tsv: 100%|██████████| 3947/3947 [00:15<00:00, 250.39 Dicts/s]\n",
            "09/16/2021 10:25:55 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n",
            "09/16/2021 10:25:55 - INFO - farm.data_handler.data_silo -   Took 787 samples out of train set to create dev set (dev split is roughly 0.1)\n",
            "09/16/2021 10:25:55 - INFO - farm.data_handler.data_silo -   Loading test set from: ../content/test_with_solutions.tsv\n",
            "09/16/2021 10:25:55 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2647 dictionaries to pytorch datasets (chunksize = 530)...\n",
            "09/16/2021 10:25:55 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:25:55 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:25:55 - INFO - farm.data_handler.data_silo -   / \\\n",
            "09/16/2021 10:25:55 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv:   0%|          | 0/2647 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:25:59 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:25:59 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 331-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"You'll be bloody miserable though!\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'You', \"'ll\", 'Ġbe', 'Ġbloody', 'Ġmiserable', 'Ġthough', '!\"']\n",
            " \toffsets: [0, 1, 4, 8, 11, 18, 28, 34]\n",
            " \tstart_of_word: [True, False, False, True, True, True, True, False]\n",
            "Features: \n",
            " \tinput_ids: [0, 113, 1185, 581, 28, 13629, 20161, 600, 2901, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:25:59 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 280-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"Guest I have been reading your post for a while,are you a female?\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'Guest', 'ĠI', 'Ġhave', 'Ġbeen', 'Ġreading', 'Ġyour', 'Ġpost', 'Ġfor', 'Ġa', 'Ġwhile', ',', 'are', 'Ġyou', 'Ġa', 'Ġfemale', '?\"']\n",
            " \toffsets: [0, 1, 7, 9, 14, 19, 27, 32, 37, 41, 43, 48, 49, 53, 57, 59, 65]\n",
            " \tstart_of_word: [True, False, True, True, True, True, True, True, True, True, True, False, False, True, True, True, False]\n",
            "Features: \n",
            " \tinput_ids: [0, 113, 45721, 38, 33, 57, 2600, 110, 618, 13, 10, 150, 6, 1322, 47, 10, 2182, 1917, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv: 100%|██████████| 2647/2647 [00:11<00:00, 222.94 Dicts/s]\n",
            "09/16/2021 10:26:07 - INFO - farm.data_handler.data_silo -   Examples in train: 3160\n",
            "09/16/2021 10:26:07 - INFO - farm.data_handler.data_silo -   Examples in dev  : 787\n",
            "09/16/2021 10:26:07 - INFO - farm.data_handler.data_silo -   Examples in test : 2647\n",
            "09/16/2021 10:26:07 - INFO - farm.data_handler.data_silo -   \n",
            "09/16/2021 10:26:08 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
            "09/16/2021 10:26:08 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 42.16012658227848\n",
            "09/16/2021 10:26:08 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.07088607594936709\n",
            "09/16/2021 10:26:08 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='n_samples_train' was already logged with value='3947' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '3160'.\n",
            "09/16/2021 10:26:08 - INFO - filelock -   Lock 139649147428560 acquired on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "aef42849e58540af83f299cc692cc013",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:26:25 - INFO - filelock -   Lock 139649147428560 released on /root/.cache/torch/transformers/80b4a484eddeb259bec2f06a6f2f05d90934111628e0e1c09a33bd4a121358e1.49b88ba7ec2c26a7558dda98ca3884c3b80fa31cf43a1b1f23aef3ff81ba344e.lock\n",
            "09/16/2021 10:26:28 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/16/2021 10:26:28 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/16/2021 10:26:28 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.67650837 1.9163636 ]\n",
            "09/16/2021 10:26:28 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='lm_type' was already logged with value='Bert' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value 'Roberta'.\n",
            "09/16/2021 10:26:28 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='num_train_optimization_steps' was already logged with value='372' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '297'.\n",
            "09/16/2021 10:26:28 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
            "09/16/2021 10:26:28 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/16/2021 10:26:28 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 29.700000000000003, 'num_training_steps': 297}'\n",
            "09/16/2021 10:26:28 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='num_warmup_steps' was already logged with value='37.2' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '29.700000000000003'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 16 10:26:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   58C    P0    61W / 149W |   6429MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:26:29 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/2 (Cur. train loss: 0.4021): 100%|██████████| 99/99 [02:05<00:00,  1.27s/it]\n",
            "Train epoch 1/2 (Cur. train loss: 0.2414):   1%|          | 1/99 [00:01<02:01,  1.24s/it]\n",
            "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 25/25 [00:10<00:00,  2.29it/s]\n",
            "09/16/2021 10:28:48 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:28:48 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:28:48 - INFO - farm.eval -   loss: 0.37340200083682923\n",
            "09/16/2021 10:28:48 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:28:48 - INFO - farm.eval -   f1_macro: 0.8294176962294912\n",
            "09/16/2021 10:28:48 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9273    0.8630    0.8940       562\n",
            "           1     0.7083    0.8311    0.7648       225\n",
            "\n",
            "    accuracy                         0.8539       787\n",
            "   macro avg     0.8178    0.8471    0.8294       787\n",
            "weighted avg     0.8647    0.8539    0.8571       787\n",
            "\n",
            "Train epoch 1/2 (Cur. train loss: 0.4249): 100%|██████████| 99/99 [02:14<00:00,  1.36s/it]\n",
            "Train epoch 2/2 (Cur. train loss: 0.1718):   2%|▏         | 2/99 [00:02<01:59,  1.23s/it]\n",
            "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 25/25 [00:10<00:00,  2.30it/s]\n",
            "09/16/2021 10:31:03 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:31:03 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:31:03 - INFO - farm.eval -   loss: 0.35854773812251595\n",
            "09/16/2021 10:31:03 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:31:03 - INFO - farm.eval -   f1_macro: 0.8439673309426328\n",
            "09/16/2021 10:31:03 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9242    0.8897    0.9066       562\n",
            "           1     0.7480    0.8178    0.7813       225\n",
            "\n",
            "    accuracy                         0.8691       787\n",
            "   macro avg     0.8361    0.8537    0.8440       787\n",
            "weighted avg     0.8738    0.8691    0.8708       787\n",
            "\n",
            "Train epoch 2/2 (Cur. train loss: 0.3376): 100%|██████████| 99/99 [02:13<00:00,  1.35s/it]\n",
            "Evaluating: 100%|██████████| 83/83 [00:36<00:00,  2.27it/s]\n",
            "09/16/2021 10:33:39 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 297 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:33:39 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:33:39 - INFO - farm.eval -   loss: 0.41176522656301306\n",
            "09/16/2021 10:33:39 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:33:39 - INFO - farm.eval -   f1_macro: 0.8542402993271805\n",
            "09/16/2021 10:33:39 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9315    0.9115    0.9214      1954\n",
            "           1     0.7646    0.8110    0.7871       693\n",
            "\n",
            "    accuracy                         0.8852      2647\n",
            "   macro avg     0.8481    0.8612    0.8542      2647\n",
            "weighted avg     0.8878    0.8852    0.8862      2647\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXbVD_NEhqZ-"
      },
      "source": [
        "## ALBERT <br>\n",
        "https://huggingface.co/albert-base-v2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "cac347724a8d46d3ab01c099b10797d8",
            "1d43b82458924221bdb278b6c8241d4c",
            "e2c155a6ffa94f4fb2d4be86b72230ec",
            "de6dbda986d94875895db63f49ac7781",
            "23740a4966a24caf8a66827a9fe29510",
            "91b4ac4f53034f07bdf3f5a69d0c6dbd",
            "0a3a855ce8ff46d093fcfdb2ba3325a6",
            "d5a5390d39a347d3980f1a09f80cba19",
            "1d7b07cc2c114fcdb69ce24bc1273dc8",
            "a5b8873f60304ef288bad933e46a6e58",
            "786516831dd64420b685b3100393c8f7",
            "88bcdd4ef93648719ee6abff7ea75268",
            "201301b151394e2aa96f8b692b085955",
            "b6bbde1da38e42279125ee459b8f969c",
            "480aa1092c064c00ba1a4d5bc1e30f07",
            "b072b0fc5ebc421fbe1437e68506d02f",
            "cbbc22c9ba764724af6c2647c2918635",
            "e9ad53b659144594a9aee7d831b47140",
            "527334f00e1d4b79afc65ddd3b61c3f7",
            "c52d85b64a024712a9b4f311d351892b",
            "a02d24898b0645798a9ff8d684222889",
            "4c2a1de7722b410fbf205c48333c25b1",
            "c4f8f89f624a44138aac17569e5fe592",
            "78c5935ff6414d23ac8d8823b1db18f1",
            "68a4942929d1443994db197cc206f813",
            "9a713a114f8d4f56ba882ec4e59bcdab",
            "a645f44068404c8caf46c40da1382a52",
            "78bc8b44153f4845900a50203bf3daaf",
            "5a72b8368d24445cbab255cc3537b187",
            "636e649439b840da9d58d89020b58932",
            "79b4547356e84ff4a75726886cdec7e8",
            "956e9145036b478fb0f8250551325363",
            "43e48c5929cb40e482455b59f4fe9d41"
          ]
        },
        "id": "9Eder9_RhtEA",
        "outputId": "d850f932-f9f8-41f2-d244-c8213459a0c4"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "# Here we initialize a tokenizer that will be used for preprocessing text\n",
        "# This is the BERT Tokenizer which uses the byte pair encoding method.\n",
        "# It is currently loaded with a German model\n",
        "\n",
        "#tokenizer = Tokenizer.load(\n",
        "#    pretrained_model_name_or_path=\"finiteautomata/bertweet-base-sentiment-analysis\",\n",
        "#    do_lower_case=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"albert-base-v2\")\n",
        "\n",
        "# In order to prepare the data for the model, we need a set of\n",
        "# functions to transform data files into PyTorch Datasets.\n",
        "# We group these together in Processor objects.\n",
        "# We will need a new Processor object for each new source of data.\n",
        "# The abstract class can be found in farm.data_handling.processor.Processor\n",
        "# TOXIC = 1\n",
        "# OTHER = 0\n",
        "LABEL_LIST = [\"0\", \"1\"]\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=128,\n",
        "                                        warmup = 600,\n",
        "                                        train_filename=\"train.tsv\",\n",
        "                                        dev_filename=\"test_with_solutions.tsv\",\n",
        "                                        test_filename=\"impermium_verification_labels.tsv\",\n",
        "                                        data_dir=\"../content\",\n",
        "                                        label_list=LABEL_LIST,\n",
        "                                        metric=\"f1_macro\",\n",
        "                                        text_column_name=\"Comment\",\n",
        "                                        label_column_name=\"Insult\")\n",
        "\n",
        "# We need a DataSilo in order to keep our train, dev and test sets separate.\n",
        "# The DataSilo will call the functions in the Processor to generate these sets.\n",
        "# From the DataSilo, we can fetch a PyTorch DataLoader object which will\n",
        "# be passed on to the model.\n",
        "# Here is a good place to define a batch size for the model\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "# The language model is the foundation on which modern NLP systems are built.\n",
        "# They encapsulate a general understanding of sentence semantics\n",
        "# and are not specific to any one task.\n",
        "\n",
        "# Here we are using Google's BERT model as implemented by HuggingFace. \n",
        "# The model being loaded is a German model that we trained. \n",
        "# You can also change the MODEL_NAME_OR_PATH to point to a BERT model that you\n",
        "# have saved or download one connected to the HuggingFace repository.\n",
        "# See farm.modeling.language_model.PRETRAINED_MODEL_ARCHIVE_MAP for a list of\n",
        "# available models\n",
        "\n",
        "MODEL_NAME_OR_PATH = \"albert-base-v2\"\n",
        "# MODEL_NAME_OR_PATH = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "language_model = LanguageModel.load(MODEL_NAME_OR_PATH)\n",
        "\n",
        "# A prediction head is a model that processes the output of the language model\n",
        "# for a specific task.\n",
        "# Prediction heads will look different depending on whether you're doing text classification\n",
        "# Named Entity Recognition (NER), question answering or some other task.\n",
        "# They should generate logits over the available prediction classes and contain methods\n",
        "# to convert these logits to losses or predictions \n",
        "\n",
        "# Here we use TextClassificationHead which receives a single fixed length sentence vector\n",
        "# and processes it using a feed forward neural network. layer_dims is a list of dimensions:\n",
        "# [input_dims, hidden_1_dims, hidden_2_dims ..., output_dims]\n",
        "\n",
        "# Here by default we have a single layer network.\n",
        "# It takes in a vector of length 768 (the default size of BERT's output).\n",
        "# It outputs a vector of length 2 (the number of classes in the GermEval18 (coarse) dataset)\n",
        "\n",
        "prediction_head = TextClassificationHead(num_labels=len(LABEL_LIST), class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"))\n",
        "\n",
        "# The language model and prediction head are coupled together in the Adaptive Model.\n",
        "# This class takes care of model saving and loading and also coordinates\n",
        "# cases where there is more than one prediction head.\n",
        "\n",
        "# EMBEDS_DROPOUT_PROB is the probability that an element of the output vector from the\n",
        "# language model will be set to zero.\n",
        "# EMBEDS_DROPOUT_PROB = 0.1 distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "# EMBEDS_DROPOUT_PROB = 0.01\n",
        "# EMBEDS_DROPOUT_PROB = 0.2 distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device)\n",
        "\n",
        "# Here we initialize a Bert Adam optimizer that has a linear warmup and warmdown\n",
        "# Here you can set learning rate, the warmup proportion and number of epochs to train for\n",
        "\n",
        "#LEARNING_RATE = 2e-5 # distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "#LEARNING_RATE = 1e-7\n",
        "LEARNING_RATE = 1e-5  # distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "\n",
        "N_EPOCHS = 3\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS)\n",
        "\n",
        "# Training loop handled by this\n",
        "# It will also trigger evaluation during training using the dev data\n",
        "# and after training using the test data.\n",
        "\n",
        "# Set N_GPU to a positive value if CUDA is available\n",
        "N_GPU = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device, \n",
        ")\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:33:39 - INFO - filelock -   Lock 139649145630416 acquired on /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cac347724a8d46d3ab01c099b10797d8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:33:40 - INFO - filelock -   Lock 139649145630416 released on /root/.cache/torch/transformers/0bbb1531ce82f042a813219ffeed7a1fa1f44cd8f78a652c47fc5311e0d40231.978ff53dd976bbf4bc66f09bf4205da0542be753d025263787842df74d15bbca.lock\n",
            "09/16/2021 10:33:40 - INFO - filelock -   Lock 139649145661200 acquired on /root/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88bcdd4ef93648719ee6abff7ea75268",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:33:41 - INFO - filelock -   Lock 139649145661200 released on /root/.cache/torch/transformers/dd1588b85b6fdce1320e224d29ad062e97588e17326b9d05a0b29ee84b8f5f93.c81d4deb77aec08ce575b7a39a989a79dd54f321bfb82c2b54dd35f52f8182cf.lock\n",
            "09/16/2021 10:33:41 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='tokenizer' was already logged with value='BertTokenizer' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value 'AlbertTokenizer'.\n",
            "09/16/2021 10:33:41 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "09/16/2021 10:33:41 - INFO - farm.data_handler.data_silo -   Loading train set from: ../content/train.tsv \n",
            "09/16/2021 10:33:41 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 3947 dictionaries to pytorch datasets (chunksize = 790)...\n",
            "09/16/2021 10:33:41 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:33:41 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:33:41 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/16/2021 10:33:41 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/train.tsv:   0%|          | 0/3947 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:33:44 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:33:44 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 677-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"SHOLAAMEOBI ' WHAT PLANET DO YOU LIVE ON YOU NEED TO GET DOWN TO SPECSAVERS ARE YOU BLIND OR STUPID?\"\n",
            "Tokenized: \n",
            " \ttokens: ['▁', '\"', 'sh', 'ola', 'ame', 'obi', '▁', \"'\", '▁what', '▁planet', '▁do', '▁you', '▁live', '▁on', '▁you', '▁need', '▁to', '▁get', '▁down', '▁to', '▁spec', 's', 'aver', 's', '▁are', '▁you', '▁blind', '▁or', '▁stupid', '?', '\"']\n",
            " \toffsets: [0, 0, 1, 3, 6, 9, 13, 13, 15, 20, 27, 30, 34, 39, 42, 46, 51, 54, 58, 63, 66, 70, 71, 75, 77, 81, 85, 91, 94, 100, 101]\n",
            " \tstart_of_word: [True, False, False, False, False, False, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, False, True, True, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [2, 13, 7, 1635, 2268, 8357, 14398, 13, 22, 98, 3027, 107, 42, 515, 27, 42, 376, 20, 164, 125, 20, 12737, 18, 11937, 18, 50, 42, 4631, 54, 3553, 60, 7, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:33:44 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 271-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"LMAO. Do people who hate gays and lesbians really think protesting will get us to stop having kids and being a family?? You serious?? Its funny how everyone quotes the bible but it also says DIVORCE is a sin, BEING A DRUNKARD is a sin, BEING A BASTARD is a sin, CHEATING IS A SIN. Have you idiots not read the 10 commandments?? Those are ALL ABOMINATIONS! You anti-gay homophobes are so ignorant. Karma is a bitch. You just wait and see, haters.\"\n",
            "Tokenized: \n",
            " \ttokens: ['▁', '\"', 'lma', 'o', '.', '▁do', '▁people', '▁who', '▁hate', '▁gay', 's', '▁and', '▁lesbian', 's', '▁really', '▁think', '▁protesting', '▁will', '▁get', '▁us', '▁to', '▁stop', '▁having', '▁kids', '▁and', '▁being', '▁a', '▁family', '?', '?', '▁you', '▁serious', '?', '?', '▁its', '▁funny', '▁how', '▁everyone', '▁quotes', '▁the', '▁bible', '▁but', '▁it', '▁also', '▁says', '▁divorce', '▁is', '▁a', '▁sin', ',', '▁being', '▁a', '▁drunk', 'ard', '▁is', '▁a', '▁sin', ',', '▁being', '▁a', '▁bastard', '▁is', '▁a', '▁sin', ',', '▁cheating', '▁is', '▁a', '▁sin', '.', '▁have', '▁you', '▁idiot', 's', '▁not', '▁read', '▁the', '▁10', '▁command', 'ments', '?', '?', '▁those', '▁are', '▁all', '▁a', 'bo', 'mination', 's', '!', '▁you', '▁anti', '-', 'gay', '▁homo', 'pho', 'bes', '▁are', '▁so', '▁ignorant', '.', '▁karma', '▁is', '▁a', '▁bitch', '.', '▁you', '▁just', '▁wait', '▁and', '▁see', ',', '▁hat', 'ers', '.', '\"']\n",
            " \toffsets: [0, 0, 1, 4, 5, 7, 10, 17, 21, 26, 29, 31, 35, 42, 44, 51, 57, 68, 73, 77, 80, 83, 88, 95, 100, 104, 110, 112, 118, 119, 121, 125, 132, 133, 135, 139, 145, 149, 158, 165, 169, 175, 179, 182, 187, 192, 200, 203, 205, 208, 210, 216, 218, 223, 227, 230, 232, 235, 237, 243, 245, 253, 256, 258, 261, 263, 272, 275, 277, 280, 282, 287, 291, 296, 298, 302, 307, 311, 314, 321, 326, 327, 329, 335, 339, 343, 344, 346, 354, 355, 357, 361, 365, 366, 370, 374, 377, 381, 385, 388, 396, 398, 404, 407, 409, 414, 416, 420, 425, 430, 434, 437, 439, 442, 445, 446]\n",
            " \tstart_of_word: [True, False, False, False, False, True, True, True, True, True, False, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, False, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, False, True, True, True, True, True, False, False, False, True, True, True, True, False, False, False, False, True, True, False, False, True, False, False, True, True, True, False, True, True, True, True, False, True, True, True, True, True, False, True, False, False, False]\n",
            "Features: \n",
            " \tinput_ids: [2, 13, 7, 19073, 111, 9, 107, 148, 72, 3223, 3398, 18, 17, 10564, 18, 510, 277, 23604, 129, 164, 182, 20, 747, 452, 2627, 17, 142, 21, 190, 60, 60, 42, 2055, 60, 60, 82, 5066, 184, 1266, 18901, 14, 5095, 47, 32, 67, 898, 7366, 25, 21, 3278, 15, 142, 21, 5922, 1514, 25, 21, 3278, 15, 142, 21, 6862, 25, 21, 3278, 15, 20091, 25, 21, 3278, 9, 57, 42, 8563, 18, 52, 1302, 14, 332, 1202, 6601, 60, 60, 273, 50, 65, 21, 1192, 15971, 18, 187, 42, 1082, 8, 19710, 9131, 9906, 11296, 50, 86, 24096, 9, 19486, 25, 21, 6643, 9, 42, 114, 1760, 17, 196, 15, 2970, 445, 9, 7, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/train.tsv: 100%|██████████| 3947/3947 [00:08<00:00, 450.74 Dicts/s]\n",
            "09/16/2021 10:33:50 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n",
            "09/16/2021 10:33:50 - INFO - farm.data_handler.data_silo -   Took 787 samples out of train set to create dev set (dev split is roughly 0.1)\n",
            "09/16/2021 10:33:50 - INFO - farm.data_handler.data_silo -   Loading test set from: ../content/test_with_solutions.tsv\n",
            "09/16/2021 10:33:50 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2647 dictionaries to pytorch datasets (chunksize = 530)...\n",
            "09/16/2021 10:33:50 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:33:50 - INFO - farm.data_handler.data_silo -   /|\\\n",
            "09/16/2021 10:33:50 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/16/2021 10:33:50 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv:   0%|          | 0/2647 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:33:52 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:33:52 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 13-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"Thank you.  Unfortunately on this kindle I'm limited on how far back I can go.\"\n",
            "Tokenized: \n",
            " \ttokens: ['▁', '\"', 'thank', '▁you', '.', '▁unfortunately', '▁on', '▁this', '▁kind', 'le', '▁i', \"'\", 'm', '▁limited', '▁on', '▁how', '▁far', '▁back', '▁i', '▁can', '▁go', '.', '\"']\n",
            " \toffsets: [0, 0, 1, 7, 10, 13, 27, 30, 35, 39, 42, 43, 44, 46, 54, 57, 61, 65, 70, 72, 76, 78, 79]\n",
            " \tstart_of_word: [True, False, False, True, False, True, True, True, True, False, True, False, False, True, True, True, True, True, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [2, 13, 7, 5904, 42, 9, 6200, 27, 48, 825, 413, 31, 22, 79, 1317, 27, 184, 463, 97, 31, 92, 162, 9, 7, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:33:52 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 64-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"Bad as I dislike Obama I wouldn't wish this puke on his kids\"\n",
            "Tokenized: \n",
            " \ttokens: ['▁', '\"', 'bad', '▁as', '▁i', '▁dislike', '▁obama', '▁i', '▁wouldn', \"'\", 't', '▁wish', '▁this', '▁pu', 'ke', '▁on', '▁his', '▁kids', '\"']\n",
            " \toffsets: [0, 0, 1, 5, 8, 10, 18, 24, 26, 32, 33, 35, 40, 45, 47, 50, 53, 57, 61]\n",
            " \tstart_of_word: [True, False, False, True, True, True, True, True, True, False, False, True, True, True, False, True, True, True, False]\n",
            "Features: \n",
            " \tinput_ids: [2, 13, 7, 5989, 28, 31, 18686, 7677, 31, 1265, 22, 38, 2536, 48, 3323, 1048, 27, 33, 2627, 7, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv: 100%|██████████| 2647/2647 [00:06<00:00, 384.36 Dicts/s]\n",
            "09/16/2021 10:33:57 - INFO - farm.data_handler.data_silo -   Examples in train: 3160\n",
            "09/16/2021 10:33:57 - INFO - farm.data_handler.data_silo -   Examples in dev  : 787\n",
            "09/16/2021 10:33:57 - INFO - farm.data_handler.data_silo -   Examples in test : 2647\n",
            "09/16/2021 10:33:57 - INFO - farm.data_handler.data_silo -   \n",
            "09/16/2021 10:33:57 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
            "09/16/2021 10:33:57 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 44.88354430379747\n",
            "09/16/2021 10:33:57 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.07784810126582278\n",
            "09/16/2021 10:33:57 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='n_samples_train' was already logged with value='3947' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '3160'.\n",
            "09/16/2021 10:33:59 - INFO - filelock -   Lock 139649522373072 acquired on /root/.cache/torch/transformers/c7c1b2b621933bfa9a5f6ed18b1d6dc2f445001779b13d37286a806117ebeb10.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c4f8f89f624a44138aac17569e5fe592",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:34:02 - INFO - filelock -   Lock 139649522373072 released on /root/.cache/torch/transformers/c7c1b2b621933bfa9a5f6ed18b1d6dc2f445001779b13d37286a806117ebeb10.ab806923413c2af99835e13fdbb6014b24af86b0de8edc2d71ef5c646fc54f24.lock\n",
            "09/16/2021 10:34:02 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/16/2021 10:34:02 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/16/2021 10:34:02 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6791237 1.8956834]\n",
            "09/16/2021 10:34:02 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='lm_type' was already logged with value='Bert' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value 'Albert'.\n",
            "09/16/2021 10:34:02 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='num_train_optimization_steps' was already logged with value='372' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '297'.\n",
            "09/16/2021 10:34:02 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
            "09/16/2021 10:34:03 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/16/2021 10:34:03 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 29.700000000000003, 'num_training_steps': 297}'\n",
            "09/16/2021 10:34:03 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='num_warmup_steps' was already logged with value='37.2' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '29.700000000000003'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 16 10:34:03 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   53C    P0    60W / 149W |   7021MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:34:03 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/2 (Cur. train loss: 0.4100): 100%|██████████| 99/99 [02:08<00:00,  1.30s/it]\n",
            "Train epoch 1/2 (Cur. train loss: 0.4458):   1%|          | 1/99 [00:01<02:07,  1.30s/it]\n",
            "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 25/25 [00:12<00:00,  2.02it/s]\n",
            "09/16/2021 10:36:27 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:36:27 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:36:27 - INFO - farm.eval -   loss: 0.41548606916182834\n",
            "09/16/2021 10:36:27 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:36:27 - INFO - farm.eval -   f1_macro: 0.7338409112368134\n",
            "09/16/2021 10:36:27 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9583    0.6848    0.7988       571\n",
            "           1     0.5251    0.9213    0.6689       216\n",
            "\n",
            "    accuracy                         0.7497       787\n",
            "   macro avg     0.7417    0.8030    0.7338       787\n",
            "weighted avg     0.8394    0.7497    0.7631       787\n",
            "\n",
            "Train epoch 1/2 (Cur. train loss: 0.3100): 100%|██████████| 99/99 [02:21<00:00,  1.43s/it]\n",
            "Train epoch 2/2 (Cur. train loss: 0.3466):   2%|▏         | 2/99 [00:02<02:04,  1.29s/it]\n",
            "Evaluating:   0%|          | 0/25 [00:00<?, ?it/s]\u001b[A\n",
            "Evaluating: 100%|██████████| 25/25 [00:12<00:00,  2.02it/s]\n",
            "09/16/2021 10:38:50 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:38:50 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:38:50 - INFO - farm.eval -   loss: 0.38038646644679536\n",
            "09/16/2021 10:38:50 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:38:50 - INFO - farm.eval -   f1_macro: 0.8275189398052809\n",
            "09/16/2021 10:38:50 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9167    0.8862    0.9012       571\n",
            "           1     0.7234    0.7870    0.7539       216\n",
            "\n",
            "    accuracy                         0.8590       787\n",
            "   macro avg     0.8200    0.8366    0.8275       787\n",
            "weighted avg     0.8636    0.8590    0.8607       787\n",
            "\n",
            "Train epoch 2/2 (Cur. train loss: 0.2001): 100%|██████████| 99/99 [02:21<00:00,  1.43s/it]\n",
            "Evaluating: 100%|██████████| 83/83 [00:41<00:00,  2.00it/s]\n",
            "09/16/2021 10:41:36 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 297 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:41:36 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:41:36 - INFO - farm.eval -   loss: 0.4081311820361314\n",
            "09/16/2021 10:41:36 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:41:36 - INFO - farm.eval -   f1_macro: 0.8357836206349298\n",
            "09/16/2021 10:41:36 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9232    0.8987    0.9108      1954\n",
            "           1     0.7342    0.7893    0.7608       693\n",
            "\n",
            "    accuracy                         0.8700      2647\n",
            "   macro avg     0.8287    0.8440    0.8358      2647\n",
            "weighted avg     0.8738    0.8700    0.8715      2647\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NoF8lgzEimL6"
      },
      "source": [
        "## DistilBERT <br>\n",
        "https://huggingface.co/distilbert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "d0f760ebcc9444df80201dc5a29a6cae",
            "f55ae31f277b42ee938c6e561db1dd7a",
            "460832ea307643ddb43542f199831ce8",
            "411fb158675247338153ab208f5a1e92",
            "b06e1e6ab24d48138781830efec40478",
            "c4e75c92688942c48e492d77e13e6f67",
            "575844d0cf84470c847435720ff06e62",
            "f95b1349a41d44a5bf629f78b9cf0cb0",
            "493734283b314c0dbf016ddd15b25c04",
            "f94097a322c84cf18a2cb47f97b5c01f",
            "4900b2b2906d4a91aff9e9e6ea4b57e5",
            "91e916586f77476084dc4fdc6c66bc62",
            "30176b44a609422fbe42214b602cc983",
            "35dd7a3645634f6397ac6505bc64fe89",
            "405215c0ff564a39a5303baedacc9322",
            "6776cbb6f02e4ba180701c66252b2737",
            "8d099074d3e2491ab1f95c6ce79fc6a2",
            "2c73370b8e5b4317b6734dfe678a6574",
            "e84866fe3d3645d4aa104d4578c8867c",
            "124b8f50fc2d422f8c76ad5413277b8b",
            "99b737b71e6f4d9a93d932f8a40da266",
            "6c00e7738c2b4828a9d526892f3e371e"
          ]
        },
        "id": "MKfscV12ikAD",
        "outputId": "33acb995-1dab-47eb-dabc-f745dbd9f79b"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "# Here we initialize a tokenizer that will be used for preprocessing text\n",
        "# This is the BERT Tokenizer which uses the byte pair encoding method.\n",
        "# It is currently loaded with a German model\n",
        "\n",
        "#tokenizer = Tokenizer.load(\n",
        "#    pretrained_model_name_or_path=\"finiteautomata/bertweet-base-sentiment-analysis\",\n",
        "#    do_lower_case=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# In order to prepare the data for the model, we need a set of\n",
        "# functions to transform data files into PyTorch Datasets.\n",
        "# We group these together in Processor objects.\n",
        "# We will need a new Processor object for each new source of data.\n",
        "# The abstract class can be found in farm.data_handling.processor.Processor\n",
        "# TOXIC = 1\n",
        "# OTHER = 0\n",
        "LABEL_LIST = [\"0\", \"1\"]\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=128,\n",
        "                                        warmup = 600,\n",
        "                                        train_filename=\"train.tsv\",\n",
        "                                        dev_filename=\"test_with_solutions.tsv\",\n",
        "                                        test_filename=\"impermium_verification_labels.tsv\",\n",
        "                                        data_dir=\"../content\",\n",
        "                                        label_list=LABEL_LIST,\n",
        "                                        metric=\"f1_macro\",\n",
        "                                        text_column_name=\"Comment\",\n",
        "                                        label_column_name=\"Insult\")\n",
        "\n",
        "# We need a DataSilo in order to keep our train, dev and test sets separate.\n",
        "# The DataSilo will call the functions in the Processor to generate these sets.\n",
        "# From the DataSilo, we can fetch a PyTorch DataLoader object which will\n",
        "# be passed on to the model.\n",
        "# Here is a good place to define a batch size for the model\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "# The language model is the foundation on which modern NLP systems are built.\n",
        "# They encapsulate a general understanding of sentence semantics\n",
        "# and are not specific to any one task.\n",
        "\n",
        "# Here we are using Google's BERT model as implemented by HuggingFace. \n",
        "# The model being loaded is a German model that we trained. \n",
        "# You can also change the MODEL_NAME_OR_PATH to point to a BERT model that you\n",
        "# have saved or download one connected to the HuggingFace repository.\n",
        "# See farm.modeling.language_model.PRETRAINED_MODEL_ARCHIVE_MAP for a list of\n",
        "# available models\n",
        "\n",
        "MODEL_NAME_OR_PATH = \"distilbert-base-uncased\"\n",
        "# MODEL_NAME_OR_PATH = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "language_model = LanguageModel.load(MODEL_NAME_OR_PATH)\n",
        "\n",
        "# A prediction head is a model that processes the output of the language model\n",
        "# for a specific task.\n",
        "# Prediction heads will look different depending on whether you're doing text classification\n",
        "# Named Entity Recognition (NER), question answering or some other task.\n",
        "# They should generate logits over the available prediction classes and contain methods\n",
        "# to convert these logits to losses or predictions \n",
        "\n",
        "# Here we use TextClassificationHead which receives a single fixed length sentence vector\n",
        "# and processes it using a feed forward neural network. layer_dims is a list of dimensions:\n",
        "# [input_dims, hidden_1_dims, hidden_2_dims ..., output_dims]\n",
        "\n",
        "# Here by default we have a single layer network.\n",
        "# It takes in a vector of length 768 (the default size of BERT's output).\n",
        "# It outputs a vector of length 2 (the number of classes in the GermEval18 (coarse) dataset)\n",
        "\n",
        "prediction_head = TextClassificationHead(num_labels=len(LABEL_LIST), class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"))\n",
        "\n",
        "# The language model and prediction head are coupled together in the Adaptive Model.\n",
        "# This class takes care of model saving and loading and also coordinates\n",
        "# cases where there is more than one prediction head.\n",
        "\n",
        "# EMBEDS_DROPOUT_PROB is the probability that an element of the output vector from the\n",
        "# language model will be set to zero.\n",
        "# EMBEDS_DROPOUT_PROB = 0.1 distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "# EMBEDS_DROPOUT_PROB = 0.01\n",
        "# EMBEDS_DROPOUT_PROB = 0.2 distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device)\n",
        "\n",
        "# Here we initialize a Bert Adam optimizer that has a linear warmup and warmdown\n",
        "# Here you can set learning rate, the warmup proportion and number of epochs to train for\n",
        "\n",
        "#LEARNING_RATE = 2e-5 # distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "#LEARNING_RATE = 1e-7\n",
        "LEARNING_RATE = 1e-5  # distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "\n",
        "N_EPOCHS = 3\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS)\n",
        "\n",
        "# Training loop handled by this\n",
        "# It will also trigger evaluation during training using the dev data\n",
        "# and after training using the test data.\n",
        "\n",
        "# Set N_GPU to a positive value if CUDA is available\n",
        "N_GPU = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device, \n",
        ")\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:41:37 - INFO - filelock -   Lock 139649146410704 acquired on /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d0f760ebcc9444df80201dc5a29a6cae",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/442 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:41:37 - INFO - filelock -   Lock 139649146410704 released on /root/.cache/torch/transformers/a41e817d5c0743e29e86ff85edc8c257e61bc8d88e4271bb1b243b6e7614c633.8949e27aafafa845a18d98a0e3a88bc2d248bbc32a1b75947366664658f23b1c.lock\n",
            "09/16/2021 10:41:38 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='tokenizer' was already logged with value='BertTokenizer' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value 'DistilBertTokenizer'.\n",
            "09/16/2021 10:41:38 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "09/16/2021 10:41:38 - INFO - farm.data_handler.data_silo -   Loading train set from: ../content/train.tsv \n",
            "09/16/2021 10:41:38 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 3947 dictionaries to pytorch datasets (chunksize = 790)...\n",
            "09/16/2021 10:41:38 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:41:38 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:41:38 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/16/2021 10:41:38 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/train.tsv:   0%|          | 0/3947 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:41:41 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:41:41 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 103-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"And the last day is upon us. Will I be the lucky one? Doubt it, but it's still a sexy piece of hardware!\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'and', 'the', 'last', 'day', 'is', 'upon', 'us', '.', 'will', 'i', 'be', 'the', 'lucky', 'one', '?', 'doubt', 'it', ',', 'but', 'it', \"'\", 's', 'still', 'a', 'sexy', 'piece', 'of', 'hardware', '!', '\"']\n",
            " \toffsets: [0, 1, 5, 9, 14, 18, 21, 26, 28, 30, 35, 37, 40, 44, 50, 53, 55, 61, 63, 65, 69, 71, 72, 74, 80, 82, 87, 93, 96, 104, 105]\n",
            " \tstart_of_word: [True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, False, True, True, False, False, True, True, True, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 1998, 1996, 2197, 2154, 2003, 2588, 2149, 1012, 2097, 1045, 2022, 1996, 5341, 2028, 1029, 4797, 2009, 1010, 2021, 2009, 1005, 1055, 2145, 1037, 7916, 3538, 1997, 8051, 999, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:41:41 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 703-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"Let me educate you. You don't go vote for the nominee that is a 0 vote.A\\xa0Obama supporter\\xa0votes for Obama.Plus one for Obama.\\nNow if you vote for the nominee it washes that plus one out to 0.\\nSee how easy that was.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'let', 'me', 'educate', 'you', '.', 'you', 'don', \"'\", 't', 'go', 'vote', 'for', 'the', 'nominee', 'that', 'is', 'a', '0', 'vote', '.', 'a', '\\\\', 'x', '##a', '##0', '##ob', '##ama', 'supporter', '\\\\', 'x', '##a', '##0', '##vot', '##es', 'for', 'obama', '.', 'plus', 'one', 'for', 'obama', '.', '\\\\', 'n', '##now', 'if', 'you', 'vote', 'for', 'the', 'nominee', 'it', 'wash', '##es', 'that', 'plus', 'one', 'out', 'to', '0', '.', '\\\\', 'ns', '##ee', 'how', 'easy', 'that', 'was', '.', '\"']\n",
            " \toffsets: [0, 1, 5, 8, 16, 19, 21, 25, 28, 29, 31, 34, 39, 43, 47, 55, 60, 63, 65, 67, 71, 72, 73, 74, 75, 76, 77, 79, 83, 92, 93, 94, 95, 96, 99, 102, 106, 111, 112, 117, 121, 125, 130, 131, 132, 133, 137, 140, 144, 149, 153, 157, 165, 168, 172, 175, 180, 185, 189, 193, 196, 197, 198, 199, 201, 204, 208, 213, 218, 221, 222]\n",
            " \tstart_of_word: [True, False, True, True, True, False, True, True, False, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, False, False, False, True, False, False, False, False, False, False, True, True, False, False, True, True, True, False, False, False, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, False, False, False, True, True, True, True, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 2292, 2033, 16957, 2017, 1012, 2017, 2123, 1005, 1056, 2175, 3789, 2005, 1996, 9773, 2008, 2003, 1037, 1014, 3789, 1012, 1037, 1032, 1060, 2050, 2692, 16429, 8067, 10129, 1032, 1060, 2050, 2692, 22994, 2229, 2005, 8112, 1012, 4606, 2028, 2005, 8112, 1012, 1032, 1050, 19779, 2065, 2017, 3789, 2005, 1996, 9773, 2009, 9378, 2229, 2008, 4606, 2028, 2041, 2000, 1014, 1012, 1032, 24978, 4402, 2129, 3733, 2008, 2001, 1012, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/train.tsv: 100%|██████████| 3947/3947 [00:14<00:00, 281.01 Dicts/s]\n",
            "09/16/2021 10:41:52 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n",
            "09/16/2021 10:41:52 - INFO - farm.data_handler.data_silo -   Took 787 samples out of train set to create dev set (dev split is roughly 0.1)\n",
            "09/16/2021 10:41:52 - INFO - farm.data_handler.data_silo -   Loading test set from: ../content/test_with_solutions.tsv\n",
            "09/16/2021 10:41:52 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2647 dictionaries to pytorch datasets (chunksize = 530)...\n",
            "09/16/2021 10:41:52 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/16/2021 10:41:52 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/16/2021 10:41:52 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/16/2021 10:41:52 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv:   0%|          | 0/2647 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/16/2021 10:41:56 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/16/2021 10:41:56 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 56-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"I'll let you know when I start worrying about an invertebrate's opinion of me.\\n:-)\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'i', \"'\", 'll', 'let', 'you', 'know', 'when', 'i', 'start', 'worrying', 'about', 'an', 'in', '##vert', '##eb', '##rate', \"'\", 's', 'opinion', 'of', 'me', '.', '\\\\', 'n', ':', '-', ')', '\"']\n",
            " \toffsets: [0, 1, 2, 3, 6, 10, 14, 19, 24, 26, 32, 41, 47, 50, 52, 56, 58, 62, 63, 65, 73, 76, 78, 79, 80, 81, 82, 83, 84]\n",
            " \tstart_of_word: [True, False, False, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, False, True, True, True, False, False, False, False, False, False, False]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 1045, 1005, 2222, 2292, 2017, 2113, 2043, 1045, 2707, 15366, 2055, 2019, 1999, 16874, 15878, 11657, 1005, 1055, 5448, 1997, 2033, 1012, 1032, 1050, 1024, 1011, 1007, 1000, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/16/2021 10:41:56 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 147-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"By your reply, you did not learn much in the Navy. He is our commander-in-chief. My brothers served in vietnam, my bio dad and adopted dad in WWII, they came from all sides of the political spectrum and they respected the president. Did they agree with him always? NO, but they respected the office. We hear all the time that the vet fought for our freedom. Part of the freedom is to elect our president and other officials. Aparently you didn't learn about that in the Navy. At least this President is trying to get benefits for our vets, something the republican party is all for cutting, so they can buy the next obsolete toy for the DOD.\"\n",
            "Tokenized: \n",
            " \ttokens: ['\"', 'by', 'your', 'reply', ',', 'you', 'did', 'not', 'learn', 'much', 'in', 'the', 'navy', '.', 'he', 'is', 'our', 'commander', '-', 'in', '-', 'chief', '.', 'my', 'brothers', 'served', 'in', 'vietnam', ',', 'my', 'bio', 'dad', 'and', 'adopted', 'dad', 'in', 'wwii', ',', 'they', 'came', 'from', 'all', 'sides', 'of', 'the', 'political', 'spectrum', 'and', 'they', 'respected', 'the', 'president', '.', 'did', 'they', 'agree', 'with', 'him', 'always', '?', 'no', ',', 'but', 'they', 'respected', 'the', 'office', '.', 'we', 'hear', 'all', 'the', 'time', 'that', 'the', 'vet', 'fought', 'for', 'our', 'freedom', '.', 'part', 'of', 'the', 'freedom', 'is', 'to', 'elect', 'our', 'president', 'and', 'other', 'officials', '.', 'ap', '##are', '##ntly', 'you', 'didn', \"'\", 't', 'learn', 'about', 'that', 'in', 'the', 'navy', '.', 'at', 'least', 'this', 'president', 'is', 'trying', 'to', 'get', 'benefits', 'for', 'our', 'vet', '##s', ',', 'something', 'the', 'republican', 'party']\n",
            " \toffsets: [0, 1, 4, 9, 14, 16, 20, 24, 28, 34, 39, 42, 46, 50, 52, 55, 58, 62, 71, 72, 74, 75, 80, 82, 85, 94, 101, 104, 111, 113, 116, 120, 124, 128, 136, 140, 143, 147, 149, 154, 159, 164, 168, 174, 177, 181, 191, 200, 204, 209, 219, 223, 232, 234, 238, 243, 249, 254, 258, 264, 266, 268, 270, 274, 279, 289, 293, 299, 301, 304, 309, 313, 317, 322, 327, 331, 335, 342, 346, 350, 357, 359, 364, 367, 371, 379, 382, 385, 391, 395, 405, 409, 415, 424, 426, 428, 431, 436, 440, 444, 445, 447, 453, 459, 464, 467, 471, 475, 477, 480, 486, 491, 501, 504, 511, 514, 518, 527, 531, 535, 538, 539, 541, 551, 555, 566]\n",
            " \tstart_of_word: [True, False, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, False, False, False, False, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, False, False, True, True, False, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, False, True, True, True, True]\n",
            "Features: \n",
            " \tinput_ids: [101, 1000, 2011, 2115, 7514, 1010, 2017, 2106, 2025, 4553, 2172, 1999, 1996, 3212, 1012, 2002, 2003, 2256, 3474, 1011, 1999, 1011, 2708, 1012, 2026, 3428, 2366, 1999, 5148, 1010, 2026, 16012, 3611, 1998, 4233, 3611, 1999, 25755, 1010, 2027, 2234, 2013, 2035, 3903, 1997, 1996, 2576, 8674, 1998, 2027, 9768, 1996, 2343, 1012, 2106, 2027, 5993, 2007, 2032, 2467, 1029, 2053, 1010, 2021, 2027, 9768, 1996, 2436, 1012, 2057, 2963, 2035, 1996, 2051, 2008, 1996, 29525, 4061, 2005, 2256, 4071, 1012, 2112, 1997, 1996, 4071, 2003, 2000, 11322, 2256, 2343, 1998, 2060, 4584, 1012, 9706, 12069, 20630, 2017, 2134, 1005, 1056, 4553, 2055, 2008, 1999, 1996, 3212, 1012, 2012, 2560, 2023, 2343, 2003, 2667, 2000, 2131, 6666, 2005, 2256, 29525, 2015, 1010, 2242, 1996, 3951, 2283, 102]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv: 100%|██████████| 2647/2647 [00:10<00:00, 245.57 Dicts/s]\n",
            "09/16/2021 10:42:03 - INFO - farm.data_handler.data_silo -   Examples in train: 3160\n",
            "09/16/2021 10:42:03 - INFO - farm.data_handler.data_silo -   Examples in dev  : 787\n",
            "09/16/2021 10:42:03 - INFO - farm.data_handler.data_silo -   Examples in test : 2647\n",
            "09/16/2021 10:42:03 - INFO - farm.data_handler.data_silo -   \n",
            "09/16/2021 10:42:03 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
            "09/16/2021 10:42:03 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 44.74367088607595\n",
            "09/16/2021 10:42:03 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.0819620253164557\n",
            "09/16/2021 10:42:03 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='n_samples_train' was already logged with value='3947' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '3160'.\n",
            "09/16/2021 10:42:04 - INFO - filelock -   Lock 139649522998864 acquired on /root/.cache/torch/transformers/ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5.lock\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91e916586f77476084dc4fdc6c66bc62",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:42:13 - INFO - filelock -   Lock 139649522998864 released on /root/.cache/torch/transformers/ae9df7a8d658c4f3e1917a471a8a21cf678fa1d4cb91e7702dfe0598dbdcf354.c2015533705b9dff680ae707e205a35e2860e8d148b45d35085419d74fe57ac5.lock\n",
            "09/16/2021 10:42:14 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/16/2021 10:42:14 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/16/2021 10:42:14 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.68979055 1.8172414 ]\n",
            "09/16/2021 10:42:14 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='lm_type' was already logged with value='Bert' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value 'DistilBert'.\n",
            "09/16/2021 10:42:15 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='num_train_optimization_steps' was already logged with value='372' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '297'.\n",
            "09/16/2021 10:42:15 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
            "09/16/2021 10:42:15 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/16/2021 10:42:15 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 29.700000000000003, 'num_training_steps': 297}'\n",
            "09/16/2021 10:42:15 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='num_warmup_steps' was already logged with value='37.2' for run ID='7d89c879a6e64f88951e0668f5c1804d. Attempted logging new value '29.700000000000003'.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Sep 16 10:42:15 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   51C    P0    60W / 149W |   7165MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/16/2021 10:42:15 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/2 (Cur. train loss: 0.5709): 100%|██████████| 99/99 [01:02<00:00,  1.57it/s]\n",
            "Train epoch 1/2 (Cur. train loss: 0.2287):   1%|          | 1/99 [00:00<01:21,  1.21it/s]\n",
            "Evaluating: 100%|██████████| 25/25 [00:05<00:00,  4.58it/s]\n",
            "09/16/2021 10:43:25 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 100 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:43:25 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:43:25 - INFO - farm.eval -   loss: 0.31710278094193534\n",
            "09/16/2021 10:43:25 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:43:26 - INFO - farm.eval -   f1_macro: 0.8051780247912428\n",
            "09/16/2021 10:43:26 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9566    0.8353    0.8918       607\n",
            "           1     0.6109    0.8722    0.7185       180\n",
            "\n",
            "    accuracy                         0.8437       787\n",
            "   macro avg     0.7837    0.8537    0.8052       787\n",
            "weighted avg     0.8775    0.8437    0.8522       787\n",
            "\n",
            "Train epoch 1/2 (Cur. train loss: 0.2422): 100%|██████████| 99/99 [01:08<00:00,  1.45it/s]\n",
            "Train epoch 2/2 (Cur. train loss: 0.1211):   2%|▏         | 2/99 [00:01<01:00,  1.61it/s]\n",
            "Evaluating: 100%|██████████| 25/25 [00:05<00:00,  4.57it/s]\n",
            "09/16/2021 10:44:34 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | DEV SET | AFTER 200 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:44:34 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:44:34 - INFO - farm.eval -   loss: 0.34318773083038523\n",
            "09/16/2021 10:44:34 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:44:34 - INFO - farm.eval -   f1_macro: 0.8062635469015497\n",
            "09/16/2021 10:44:34 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9601    0.8320    0.8914       607\n",
            "           1     0.6092    0.8833    0.7211       180\n",
            "\n",
            "    accuracy                         0.8437       787\n",
            "   macro avg     0.7846    0.8576    0.8063       787\n",
            "weighted avg     0.8798    0.8437    0.8525       787\n",
            "\n",
            "Train epoch 2/2 (Cur. train loss: 0.1693): 100%|██████████| 99/99 [01:08<00:00,  1.45it/s]\n",
            "Evaluating: 100%|██████████| 83/83 [00:18<00:00,  4.52it/s]\n",
            "09/16/2021 10:45:53 - INFO - farm.eval -   \n",
            "\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "***************************************************\n",
            "***** EVALUATION | TEST SET | AFTER 297 BATCHES *****\n",
            "***************************************************\n",
            "\\\\|//       \\\\|//      \\\\|//       \\\\|//     \\\\|//\n",
            "^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "\n",
            "09/16/2021 10:45:53 - INFO - farm.eval -   \n",
            " _________ text_classification _________\n",
            "09/16/2021 10:45:53 - INFO - farm.eval -   loss: 0.42968257778673563\n",
            "09/16/2021 10:45:53 - INFO - farm.eval -   task_name: text_classification\n",
            "09/16/2021 10:45:53 - INFO - farm.eval -   f1_macro: 0.8465720206348171\n",
            "09/16/2021 10:45:53 - INFO - farm.eval -   report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9234    0.9135    0.9184      1954\n",
            "           1     0.7633    0.7864    0.7747       693\n",
            "\n",
            "    accuracy                         0.8802      2647\n",
            "   macro avg     0.8434    0.8500    0.8466      2647\n",
            "weighted avg     0.8815    0.8802    0.8808      2647\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9mV4ecPEjyML"
      },
      "source": [
        "### Optimizing DistilBERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444,
          "referenced_widgets": [
            "54d8411d066440249716876c4b7ba478",
            "474864b66b2d4127a26d1029a5e414a5",
            "5147e3150eb84951ba338f447e7a86cb",
            "5f0c2f516d8e40daa2838efb1f2ee4d4",
            "e740d1d29f9a4ee2af1da224886163f8",
            "f723b0257d0a4c24a8c97fcbf6eba6f4",
            "773eb33aa4d249298921c5184cafd715",
            "fe61ff43a2f94ceea8607e044c8c4e49",
            "6be315a181e84f37b30d11ff17dc55b3",
            "f0ba1299e8aa4ff6bffd9a8a9d52bf30",
            "d1b15f28d2524856a2f299de860e5aa1",
            "db11a4bb6c60498695b2134cb7b5123b",
            "0044dea262cf49c6ac787aa04ea77534",
            "eb2558efba444fa5af5d3de729342621",
            "e64a0871df34452796f7e6b2d9573a1f",
            "c4aa63ad4b594090aac499014fde3171",
            "4f5f9112204348099026bd9808de275f",
            "ad402ec4ecf74732821481b402ba5227",
            "873041efa4fc4f909c393926a4f0bace",
            "86bcd3203fdf456ab8edb2d0a647b057",
            "2aebb694daf04a2e8fef6c6842aad212",
            "849b1f3c7a3c43688bcde12efadeb036"
          ]
        },
        "id": "goYK0s_Ej0pq",
        "outputId": "5c97f8d0-2286-4939-aa0d-a46cbb8b224e"
      },
      "source": [
        "from transformers import DistilBertForSequenceClassification, Trainer, TrainingArguments, AutoModelForMaskedLM\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',          # output directory\n",
        "    num_train_epochs=3,              # total number of training epochs\n",
        "    per_device_train_batch_size=16,  # batch size per device during training\n",
        "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
        "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
        "    weight_decay=0.01,               # strength of weight decay\n",
        "    logging_dir='./logs',            # directory for storing logs\n",
        "    logging_steps=10,\n",
        ")\n",
        "\n",
        "model = AutoModelForMaskedLM.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,                            # the instantiated 🤗 Transformers model to be trained\n",
        "    args=training_args,                     # training arguments, defined above\n",
        "    train_dataset=\"train.tsv\",              # training dataset\n",
        "    eval_dataset=\"test_with_solutions.tsv\"  # evaluation dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "54d8411d066440249716876c4b7ba478",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db11a4bb6c60498695b2134cb7b5123b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Iteration:   0%|          | 0/1 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-34b5fcdb2391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m )\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, model_path, trial)\u001b[0m\n\u001b[1;32m    753\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m             \u001b[0mepoch_pbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Iteration\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdisable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisable_tqdm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 755\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_iterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    756\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    757\u001b[0m                 \u001b[0;31m# Skip past any already trained steps if resuming training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m     \u001b[0;31m#           Even with carefully designed data dependencies (i.e., a `put()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m     \u001b[0;31m#           always corresponding to a `get()`), hanging on `get()` can still\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;31m#           happen when data in queue is corrupted (e.g., due to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m     \u001b[0;31m#           `cancel_join_thread` or unexpected exit).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;31m#           prevent this automatic join.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m     \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m     \u001b[0;31m#           Moreover, having all queues called `cancel_join_thread` makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m     \u001b[0;31m#           implementing graceful shutdown logic in `__del__` much easier.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;31m#           It won't need to get from any queue, which would also need to be\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36mdefault_data_collator\u001b[0;34m(features)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# on the whole batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/data/data_collator.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# on the whole batch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBatchEncoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mfeatures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mfirst\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: vars() argument must have __dict__ attribute"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiUubEaJiBus"
      },
      "source": [
        "## XLMRoBERTa <br>\n",
        "https://huggingface.co/xlm-roberta-base "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmM3w0uviEls",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 393
        },
        "outputId": "53ec4cc9-66cc-41f5-8c27-686798ecd3df"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "import torch\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "# Here we initialize a tokenizer that will be used for preprocessing text\n",
        "# This is the BERT Tokenizer which uses the byte pair encoding method.\n",
        "# It is currently loaded with a German model\n",
        "\n",
        "#tokenizer = Tokenizer.load(\n",
        "#    pretrained_model_name_or_path=\"finiteautomata/bertweet-base-sentiment-analysis\",\n",
        "#    do_lower_case=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
        "\n",
        "# In order to prepare the data for the model, we need a set of\n",
        "# functions to transform data files into PyTorch Datasets.\n",
        "# We group these together in Processor objects.\n",
        "# We will need a new Processor object for each new source of data.\n",
        "# The abstract class can be found in farm.data_handling.processor.Processor\n",
        "# TOXIC = 1\n",
        "# OTHER = 0\n",
        "LABEL_LIST = [\"0\", \"1\"]\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=128,\n",
        "                                        warmup = 600,\n",
        "                                        train_filename=\"train.tsv\",\n",
        "                                        dev_filename=\"test_with_solutions.tsv\",\n",
        "                                        test_filename=\"impermium_verification_labels.tsv\",\n",
        "                                        data_dir=\"../content\",\n",
        "                                        label_list=LABEL_LIST,\n",
        "                                        metric=\"f1_macro\",\n",
        "                                        text_column_name=\"Comment\",\n",
        "                                        label_column_name=\"Insult\")\n",
        "\n",
        "# We need a DataSilo in order to keep our train, dev and test sets separate.\n",
        "# The DataSilo will call the functions in the Processor to generate these sets.\n",
        "# From the DataSilo, we can fetch a PyTorch DataLoader object which will\n",
        "# be passed on to the model.\n",
        "# Here is a good place to define a batch size for the model\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "# The language model is the foundation on which modern NLP systems are built.\n",
        "# They encapsulate a general understanding of sentence semantics\n",
        "# and are not specific to any one task.\n",
        "\n",
        "# Here we are using Google's BERT model as implemented by HuggingFace. \n",
        "# The model being loaded is a German model that we trained. \n",
        "# You can also change the MODEL_NAME_OR_PATH to point to a BERT model that you\n",
        "# have saved or download one connected to the HuggingFace repository.\n",
        "# See farm.modeling.language_model.PRETRAINED_MODEL_ARCHIVE_MAP for a list of\n",
        "# available models\n",
        "\n",
        "MODEL_NAME_OR_PATH = \"xlm-roberta-base\"\n",
        "# MODEL_NAME_OR_PATH = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "language_model = LanguageModel.load(MODEL_NAME_OR_PATH)\n",
        "\n",
        "# A prediction head is a model that processes the output of the language model\n",
        "# for a specific task.\n",
        "# Prediction heads will look different depending on whether you're doing text classification\n",
        "# Named Entity Recognition (NER), question answering or some other task.\n",
        "# They should generate logits over the available prediction classes and contain methods\n",
        "# to convert these logits to losses or predictions \n",
        "\n",
        "# Here we use TextClassificationHead which receives a single fixed length sentence vector\n",
        "# and processes it using a feed forward neural network. layer_dims is a list of dimensions:\n",
        "# [input_dims, hidden_1_dims, hidden_2_dims ..., output_dims]\n",
        "\n",
        "# Here by default we have a single layer network.\n",
        "# It takes in a vector of length 768 (the default size of BERT's output).\n",
        "# It outputs a vector of length 2 (the number of classes in the GermEval18 (coarse) dataset)\n",
        "\n",
        "prediction_head = TextClassificationHead(num_labels=len(LABEL_LIST), class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"))\n",
        "\n",
        "# The language model and prediction head are coupled together in the Adaptive Model.\n",
        "# This class takes care of model saving and loading and also coordinates\n",
        "# cases where there is more than one prediction head.\n",
        "\n",
        "# EMBEDS_DROPOUT_PROB is the probability that an element of the output vector from the\n",
        "# language model will be set to zero.\n",
        "# EMBEDS_DROPOUT_PROB = 0.1 distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "# EMBEDS_DROPOUT_PROB = 0.01\n",
        "# EMBEDS_DROPOUT_PROB = 0.2 distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device)\n",
        "\n",
        "# Here we initialize a Bert Adam optimizer that has a linear warmup and warmdown\n",
        "# Here you can set learning rate, the warmup proportion and number of epochs to train for\n",
        "\n",
        "#LEARNING_RATE = 2e-5 # distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "#LEARNING_RATE = 1e-7\n",
        "LEARNING_RATE = 1e-5  # distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "\n",
        "N_EPOCHS = 3\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS)\n",
        "\n",
        "# Training loop handled by this\n",
        "# It will also trigger evaluation during training using the dev data\n",
        "# and after training using the test data.\n",
        "\n",
        "# Set N_GPU to a positive value if CUDA is available\n",
        "N_GPU = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device, \n",
        ")\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-fb848e442140>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenization\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessor\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextClassificationProcessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfarm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_silo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataSilo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cVnUyU9DhQo5"
      },
      "source": [
        "## XLNet Cased <br>\n",
        "https://huggingface.co/xlnet-base-cased "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "j9iM9t_hhQ5d",
        "outputId": "bf2f2d24-6ce8-42fd-8948-282e9c833fe3"
      },
      "source": [
        "import torch\n",
        "from farm.modeling.tokenization import Tokenizer\n",
        "from farm.data_handler.processor import TextClassificationProcessor\n",
        "from farm.data_handler.data_silo import DataSilo\n",
        "from farm.modeling.language_model import LanguageModel\n",
        "from farm.modeling.prediction_head import TextClassificationHead\n",
        "from farm.modeling.adaptive_model import AdaptiveModel\n",
        "from farm.modeling.optimization import initialize_optimizer\n",
        "from farm.train import Trainer\n",
        "from farm.utils import MLFlowLogger\n",
        "\n",
        "# Here we initialize a tokenizer that will be used for preprocessing text\n",
        "# This is the BERT Tokenizer which uses the byte pair encoding method.\n",
        "# It is currently loaded with a German model\n",
        "\n",
        "#tokenizer = Tokenizer.load(\n",
        "#    pretrained_model_name_or_path=\"finiteautomata/bertweet-base-sentiment-analysis\",\n",
        "#    do_lower_case=False)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"xlnet-base-cased\")\n",
        "\n",
        "# In order to prepare the data for the model, we need a set of\n",
        "# functions to transform data files into PyTorch Datasets.\n",
        "# We group these together in Processor objects.\n",
        "# We will need a new Processor object for each new source of data.\n",
        "# The abstract class can be found in farm.data_handling.processor.Processor\n",
        "# TOXIC = 1\n",
        "# OTHER = 0\n",
        "LABEL_LIST = [\"0\", \"1\"]\n",
        "processor = TextClassificationProcessor(tokenizer=tokenizer,\n",
        "                                        max_seq_len=128,\n",
        "                                        warmup = 600,\n",
        "                                        train_filename=\"train.tsv\",\n",
        "                                        test_filename=\"test_with_solutions.tsv\",\n",
        "                                        data_dir=\"../content\",\n",
        "                                        label_list=LABEL_LIST,\n",
        "                                        metric=\"f1_macro\",\n",
        "                                        text_column_name=\"Comment\",\n",
        "                                        label_column_name=\"Insult\")\n",
        "\n",
        "# We need a DataSilo in order to keep our train, dev and test sets separate.\n",
        "# The DataSilo will call the functions in the Processor to generate these sets.\n",
        "# From the DataSilo, we can fetch a PyTorch DataLoader object which will\n",
        "# be passed on to the model.\n",
        "# Here is a good place to define a batch size for the model\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=processor,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "# The language model is the foundation on which modern NLP systems are built.\n",
        "# They encapsulate a general understanding of sentence semantics\n",
        "# and are not specific to any one task.\n",
        "\n",
        "# Here we are using Google's BERT model as implemented by HuggingFace. \n",
        "# The model being loaded is a German model that we trained. \n",
        "# You can also change the MODEL_NAME_OR_PATH to point to a BERT model that you\n",
        "# have saved or download one connected to the HuggingFace repository.\n",
        "# See farm.modeling.language_model.PRETRAINED_MODEL_ARCHIVE_MAP for a list of\n",
        "# available models\n",
        "\n",
        "MODEL_NAME_OR_PATH = \"xlnet-base-cased\"\n",
        "# MODEL_NAME_OR_PATH = AutoModelForSequenceClassification.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
        "language_model = LanguageModel.load(MODEL_NAME_OR_PATH)\n",
        "\n",
        "# A prediction head is a model that processes the output of the language model\n",
        "# for a specific task.\n",
        "# Prediction heads will look different depending on whether you're doing text classification\n",
        "# Named Entity Recognition (NER), question answering or some other task.\n",
        "# They should generate logits over the available prediction classes and contain methods\n",
        "# to convert these logits to losses or predictions \n",
        "\n",
        "# Here we use TextClassificationHead which receives a single fixed length sentence vector\n",
        "# and processes it using a feed forward neural network. layer_dims is a list of dimensions:\n",
        "# [input_dims, hidden_1_dims, hidden_2_dims ..., output_dims]\n",
        "\n",
        "# Here by default we have a single layer network.\n",
        "# It takes in a vector of length 768 (the default size of BERT's output).\n",
        "# It outputs a vector of length 2 (the number of classes in the GermEval18 (coarse) dataset)\n",
        "\n",
        "prediction_head = TextClassificationHead(num_labels=len(LABEL_LIST), class_weights=data_silo.calculate_class_weights(task_name=\"text_classification\"))\n",
        "\n",
        "# The language model and prediction head are coupled together in the Adaptive Model.\n",
        "# This class takes care of model saving and loading and also coordinates\n",
        "# cases where there is more than one prediction head.\n",
        "\n",
        "# EMBEDS_DROPOUT_PROB is the probability that an element of the output vector from the\n",
        "# language model will be set to zero.\n",
        "# EMBEDS_DROPOUT_PROB = 0.1 distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "# EMBEDS_DROPOUT_PROB = 0.01\n",
        "# EMBEDS_DROPOUT_PROB = 0.2 distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "EMBEDS_DROPOUT_PROB = 0.01\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device)\n",
        "\n",
        "# Here we initialize a Bert Adam optimizer that has a linear warmup and warmdown\n",
        "# Here you can set learning rate, the warmup proportion and number of epochs to train for\n",
        "\n",
        "#LEARNING_RATE = 2e-5 # distilbert-base-uncased-finetuned-sst-2-english_1.PNG\n",
        "#LEARNING_RATE = 1e-7\n",
        "LEARNING_RATE = 1e-5  # distilbert-base-uncased-finetuned-sst-2-english_2.PNG\n",
        "\n",
        "N_EPOCHS = 3\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    device=device,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS)\n",
        "\n",
        "# Training loop handled by this\n",
        "# It will also trigger evaluation during training using the dev data\n",
        "# and after training using the test data.\n",
        "\n",
        "# Set N_GPU to a positive value if CUDA is available\n",
        "N_GPU = 1\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device, \n",
        ")\n",
        "\n",
        "!nvidia-smi\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/configuration_xlnet.py:212: FutureWarning: This config doesn't use attention memories, a core feature of XLNet. Consider setting `men_len` to a non-zero value, for example `xlnet = XLNetLMHeadModel.from_pretrained('xlnet-base-cased'', mem_len=1024)`, for accurate training performance as well as an order of magnitude faster inference. Starting from version 3.5.0, the default parameter will be 1024, following the implementation in https://arxiv.org/abs/1906.08237\n",
            "  FutureWarning,\n",
            "09/13/2021 16:40:25 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='tokenizer' was already logged with value='DistilBertTokenizer' for run ID='6543ccfdbba146ca82a34b6de1bbb983. Attempted logging new value 'XLNetTokenizer'.\n",
            "09/13/2021 16:40:25 - INFO - farm.data_handler.data_silo -   \n",
            "Loading data into the data silo ... \n",
            "              ______\n",
            "               |o  |   !\n",
            "   __          |:`_|---'-.\n",
            "  |__|______.-/ _ \\-----.|       \n",
            " (o)(o)------'\\ _ /     ( )      \n",
            " \n",
            "09/13/2021 16:40:25 - INFO - farm.data_handler.data_silo -   Loading train set from: ../content/train.tsv \n",
            "09/13/2021 16:40:26 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 3947 dictionaries to pytorch datasets (chunksize = 790)...\n",
            "09/13/2021 16:40:26 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/13/2021 16:40:26 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/13/2021 16:40:26 - INFO - farm.data_handler.data_silo -   /'\\\n",
            "09/13/2021 16:40:26 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/train.tsv:   0%|          | 0/3947 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/13/2021 16:40:27 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/13/2021 16:40:27 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 44-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"....oh fuck what an amazing cock its soooooooo dam big and a perfect foreskin one of the best dicks Ive ever seen\"\n",
            "Tokenized: \n",
            " \ttokens: ['▁', '\"', '.', '.', '.', '.', 'oh', '▁fuck', '▁what', '▁an', '▁amazing', '▁cock', '▁its', '▁so', 'oo', 'o', 'oo', 'oo', '▁dam', '▁big', '▁and', '▁a', '▁perfect', '▁for', 'es', 'kin', '▁one', '▁of', '▁the', '▁best', '▁', 'dick', 's', '▁I', 've', '▁ever', '▁seen', '\"']\n",
            " \toffsets: [0, 0, 1, 2, 3, 4, 5, 8, 13, 18, 21, 29, 34, 38, 40, 42, 43, 45, 48, 52, 56, 60, 62, 70, 73, 75, 79, 83, 86, 90, 95, 95, 99, 101, 102, 105, 110, 114]\n",
            " \tstart_of_word: [True, False, False, False, False, False, False, True, True, True, True, True, True, True, False, False, False, False, True, True, True, True, True, True, False, False, True, True, True, True, True, False, False, True, False, True, True, False]\n",
            "Features: \n",
            " \tinput_ids: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 17, 12, 9, 9, 9, 9, 4470, 15707, 113, 48, 3704, 13173, 81, 102, 5449, 155, 5449, 5449, 7678, 534, 21, 24, 1705, 28, 202, 2160, 65, 20, 18, 252, 17, 17882, 23, 35, 189, 545, 566, 12, 4, 3]\n",
            " \tpadding_mask: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tsegment_ids: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/13/2021 16:40:27 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 708-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"battier sucks again!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!1\"\n",
            "Tokenized: \n",
            " \ttokens: ['▁', '\"', 'bat', 'tier', '▁suck', 's', '▁again', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '!!!!', '1', '\"']\n",
            " \toffsets: [0, 0, 1, 4, 9, 13, 15, 20, 24, 28, 32, 36, 40, 44, 48, 52, 56, 60, 64, 68, 72, 76, 80, 84, 88, 92, 93]\n",
            " \tstart_of_word: [True, False, False, False, True, False, True, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False, False]\n",
            "Features: \n",
            " \tinput_ids: [5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 17, 12, 5316, 5861, 11989, 23, 292, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 21823, 174, 12, 4, 3]\n",
            " \tpadding_mask: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tsegment_ids: [4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/train.tsv: 100%|██████████| 3947/3947 [00:09<00:00, 395.78 Dicts/s]\n",
            "09/13/2021 16:40:36 - INFO - farm.data_handler.data_silo -   Loading dev set as a slice of train set\n",
            "09/13/2021 16:40:36 - INFO - farm.data_handler.data_silo -   Took 787 samples out of train set to create dev set (dev split is roughly 0.1)\n",
            "09/13/2021 16:40:36 - INFO - farm.data_handler.data_silo -   Loading test set from: ../content/test_with_solutions.tsv\n",
            "09/13/2021 16:40:36 - INFO - farm.data_handler.data_silo -   Got ya 1 parallel workers to convert 2647 dictionaries to pytorch datasets (chunksize = 530)...\n",
            "09/13/2021 16:40:36 - INFO - farm.data_handler.data_silo -    0 \n",
            "09/13/2021 16:40:36 - INFO - farm.data_handler.data_silo -   /w\\\n",
            "09/13/2021 16:40:36 - INFO - farm.data_handler.data_silo -   / \\\n",
            "09/13/2021 16:40:36 - INFO - farm.data_handler.data_silo -   \n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv:   0%|          | 0/2647 [00:00<?, ? Dicts/s]/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py:460: FutureWarning: `is_pretokenized` is deprecated and will be removed in a future version, use `is_split_into_words` instead.\n",
            "  FutureWarning,\n",
            "09/13/2021 16:40:38 - INFO - farm.data_handler.processor -   *** Show 2 random examples ***\n",
            "09/13/2021 16:40:38 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 276-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 0\n",
            " \ttext: \"@james3012   really?? more name calling?? i would have never guessed it. what a sad little boy you must be. just because the big kids bully you at school doesnt mean you have to try to be some internet gangster because i promise you you are not scaring anyone. you must be a wh fan. once again you guys continue to prove my comments about no class no character true. maybe for now on that can be your clubs motto.... NO CLASS NO CHARACTER by the way your comment \"Just be glad someone from Manchester actually has a career\" doesnt really make much sense. actually it doesnt make any sense at all. but what else can we expect from dense people such as yourself and the other two i was talking to. keep supporting rubbish people who shouldnt be allowed to profit from the beautiful game. ok i will shut it because i know you are feeble minded so go back to your nintendo\"\n",
            "Tokenized: \n",
            " \ttokens: ['▁', '\"', '@', 'ja', 'mes', '30', '12', '▁really', '?', '?', '▁more', '▁name', '▁calling', '?', '?', '▁', 'i', '▁would', '▁have', '▁never', '▁guessed', '▁it', '.', '▁what', '▁a', '▁sad', '▁little', '▁boy', '▁you', '▁must', '▁be', '.', '▁just', '▁because', '▁the', '▁big', '▁kids', '▁bull', 'y', '▁you', '▁at', '▁school', '▁doesn', 't', '▁mean', '▁you', '▁have', '▁to', '▁try', '▁to', '▁be', '▁some', '▁internet', '▁gangster', '▁because', '▁', 'i', '▁promise', '▁you', '▁you', '▁are', '▁not', '▁scar', 'ing', '▁anyone', '.', '▁you', '▁must', '▁be', '▁a', '▁wh', '▁fan', '.', '▁once', '▁again', '▁you', '▁guys', '▁continue', '▁to', '▁prove', '▁my', '▁comments', '▁about', '▁no', '▁class', '▁no', '▁character', '▁true', '.', '▁maybe', '▁for', '▁now', '▁on', '▁that', '▁can', '▁be', '▁your', '▁clubs', '▁motto', '.', '.', '.', '.', '▁NO', '▁C', 'LAS', 'S', '▁NO', '▁', 'CHA', 'RAC', 'TER', '▁by', '▁the', '▁way', '▁your', '▁comment', '▁', '\"', 'Just', '▁be', '▁glad', '▁someone', '▁from', '▁Manchester', '▁actually']\n",
            " \toffsets: [0, 0, 1, 2, 4, 7, 9, 14, 20, 21, 23, 28, 33, 40, 41, 43, 43, 45, 51, 56, 62, 70, 72, 74, 79, 81, 85, 92, 96, 100, 105, 107, 109, 114, 122, 126, 130, 135, 139, 141, 145, 148, 155, 160, 162, 167, 171, 176, 179, 183, 186, 189, 194, 203, 212, 220, 220, 222, 230, 234, 238, 242, 246, 250, 254, 260, 262, 266, 271, 274, 276, 279, 282, 284, 289, 295, 299, 304, 313, 316, 322, 325, 334, 340, 343, 349, 352, 362, 366, 368, 374, 378, 382, 385, 390, 394, 397, 402, 408, 413, 414, 415, 416, 418, 421, 422, 425, 427, 430, 430, 433, 436, 440, 443, 447, 451, 456, 464, 464, 465, 470, 473, 478, 486, 491, 502]\n",
            " \tstart_of_word: [True, False, False, False, False, False, False, True, False, False, True, True, True, False, False, True, False, True, True, True, True, True, False, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, False, True, False, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, True, True, True, True, True, False, True, True, True, True, True, True, True, True, True, True, False, False, False, False, True, True, False, False, True, True, False, False, False, True, True, True, True, True, True, False, False, True, True, True, True, True, True]\n",
            "Features: \n",
            " \tinput_ids: [17, 12, 13304, 1653, 4316, 1496, 1396, 343, 82, 82, 70, 304, 2149, 82, 82, 17, 150, 74, 47, 287, 19259, 36, 9, 113, 24, 5694, 293, 2001, 44, 272, 39, 9, 125, 149, 18, 534, 1886, 6446, 117, 44, 38, 297, 855, 46, 1125, 44, 47, 22, 714, 22, 39, 106, 2476, 24495, 149, 17, 150, 3691, 44, 44, 41, 50, 12612, 56, 1216, 9, 44, 272, 39, 24, 9012, 3054, 9, 497, 292, 44, 2500, 786, 22, 3392, 94, 1992, 75, 116, 1075, 116, 1542, 1229, 9, 2163, 28, 145, 31, 29, 64, 39, 73, 4136, 21636, 9, 9, 9, 9, 6721, 330, 24304, 83, 6721, 17, 19909, 26530, 9645, 37, 18, 162, 73, 1709, 17, 12, 5817, 39, 5590, 886, 40, 5017, 995, 4, 3]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            " \ttext_classification_label_ids: [0]\n",
            "_____________________________________________________\n",
            "09/13/2021 16:40:38 - INFO - farm.data_handler.processor -   \n",
            "\n",
            "      .--.        _____                       _      \n",
            "    .'_\\/_'.     / ____|                     | |     \n",
            "    '. /\\ .'    | (___   __ _ _ __ ___  _ __ | | ___ \n",
            "      \"||\"       \\___ \\ / _` | '_ ` _ \\| '_ \\| |/ _ \\ \n",
            "       || /\\     ____) | (_| | | | | | | |_) | |  __/\n",
            "    /\\ ||//\\)   |_____/ \\__,_|_| |_| |_| .__/|_|\\___|\n",
            "   (/\\||/                             |_|           \n",
            "______\\||/___________________________________________                     \n",
            "\n",
            "ID: 182-0\n",
            "Clear Text: \n",
            " \ttext_classification_label: 1\n",
            " \ttext: \"Bigger than the Chicago Tribune and the Boston Globe? \\xa0Are you HIGH???? \\xa0 I've never even SEEN the daily caller, but I've bought the Tribune and read the Globe. \\xa0What else you got? \\xa0And by the way, your blog isn't legitimate. \\xa0It's a fucking blog. \\xa0A website. \\xa0I don't think that truly qualifies, no offense Raw. \\xa0But even YOU guys don't really count and you know it. \\xa0IF they don't want to give them a press pass there really isn't much that they can do to force the White House's hand. \\xa0If they give them a pass it's because they don't feel threatened and WANT him to keep up the bullshit to SHOW the country just what these people's true colors are. \\xa0Obama and pals ARE NOT playing the race card and never have, no matter how many times the right wing assholes keep repeating that bullshit. \\xa0But these people keep painting themselves into a corner of backwards-assed white power racist uncivilized and uninspiring troglodytes.\"\n",
            "Tokenized: \n",
            " \ttokens: ['▁', '\"', 'Big', 'ger', '▁than', '▁the', '▁Chicago', '▁Tribune', '▁and', '▁the', '▁Boston', '▁Globe', '?', '▁', '\\\\', 'xa', '0', 'Are', '▁you', '▁HI', 'GH', '?', '???', '▁', '\\\\', 'xa', '0', '▁I', \"'\", 've', '▁never', '▁even', '▁SE', 'EN', '▁the', '▁daily', '▁caller', ',', '▁but', '▁I', \"'\", 've', '▁bought', '▁the', '▁Tribune', '▁and', '▁read', '▁the', '▁Globe', '.', '▁', '\\\\', 'xa', '0', 'What', '▁else', '▁you', '▁got', '?', '▁', '\\\\', 'xa', '0', 'And', '▁by', '▁the', '▁way', ',', '▁your', '▁blog', '▁isn', \"'\", 't', '▁legitimate', '.', '▁', '\\\\', 'xa', '0', 'It', \"'\", 's', '▁a', '▁fucking', '▁blog', '.', '▁', '\\\\', 'xa', '0', 'A', '▁website', '.', '▁', '\\\\', 'xa', '0', 'I', '▁don', \"'\", 't', '▁think', '▁that', '▁truly', '▁qualifies', ',', '▁no', '▁offense', '▁R', 'aw', '.', '▁', '\\\\', 'xa', '0', 'But', '▁even', '▁YOU', '▁guys', '▁don', \"'\", 't', '▁really', '▁count', '▁and', '▁you']\n",
            " \toffsets: [0, 0, 1, 4, 8, 13, 17, 25, 33, 37, 41, 48, 53, 55, 55, 56, 58, 59, 63, 67, 69, 71, 72, 76, 76, 77, 79, 81, 82, 83, 86, 92, 97, 99, 102, 106, 112, 118, 120, 124, 125, 126, 129, 136, 140, 148, 152, 157, 161, 166, 168, 168, 169, 171, 172, 177, 182, 186, 189, 191, 191, 192, 194, 195, 199, 202, 206, 209, 211, 216, 221, 224, 225, 227, 237, 239, 239, 240, 242, 243, 245, 246, 248, 250, 258, 262, 264, 264, 265, 267, 268, 270, 277, 279, 279, 280, 282, 283, 285, 288, 289, 291, 297, 302, 308, 317, 319, 322, 330, 331, 333, 335, 335, 336, 338, 339, 343, 348, 352, 357, 360, 361, 363, 370, 376, 380]\n",
            " \tstart_of_word: [True, False, False, False, True, True, True, True, True, True, True, True, False, True, False, False, False, False, True, True, False, False, False, True, False, False, False, True, False, False, True, True, True, False, True, True, True, False, True, True, False, False, True, True, True, True, True, True, True, False, True, False, False, False, False, True, True, True, False, True, False, False, False, False, True, True, True, False, True, True, True, False, False, True, False, True, False, False, False, False, False, False, True, True, True, False, True, False, False, False, False, True, False, True, False, False, False, False, True, False, False, True, True, True, True, False, True, True, True, False, False, True, False, False, False, False, True, True, True, True, False, False, True, True, True, True]\n",
            "Features: \n",
            " \tinput_ids: [17, 12, 13174, 2371, 100, 18, 1763, 14508, 21, 18, 1843, 9125, 82, 17, 17666, 14151, 279, 5416, 44, 17213, 14524, 82, 22180, 17, 17666, 14151, 279, 35, 26, 189, 287, 176, 8442, 6543, 18, 1362, 18380, 19, 57, 35, 26, 189, 2242, 18, 14508, 21, 828, 18, 9125, 9, 17, 17666, 14151, 279, 979, 1104, 44, 345, 82, 17, 17666, 14151, 279, 1648, 37, 18, 162, 19, 73, 2780, 1601, 26, 46, 7296, 9, 17, 17666, 14151, 279, 289, 26, 23, 24, 19021, 2780, 9, 17, 17666, 14151, 279, 246, 1001, 9, 17, 17666, 14151, 279, 96, 220, 26, 46, 232, 29, 3291, 28717, 19, 116, 5986, 482, 3806, 9, 17, 17666, 14151, 279, 1294, 176, 13938, 2500, 220, 26, 46, 343, 3497, 21, 44, 4, 3]\n",
            " \tpadding_mask: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
            " \tsegment_ids: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            " \ttext_classification_label_ids: [1]\n",
            "_____________________________________________________\n",
            "Preprocessing Dataset ../content/test_with_solutions.tsv: 100%|██████████| 2647/2647 [00:07<00:00, 359.10 Dicts/s]\n",
            "09/13/2021 16:40:43 - INFO - farm.data_handler.data_silo -   Examples in train: 3160\n",
            "09/13/2021 16:40:43 - INFO - farm.data_handler.data_silo -   Examples in dev  : 787\n",
            "09/13/2021 16:40:43 - INFO - farm.data_handler.data_silo -   Examples in test : 2647\n",
            "09/13/2021 16:40:43 - INFO - farm.data_handler.data_silo -   \n",
            "09/13/2021 16:40:43 - INFO - farm.data_handler.data_silo -   Longest sequence length observed after clipping:     128\n",
            "09/13/2021 16:40:43 - INFO - farm.data_handler.data_silo -   Average sequence length after clipping: 46.91962025316456\n",
            "09/13/2021 16:40:43 - INFO - farm.data_handler.data_silo -   Proportion clipped:      0.08386075949367089\n",
            "09/13/2021 16:40:43 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='ave_seq_len' was already logged with value='43.41107594936709' for run ID='6543ccfdbba146ca82a34b6de1bbb983. Attempted logging new value '46.91962025316456'.\n",
            "09/13/2021 16:40:59 - WARNING - farm.modeling.language_model -   Could not automatically detect from language model name what language it is. \n",
            "\t We guess it's an *ENGLISH* model ... \n",
            "\t If not: Init the language model by supplying the 'language' param.\n",
            "09/13/2021 16:40:59 - INFO - farm.modeling.prediction_head -   Prediction head initialized with size [768, 2]\n",
            "09/13/2021 16:40:59 - INFO - farm.modeling.prediction_head -   Using class weights for task 'text_classification': [0.6832325 1.8643868]\n",
            "09/13/2021 16:40:59 - WARNING - farm.utils -   Failed to log params: INVALID_PARAMETER_VALUE: Changing param value is not allowed. Param with key='lm_type' was already logged with value='DistilBert' for run ID='6543ccfdbba146ca82a34b6de1bbb983. Attempted logging new value 'XLNet'.\n",
            "09/13/2021 16:40:59 - INFO - farm.modeling.optimization -   Loading optimizer `TransformersAdamW`: '{'correct_bias': False, 'weight_decay': 0.01, 'lr': 1e-05}'\n",
            "09/13/2021 16:41:00 - INFO - farm.modeling.optimization -   Using scheduler 'get_linear_schedule_with_warmup'\n",
            "09/13/2021 16:41:00 - INFO - farm.modeling.optimization -   Loading schedule `get_linear_schedule_with_warmup`: '{'num_warmup_steps': 29.700000000000003, 'num_training_steps': 297}'\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Sep 13 16:41:00 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 470.63.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   49C    P0    61W / 149W |  10553MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "09/13/2021 16:41:00 - INFO - farm.train -   \n",
            " \n",
            "\n",
            "          &&& &&  & &&             _____                   _             \n",
            "      && &\\/&\\|& ()|/ @, &&       / ____|                 (_)            \n",
            "      &\\/(/&/&||/& /_/)_&/_&     | |  __ _ __ _____      ___ _ __   __ _ \n",
            "   &() &\\/&|()|/&\\/ '%\" & ()     | | |_ | '__/ _ \\ \\ /\\ / / | '_ \\ / _` |\n",
            "  &_\\_&&_\\ |& |&&/&__%_/_& &&    | |__| | | | (_) \\ V  V /| | | | | (_| |\n",
            "&&   && & &| &| /& & % ()& /&&    \\_____|_|  \\___/ \\_/\\_/ |_|_| |_|\\__, |\n",
            " ()&_---()&\\&\\|&&-&&--%---()~                                       __/ |\n",
            "     &&     \\|||                                                   |___/\n",
            "             |||\n",
            "             |||\n",
            "             |||\n",
            "       , -=-~  .-^- _\n",
            "              `\n",
            "\n",
            "Train epoch 0/2 (Cur. train loss: 0.0000):   0%|          | 0/99 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/transformers/modeling_xlnet.py:298: UserWarning: Mixed memory format inputs detected while calling the operator. The operator will output contiguous tensor even if some of the inputs are in channels_last format. (Triggered internally at  /pytorch/aten/src/ATen/native/TensorIterator.cpp:918.)\n",
            "  attn_score = (ac + bd + ef) * self.scale\n",
            "Train epoch 0/2 (Cur. train loss: 0.0000):   0%|          | 0/99 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ModuleAttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleAttributeError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-1be32d597fbc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    136\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nvidia-smi'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/train.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;31m# Forward & backward pass through model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                 \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0mper_sample_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_to_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mper_sample_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/modeling/adaptive_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m         \u001b[0;31m# Run forward pass of language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_lm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;31m# Run forward pass of (multiple) prediction heads using the output from above\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/modeling/adaptive_model.py\u001b[0m in \u001b[0;36mforward_lm\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    456\u001b[0m         \u001b[0;31m# Run forward pass of language model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    457\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mextraction_layer\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 458\u001b[0;31m             \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlanguage_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_all_encoded_layers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    460\u001b[0m             \u001b[0;31m# get output from an earlier layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/farm/modeling/language_model.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, segment_ids, padding_mask, **kwargs)\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0mpooled_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpooler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    961\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 962\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_hidden_states\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    963\u001b[0m             \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_hidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_tuple\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    964\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msequence_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpooled_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mall_hidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m         raise ModuleAttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 772\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleAttributeError\u001b[0m: 'XLNetModel' object has no attribute 'output_hidden_states'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvQUsXu9kgSq"
      },
      "source": [
        "## Switching to NER (NOT WORKING)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7vnmJMT4MYg"
      },
      "source": [
        "# Import the new building blocks\n",
        "\n",
        "from farm.data_handler.processor import NERProcessor\n",
        "from farm.modeling.prediction_head import TokenClassificationHead\n",
        "ml_logger.init_experiment(experiment_name=\"Public_FARM\", run_name=\"Tutorial1_Colab_NER\")\n",
        "\n",
        "# This processor will preprocess the data for the CoNLL03 NER task\n",
        "ner_labels = [\"[PAD]\", \"X\", \"O\", \"B-MISC\", \"I-MISC\", \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\", \"B-OTH\", \"I-OTH\"]\n",
        "\n",
        "ner_processor = NERProcessor(tokenizer=tokenizer, \n",
        "                             max_seq_len=128, \n",
        "                             data_dir=\"../data/conll03-de\",\n",
        "                             label_list=ner_labels,\n",
        "                             metric=\"seq_f1\")\n",
        "\n",
        "# This prediction head is also a feed forward neural network but expects one\n",
        "# vector per token in the input sequence and will generate a set of logits\n",
        "# for each input\n",
        "\n",
        "ner_prediction_head = TokenClassificationHead(num_labels=len(ner_labels))\n",
        "\n",
        "# We can integrate these new pieces with the rest using this code\n",
        "# It is pretty much the same structure as what we had above for text classification\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "LEARNING_RATE = 2e-5\n",
        "N_EPOCHS = 1\n",
        "N_GPU = 1\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=ner_processor,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[ner_prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_token\"],\n",
        "    device=device)\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS,\n",
        "    device=device)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device,\n",
        ")\n",
        "\n",
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "prov6seQlmLq"
      },
      "source": [
        "# Import the new building blocks\n",
        "\n",
        "from farm.data_handler.processor import NERProcessor\n",
        "from farm.modeling.prediction_head import TokenClassificationHead\n",
        "ml_logger.init_experiment(experiment_name=\"Public_FARM\", run_name=\"Tutorial1_Colab_NER\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "reITkXdilqL9"
      },
      "source": [
        "# This processor will preprocess the data for the CoNLL03 NER task\n",
        "ner_labels = [\"1\", \"0\"]\n",
        "\n",
        "ner_processor = NERProcessor(tokenizer=tokenizer, \n",
        "                             max_seq_len=128,\n",
        "                             train_filename=\"train.tsv\",\n",
        "                             test_filename=\"test_with_solutions.tsv\",\n",
        "                             dev_filename=None,\n",
        "                             data_dir=\"../content\",\n",
        "                             label_list=ner_labels,\n",
        "                             metric=\"f1_macro\",\n",
        "                             text_column_name=\"Comment\",\n",
        "                              label_column_name=\"Insult\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ-ddMWvlswY"
      },
      "source": [
        "# This prediction head is also a feed forward neural network but expects one\n",
        "# vector per token in the input sequence and will generate a set of logits\n",
        "# for each input\n",
        "\n",
        "ner_prediction_head = TokenClassificationHead(num_labels=len(ner_labels))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aY0IYYBXlu00"
      },
      "source": [
        "# We can integrate these new pieces with the rest using this code\n",
        "# It is pretty much the same structure as what we had above for text classification\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EMBEDS_DROPOUT_PROB = 0.1\n",
        "LEARNING_RATE = 2e-5\n",
        "N_EPOCHS = 1\n",
        "N_GPU = 1\n",
        "\n",
        "data_silo = DataSilo(\n",
        "    processor=ner_processor,\n",
        "    batch_size=BATCH_SIZE)\n",
        "\n",
        "model = AdaptiveModel(\n",
        "    language_model=language_model,\n",
        "    prediction_heads=[ner_prediction_head],\n",
        "    embeds_dropout_prob=EMBEDS_DROPOUT_PROB,\n",
        "    lm_output_types=[\"per_sequence\"],\n",
        "    device=device)\n",
        "\n",
        "model, optimizer, lr_schedule = initialize_optimizer(\n",
        "    model=model,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    n_batches=len(data_silo.loaders[\"train\"]),\n",
        "    n_epochs=N_EPOCHS,\n",
        "    device=device)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    optimizer=optimizer,\n",
        "    data_silo=data_silo,\n",
        "    epochs=N_EPOCHS,\n",
        "    n_gpu=N_GPU,\n",
        "    lr_schedule=lr_schedule,\n",
        "    device=device,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rbTzCDslxH0"
      },
      "source": [
        "model = trainer.train()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}