{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iHRMBU4TViPU"
   },
   "source": [
    "Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FT720Zd9ViPY",
    "outputId": "7b95b2f6-e78a-49c9-f476-cf509f689476"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweet-preprocessor in c:\\users\\julia\\anaconda3\\lib\\site-packages (0.6.0)\n",
      "Requirement already satisfied: scipy in c:\\users\\julia\\anaconda3\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.14.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from scipy) (1.19.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\julia\\anaconda3\\lib\\site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from seaborn) (1.19.2)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from seaborn) (1.5.2)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from seaborn) (1.1.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from seaborn) (3.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.0.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: certifi>=2020.06.20 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2020.6.20)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\julia\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas>=0.23->seaborn) (1.15.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweet-preprocessor\n",
    "#!pip install mlxtend\n",
    "!pip install scipy\n",
    "from scipy import stats\n",
    "!pip install seaborn\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import json\n",
    "import preprocessor as p\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score\n",
    "# Gaussian vs. Bernoulli NB\n",
    "#from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JKX0QSbuViPb"
   },
   "source": [
    "Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UagOH5MEViPb"
   },
   "outputs": [],
   "source": [
    "# Je nach Dataset m√ºssen wir dieses evtl aufteilen um Trainings- und Testdaten zu erhalten (70/30)\n",
    "\n",
    "# training data\n",
    "train = pd.read_csv(\"./datasets/detecting-insults-in-social-commentary/train.csv\")\n",
    "train_for_cv = pd.read_csv(\"./datasets/detecting-insults-in-social-commentary/train.csv\")\n",
    "\n",
    "# test data without labels to see how our classifiers perform on unlabeled and unseen data\n",
    "#test = pd.read_csv(\"./datasets/detecting-insults-in-social-commentary/test.csv\")\n",
    "\n",
    "# dev dataset\n",
    "dev = pd.read_csv(\"./datasets/detecting-insults-in-social-commentary/test_with_solutions.csv\")\n",
    "dev_for_cv = pd.read_csv(\"./datasets/detecting-insults-in-social-commentary/test_with_solutions.csv\")\n",
    "\n",
    "# test dataset with labels to calculate metrics\n",
    "test = pd.read_csv(\"./datasets/detecting-insults-in-social-commentary/impermium_verification_labels.csv\")\n",
    "test_for_cv = pd.read_csv(\"./datasets/detecting-insults-in-social-commentary/impermium_verification_labels.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9P6evsBViPd"
   },
   "source": [
    "Look at Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "70wRu2faViPe",
    "outputId": "cfeedf3f-a67c-49e0-9a96-0cfee9fe0398"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>20120502172717Z</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528164814Z</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620142813Z</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528205648Z</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>20120515200734Z</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult             Date  \\\n",
       "3942       1  20120502172717Z   \n",
       "3943       0  20120528164814Z   \n",
       "3944       0  20120620142813Z   \n",
       "3945       0  20120528205648Z   \n",
       "3946       0  20120515200734Z   \n",
       "\n",
       "                                                Comment  \n",
       "3942  \"you are both morons and that is never happening\"  \n",
       "3943  \"Many toolbars include spell check, like Yahoo...  \n",
       "3944  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...  \n",
       "3945  \"How about Felix? He is sure turning into one ...  \n",
       "3946  \"You're all upset, defending this hipster band...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()\n",
    "train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "CRiy54W7ViPf",
    "outputId": "15b92b92-83f2-4fe6-e41c-6bd52093543b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>0</td>\n",
       "      <td>20120612003508Z</td>\n",
       "      <td>\"Never really gave it much thought. I just fig...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>0</td>\n",
       "      <td>20120619210456Z</td>\n",
       "      <td>\"Nadie se salva de la regla 34 xd\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>0</td>\n",
       "      <td>20120528234613Z</td>\n",
       "      <td>\"Question: Are you a boy or a girl?\"</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>1</td>\n",
       "      <td>20120619153537Z</td>\n",
       "      <td>\"Leave your email or phone number and maybe yo...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>0</td>\n",
       "      <td>20120620000237Z</td>\n",
       "      <td>\"From the scenarios you present, I see you bel...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult             Date  \\\n",
       "2642       0  20120612003508Z   \n",
       "2643       0  20120619210456Z   \n",
       "2644       0  20120528234613Z   \n",
       "2645       1  20120619153537Z   \n",
       "2646       0  20120620000237Z   \n",
       "\n",
       "                                                Comment        Usage  \n",
       "2642  \"Never really gave it much thought. I just fig...  PrivateTest  \n",
       "2643                 \"Nadie se salva de la regla 34 xd\"  PrivateTest  \n",
       "2644               \"Question: Are you a boy or a girl?\"  PrivateTest  \n",
       "2645  \"Leave your email or phone number and maybe yo...  PrivateTest  \n",
       "2646  \"From the scenarios you present, I see you bel...  PrivateTest  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head()\n",
    "dev.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "5mbxB6sfViPf",
    "outputId": "be121eb8-42f5-4d78-d732-7967e64489dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>Insult</th>\n",
       "      <th>Date</th>\n",
       "      <th>Comment</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>2231</td>\n",
       "      <td>0</td>\n",
       "      <td>20120528100303Z</td>\n",
       "      <td>\"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>2232</td>\n",
       "      <td>1</td>\n",
       "      <td>20120531185813Z</td>\n",
       "      <td>\"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>2233</td>\n",
       "      <td>0</td>\n",
       "      <td>20120529130822Z</td>\n",
       "      <td>\"sweetie pie is looking very much like her cou...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>2234</td>\n",
       "      <td>1</td>\n",
       "      <td>20120531045826Z</td>\n",
       "      <td>\"ball4real where are you with your miami g-ayn...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>2235</td>\n",
       "      <td>0</td>\n",
       "      <td>20120531184524Z</td>\n",
       "      <td>\"Man....if you are a 3 point shooter, you must...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id  Insult             Date  \\\n",
       "2230  2231       0  20120528100303Z   \n",
       "2231  2232       1  20120531185813Z   \n",
       "2232  2233       0  20120529130822Z   \n",
       "2233  2234       1  20120531045826Z   \n",
       "2234  2235       0  20120531184524Z   \n",
       "\n",
       "                                                Comment        Usage  \n",
       "2230  \"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...  PrivateTest  \n",
       "2231  \"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...  PrivateTest  \n",
       "2232  \"sweetie pie is looking very much like her cou...  PrivateTest  \n",
       "2233  \"ball4real where are you with your miami g-ayn...  PrivateTest  \n",
       "2234  \"Man....if you are a 3 point shooter, you must...  PrivateTest  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()\n",
    "test.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6G0j5y92ViPh",
    "outputId": "f2208968-459f-405f-985f-f5f73dca2d44"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2898"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-toxic comment\n",
    "# Spalte der Label in Anf√ºhrungszeichen angeben\n",
    "sum(train[\"Insult\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "enX2OkLHWVCK",
    "outputId": "75250e76-5b7a-4431-a0d9-776755bca69c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1049"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toxic comment\n",
    "sum(train[\"Insult\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UKOJNj79WPR4",
    "outputId": "31b4e01e-61f3-4f7c-e5d0-c70381b41553"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1954"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-toxic comment\n",
    "# Spalte der Label in Anf√ºhrungszeichen angeben\n",
    "sum(dev[\"Insult\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Vq9E96EWXae",
    "outputId": "59d8223a-c4f0-46cb-c475-23a184826c64"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toxic comment\n",
    "sum(dev[\"Insult\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NzApe8rIWQ-G",
    "outputId": "65d3d879-64cb-470d-aa81-e7d585c18ef6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# non-toxic comment\n",
    "# Spalte der Label in Anf√ºhrungszeichen angeben\n",
    "sum(test[\"Insult\"] == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m86vwKjsViPi",
    "outputId": "ad5e0103-9aff-49ad-8aff-593169c9efcc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1077"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# toxic comment\n",
    "sum(test[\"Insult\"] == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LoU_kbYHViPj",
    "outputId": "0e6105b2-5acb-4673-a0e1-fc4783f97846"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Insult       0\n",
       "Date       718\n",
       "Comment      0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mlaoElEdViPk"
   },
   "source": [
    "M√ºssen die Daten noch aufger√§umt werden?\n",
    "\n",
    "\n",
    "*   Sind special characters vorhanden? -> remove\n",
    "*   also remove Punctuation (wie geht man mit \"z.B.\" oder \"U.S.A\" um?)\n",
    "*   tweet-preprocessor?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "U7UW3H4SViPk"
   },
   "outputs": [],
   "source": [
    "# remove special characters -> regex schnell und einfach\n",
    "# set up punctuations we want to be replaced\n",
    "\n",
    "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
    "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "gONp77zPViPl"
   },
   "outputs": [],
   "source": [
    "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
    "def clean_tweets(df):\n",
    "  tempArr = []\n",
    "  for line in df:\n",
    "    # send to tweet_processor\n",
    "    tmpL = p.clean(line)\n",
    "    # remove puctuation\n",
    "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
    "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
    "    tempArr.append(tmpL)\n",
    "  return tempArr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "EbzoxoDPViPl",
    "outputId": "24ac1060-9006-41d7-bd4e-c9fd07ca9a31"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3942</th>\n",
       "      <td>1</td>\n",
       "      <td>\"you are both morons and that is never happening\"</td>\n",
       "      <td>you are both morons and that is never happening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3943</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Many toolbars include spell check, like Yahoo...</td>\n",
       "      <td>many toolbars include spell check like yahoo f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3944</th>\n",
       "      <td>0</td>\n",
       "      <td>\"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...</td>\n",
       "      <td>\\xa0\\xa0moss\\xa0\\nsioux falls sd i told my boy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3945</th>\n",
       "      <td>0</td>\n",
       "      <td>\"How about Felix? He is sure turning into one ...</td>\n",
       "      <td>how about felix he is sure turning into one he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3946</th>\n",
       "      <td>0</td>\n",
       "      <td>\"You're all upset, defending this hipster band...</td>\n",
       "      <td>youre all upset defending this hipster bandand...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment  \\\n",
       "3942       1  \"you are both morons and that is never happening\"   \n",
       "3943       0  \"Many toolbars include spell check, like Yahoo...   \n",
       "3944       0  \"@LambeauOrWrigley\\xa0\\xa0@K.Moss\\xa0\\nSioux F...   \n",
       "3945       0  \"How about Felix? He is sure turning into one ...   \n",
       "3946       0  \"You're all upset, defending this hipster band...   \n",
       "\n",
       "                                            clean_tweet  \n",
       "3942    you are both morons and that is never happening  \n",
       "3943  many toolbars include spell check like yahoo f...  \n",
       "3944  \\xa0\\xa0moss\\xa0\\nsioux falls sd i told my boy...  \n",
       "3945  how about felix he is sure turning into one he...  \n",
       "3946  youre all upset defending this hipster bandand...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean training data\n",
    "train_tweet = clean_tweets(train[\"Comment\"])\n",
    "train_tweet = pd.DataFrame(train_tweet)\n",
    "\n",
    "# append cleaned tweets to the training data\n",
    "train[\"clean_tweet\"] = train_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "#train.head(10)\n",
    "\n",
    "#create separate Dataframe for creating all_data for 10-fold cross validation\n",
    "train_for_cv = train\n",
    "# delete column 'Date'\n",
    "train_for_cv.drop('Date', inplace=True, axis=1)\n",
    "train_for_cv.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "id": "sFCfG8wfViPm",
    "outputId": "507182b9-1900-4b78-b94f-02a2608b29c5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Never really gave it much thought. I just fig...</td>\n",
       "      <td>never really gave it much thought i just figur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Nadie se salva de la regla 34 xd\"</td>\n",
       "      <td>nadie se salva de la regla xd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2644</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Question: Are you a boy or a girl?\"</td>\n",
       "      <td>question are you a boy or a girl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2645</th>\n",
       "      <td>1</td>\n",
       "      <td>\"Leave your email or phone number and maybe yo...</td>\n",
       "      <td>leave your email or phone number and maybe you...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2646</th>\n",
       "      <td>0</td>\n",
       "      <td>\"From the scenarios you present, I see you bel...</td>\n",
       "      <td>from the scenarios you present i see you belie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment  \\\n",
       "2642       0  \"Never really gave it much thought. I just fig...   \n",
       "2643       0                 \"Nadie se salva de la regla 34 xd\"   \n",
       "2644       0               \"Question: Are you a boy or a girl?\"   \n",
       "2645       1  \"Leave your email or phone number and maybe yo...   \n",
       "2646       0  \"From the scenarios you present, I see you bel...   \n",
       "\n",
       "                                            clean_tweet  \n",
       "2642  never really gave it much thought i just figur...  \n",
       "2643                      nadie se salva de la regla xd  \n",
       "2644                   question are you a boy or a girl  \n",
       "2645  leave your email or phone number and maybe you...  \n",
       "2646  from the scenarios you present i see you belie...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the dev data and append the cleaned tweets to the dev data\n",
    "dev_tweet = clean_tweets(dev[\"Comment\"])\n",
    "dev_tweet = pd.DataFrame(dev_tweet)\n",
    "# append cleaned tweets to the training data\n",
    "dev[\"clean_tweet\"] = dev_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "#dev.tail()\n",
    "\n",
    "#create separate Dataframe for creating all_data for 10-fold cross validation\n",
    "dev_for_cv = dev\n",
    "# delete column 'Date'\n",
    "dev_for_cv.drop('Date', inplace=True, axis=1)\n",
    "# delete column 'Usage'\n",
    "dev_for_cv.drop('Usage', inplace=True, axis=1)\n",
    "dev_for_cv.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "id": "X0mkLRwDViPm",
    "outputId": "dc1442c2-c7fa-494e-c853-ed0481420842"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>0</td>\n",
       "      <td>\"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...</td>\n",
       "      <td>fuckin lame come on wtf stop fucking over my b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>1</td>\n",
       "      <td>\"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...</td>\n",
       "      <td>you shut your ignorant pie hole you little ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>0</td>\n",
       "      <td>\"sweetie pie is looking very much like her cou...</td>\n",
       "      <td>sweetie pie is looking very much like her cous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>1</td>\n",
       "      <td>\"ball4real where are you with your miami g-ayn...</td>\n",
       "      <td>ball4real where are you with your miami g ayness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Man....if you are a 3 point shooter, you must...</td>\n",
       "      <td>manif you are a point shooter you must love pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment  \\\n",
       "2230       0  \"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...   \n",
       "2231       1  \"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...   \n",
       "2232       0  \"sweetie pie is looking very much like her cou...   \n",
       "2233       1  \"ball4real where are you with your miami g-ayn...   \n",
       "2234       0  \"Man....if you are a 3 point shooter, you must...   \n",
       "\n",
       "                                            clean_tweet  \n",
       "2230  fuckin lame come on wtf stop fucking over my b...  \n",
       "2231  you shut your ignorant pie hole you little ins...  \n",
       "2232  sweetie pie is looking very much like her cous...  \n",
       "2233   ball4real where are you with your miami g ayness  \n",
       "2234  manif you are a point shooter you must love pl...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean the test data and append the cleaned tweets to the test data\n",
    "test_tweet = clean_tweets(test[\"Comment\"])\n",
    "test_tweet = pd.DataFrame(test_tweet)\n",
    "# append cleaned tweets to the training data\n",
    "test[\"clean_tweet\"] = test_tweet\n",
    "\n",
    "# compare the cleaned and uncleaned tweets\n",
    "#test.tail()\n",
    "\n",
    "#create separate Dataframe for creating all_data for 10-fold cross validation\n",
    "test_for_cv = test\n",
    "# delete column 'id'\n",
    "test_for_cv.drop('id', inplace=True, axis=1)\n",
    "# delete column 'Date'\n",
    "test_for_cv.drop('Date', inplace=True, axis=1)\n",
    "# delete column 'Usage'\n",
    "test_for_cv.drop('Usage', inplace=True, axis=1)\n",
    "test_for_cv.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare csv-files for merge to compute cross validation\n",
    "Because my dataset is already splitted, I want to create one big dataset for performing 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Insult</th>\n",
       "      <th>Comment</th>\n",
       "      <th>clean_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>\"You fuck your dad.\"</td>\n",
       "      <td>you fuck your dad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>\"i really don't understand your point.\\xa0 It ...</td>\n",
       "      <td>i really dont understand your point\\xa0 it see...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>\"A\\\\xc2\\\\xa0majority of Canadians can and has ...</td>\n",
       "      <td>a\\\\xc2\\\\xa0majority of canadians can and has b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>\"listen if you dont wanna get married to a man...</td>\n",
       "      <td>listen if you dont wanna get married to a man ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>\"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...</td>\n",
       "      <td>c\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1eddn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2230</th>\n",
       "      <td>0</td>\n",
       "      <td>\"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...</td>\n",
       "      <td>fuckin lame come on wtf stop fucking over my b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2231</th>\n",
       "      <td>1</td>\n",
       "      <td>\"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...</td>\n",
       "      <td>you shut your ignorant pie hole you little ins...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2232</th>\n",
       "      <td>0</td>\n",
       "      <td>\"sweetie pie is looking very much like her cou...</td>\n",
       "      <td>sweetie pie is looking very much like her cous...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2233</th>\n",
       "      <td>1</td>\n",
       "      <td>\"ball4real where are you with your miami g-ayn...</td>\n",
       "      <td>ball4real where are you with your miami g ayness</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2234</th>\n",
       "      <td>0</td>\n",
       "      <td>\"Man....if you are a 3 point shooter, you must...</td>\n",
       "      <td>manif you are a point shooter you must love pl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8829 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Insult                                            Comment  \\\n",
       "0          1                               \"You fuck your dad.\"   \n",
       "1          0  \"i really don't understand your point.\\xa0 It ...   \n",
       "2          0  \"A\\\\xc2\\\\xa0majority of Canadians can and has ...   \n",
       "3          0  \"listen if you dont wanna get married to a man...   \n",
       "4          0  \"C\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1edd...   \n",
       "...      ...                                                ...   \n",
       "2230       0  \"FUCKIN LAME COME ON WTF STOP FUCKING OVER MY ...   \n",
       "2231       1  \"YOU SHUT YOUR IGNORANT PIE HOLE YOU LITTLE IN...   \n",
       "2232       0  \"sweetie pie is looking very much like her cou...   \n",
       "2233       1  \"ball4real where are you with your miami g-ayn...   \n",
       "2234       0  \"Man....if you are a 3 point shooter, you must...   \n",
       "\n",
       "                                            clean_tweet  \n",
       "0                                     you fuck your dad  \n",
       "1     i really dont understand your point\\xa0 it see...  \n",
       "2     a\\\\xc2\\\\xa0majority of canadians can and has b...  \n",
       "3     listen if you dont wanna get married to a man ...  \n",
       "4     c\\xe1c b\\u1ea1n xu\\u1ed1ng \\u0111\\u01b0\\u1eddn...  \n",
       "...                                                 ...  \n",
       "2230  fuckin lame come on wtf stop fucking over my b...  \n",
       "2231  you shut your ignorant pie hole you little ins...  \n",
       "2232  sweetie pie is looking very much like her cous...  \n",
       "2233   ball4real where are you with your miami g ayness  \n",
       "2234  manif you are a point shooter you must love pl...  \n",
       "\n",
       "[8829 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frames = [train_for_cv, dev_for_cv, test_for_cv]\n",
    "all_data = pd.concat(frames)\n",
    "all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "FeRrN8S0ViPn"
   },
   "outputs": [],
   "source": [
    "# extract the labels & comments from the train data\n",
    "\n",
    "# labels\n",
    "y_train = train.Insult.values\n",
    "# comments\n",
    "X_train = train.clean_tweet.values\n",
    "\n",
    "# extract the labels & comments from the dev data\n",
    "\n",
    "# labels\n",
    "y_dev = dev.Insult.values\n",
    "# comments\n",
    "X_dev = dev.clean_tweet.values\n",
    "\n",
    "# extract the labels & comments from the test data\n",
    "\n",
    "# labels\n",
    "y_test = test.Insult.values\n",
    "# comments\n",
    "X_test = test.clean_tweet.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1-sBnW0oViPo"
   },
   "source": [
    "Vectorize tweets using CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "Oyg0z_VFViPo",
    "outputId": "02acc466-921d-44ce-9cd6-e38c068e2437"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>also</th>\n",
       "      <th>bla</th>\n",
       "      <th>blaa</th>\n",
       "      <th>blaaa</th>\n",
       "      <th>document</th>\n",
       "      <th>is</th>\n",
       "      <th>just</th>\n",
       "      <th>letter</th>\n",
       "      <th>like</th>\n",
       "      <th>more</th>\n",
       "      <th>recognize</th>\n",
       "      <th>test</th>\n",
       "      <th>than</th>\n",
       "      <th>this</th>\n",
       "      <th>trains</th>\n",
       "      <th>with</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   also  bla  blaa  blaaa  document  is  just  letter  like  more  recognize  \\\n",
       "0     0    0     0      0         1   1     0       0     0     0          0   \n",
       "1     0    0     0      0         0   0     0       0     1     0          0   \n",
       "2     0    1     1      1         0   0     0       0     0     0          0   \n",
       "3     1    0     0      0         0   0     1       1     0     1          1   \n",
       "\n",
       "   test  than  this  trains  with  words  \n",
       "0     1     0     1       0     0      0  \n",
       "1     0     0     0       1     0      0  \n",
       "2     0     0     0       0     0      0  \n",
       "3     0     1     0       0     1      1  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents = [\"This is a test document.\",\n",
    "             \"I like trains\",\n",
    "             \"Bla Blaa Blaaa\",\n",
    "            \"I also just recognize words with more than 1 letter!!\"]\n",
    "\n",
    "# initializing the countvectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "# tokenize and make the document into a matrix\n",
    "document_term_matrix = vectorizer.fit_transform(documents)\n",
    "\n",
    "# check the result\n",
    "pd.DataFrame(document_term_matrix.toarray(), columns = vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "x4NmxDM3ViPo"
   },
   "outputs": [],
   "source": [
    "# vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(X_train) + list(X_dev))\n",
    "\n",
    "# transform documents to document-term matrix\n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "X_dev_vec = vectorizer.transform(X_dev)\n",
    "X_test_vec = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "czBT0gk2ViPo"
   },
   "source": [
    "**Support Vector Machine**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "HXqQVxrIViPo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for SVC is:  68.14317673378076 %\n"
     ]
    }
   ],
   "source": [
    "# classify using support vector classifier\n",
    "# line below produces AttributeError: 'SVC' object has no attribute 'SVC'\n",
    "#svm = svm.SVC(kernel='linear', C=1, gamma=1)\n",
    "svm = SVC(kernel = 'linear', probability=True)\n",
    "\n",
    "# fit the SVC model based on the given training data\n",
    "svm.fit(X_train_vec, y_train)\n",
    "\n",
    "# make predictions on test data\n",
    "predictions = svm.predict(X_test_vec)\n",
    "\n",
    "# accuracy score for SVC\n",
    "print(\"Accuracy score for SVC is: \", accuracy_score(predictions, y_test) * 100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P1FRUVEJViPp",
    "outputId": "7df13f76-903e-4cfd-d5d7-dec6dbcc5c32"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.64      0.74      1584\n",
      "           1       0.47      0.78      0.59       651\n",
      "\n",
      "    accuracy                           0.68      2235\n",
      "   macro avg       0.67      0.71      0.66      2235\n",
      "weighted avg       0.76      0.68      0.70      2235\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6641492422400519"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(predictions,y_test))\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "f1_score(predictions,y_test, average='macro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ay9vttnvViPp",
    "outputId": "be01b887-e829-48ba-e793-6b141ca77ecc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.78 accuracy with a standard deviation of 0.01\n"
     ]
    }
   ],
   "source": [
    "# Computing cross validation for svm by splitting training data\n",
    "# from: https://scikit-learn.org/stable/modules/cross_validation.html#\n",
    "\n",
    "X  = all_data.clean_tweet.values\n",
    "X_vec = vectorizer.transform(X)\n",
    "X_vec = X_vec.toarray()\n",
    "\n",
    "y = all_data.Insult.values\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "#X_train.shape, y_train.shape\n",
    "#X_test.shape, y_test.shape\n",
    "\n",
    "X_train_vec = vectorizer.transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_vec = X_train_vec.toarray()\n",
    "X_test_vec = X_test_vec.toarray()\n",
    "\n",
    "clf = svm.fit(X_train_vec, y_train)\n",
    "clf.score(X_test_vec, y_test)\n",
    "\n",
    "\n",
    "\n",
    "scores_accuracy = cross_val_score(clf, X_vec, y, cv=10)\n",
    "scores_accuracy\n",
    "\n",
    "\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores_accuracy.mean(), scores_accuracy.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tmqnMIa5ViPq"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.74 f1_macro with a standard deviation of 0.02\n"
     ]
    }
   ],
   "source": [
    "# computing cross-validated f1_macro\n",
    "scores_f1_macro = cross_val_score(clf, X_vec, y, cv=10, scoring='f1_macro')\n",
    "\n",
    "print(\"%0.2f f1_macro with a standard deviation of %0.2f\" % (scores_f1_macro.mean(), scores_f1_macro.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_scores_accuracy = []\n",
    "for x in range(10):\n",
    "    svm_scores_accuracy.append(scores_accuracy[x])\n",
    "svm_scores_f1_macro = []\n",
    "for x in range(10):\n",
    "    svm_scores_f1_macro.append(scores_f1_macro[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('svm.all-folds-cv.f1_macro.results.json', 'w') as fp:\n",
    "  json.dump(svm_scores_f1_macro, fp)\n",
    "with open('svm.all-folds-cv.acc.results.json', 'w') as fp:\n",
    "  json.dump(svm_scores_accuracy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "mJsoLZdOgdxz"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.764046</td>\n",
       "      <td>0.798414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.745867</td>\n",
       "      <td>0.780294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.762821</td>\n",
       "      <td>0.796149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.759424</td>\n",
       "      <td>0.796149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.751291</td>\n",
       "      <td>0.787089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.746059</td>\n",
       "      <td>0.785957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.739618</td>\n",
       "      <td>0.780294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.734086</td>\n",
       "      <td>0.782559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.713673</td>\n",
       "      <td>0.755379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>SVM</td>\n",
       "      <td>0.709525</td>\n",
       "      <td>0.753968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Model  F1_macro  Accuracy\n",
       "0     0   SVM  0.764046  0.798414\n",
       "1     1   SVM  0.745867  0.780294\n",
       "2     2   SVM  0.762821  0.796149\n",
       "3     3   SVM  0.759424  0.796149\n",
       "4     4   SVM  0.751291  0.787089\n",
       "5     5   SVM  0.746059  0.785957\n",
       "6     6   SVM  0.739618  0.780294\n",
       "7     7   SVM  0.734086  0.782559\n",
       "8     8   SVM  0.713673  0.755379\n",
       "9     9   SVM  0.709525  0.753968"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Dataframe for t-test\n",
    "folds = [0,1,2,3,4,5,6,7,8,9]\n",
    "SVM_data = pd.DataFrame(folds, columns=['Fold'])\n",
    "#NB_f1_macro = pd.DataFrame(scores_f1_macro, columns=['F1_macro'])\n",
    "SVM_data['Model']='SVM'\n",
    "SVM_data['F1_macro']=svm_scores_f1_macro\n",
    "SVM_data['Accuracy']= svm_scores_accuracy\n",
    "SVM_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x-6QOCkYViPq"
   },
   "source": [
    "**Na√Øve Bayes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V7IHbnfgViPq",
    "outputId": "e9a376dd-022a-4046-f21f-6c1cab5015b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of mislabeled points out of a total 2235 points : 1066\n"
     ]
    }
   ],
   "source": [
    "naiveBayes = BernoulliNB()\n",
    "\n",
    "# vectorize tweets for model building\n",
    "vectorizer = CountVectorizer(binary=True, stop_words='english')\n",
    "\n",
    "# learn a vocabulary dictionary of all tokens in the raw documents\n",
    "vectorizer.fit(list(X_train) + list(X_dev))\n",
    "\n",
    "#X_train_vec = X_train_vec.toarray()\n",
    "#y_train = y_train.toarray()\n",
    "#X_test_vec = X_test_vec.toarray()\n",
    "\n",
    "\n",
    "y_pred = naiveBayes.fit(X_train_vec, y_train).predict(X_test_vec)\n",
    "\n",
    "print(\"Number of mislabeled points out of a total %d points : %d\" % (X_test_vec.shape[0], (y_test != y_pred).sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dG4ERiGMViPr"
   },
   "source": [
    "k-fold cross validation for Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hWnKwodTViPr",
    "outputId": "961d967b-876c-480d-b81f-077801b4a57a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.76 accuracy with a standard deviation of 0.02\n",
      "0.70 f1_macro with a standard deviation of 0.04\n"
     ]
    }
   ],
   "source": [
    "X  = all_data.clean_tweet.values\n",
    "X_vec = vectorizer.transform(X)\n",
    "X_vec = X_vec.toarray()\n",
    "\n",
    "y = all_data.Insult.values\n",
    "\n",
    "clf = naiveBayes.fit(X_train_vec, y_train)\n",
    "clf.score(X_test_vec, y_test)\n",
    "\n",
    "scores_accuracy = cross_val_score(clf, X_vec, y, cv=10)\n",
    "#scores\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores_accuracy.mean(), scores_accuracy.std()))\n",
    "\n",
    "# computing cross-validated f1_macro\n",
    "scores_f1_macro = cross_val_score(clf, X_vec, y, cv=10, scoring='f1_macro')\n",
    "print(\"%0.2f f1_macro with a standard deviation of %0.2f\" % (scores_f1_macro.mean(), scores_f1_macro.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_scores_accuracy = []\n",
    "for x in range(10):\n",
    "    nb_scores_accuracy.append(scores_accuracy[x])\n",
    "nb_scores_f1_macro = []\n",
    "for x in range(10):\n",
    "    nb_scores_f1_macro.append(scores_f1_macro[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OFdoevwfaBdT",
    "outputId": "389976ad-840b-4cfd-bd43-1e07b2bc8cdd"
   },
   "outputs": [],
   "source": [
    "scores_f1_macro\n",
    "with open('nb.all-folds-cv.f1_macro.results.json', 'w') as fp:\n",
    "  json.dump(nb_scores_f1_macro, fp)\n",
    "with open('nb.all-folds-cv.acc.results.json', 'w') as fp:\n",
    "  json.dump(nb_scores_accuracy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "oDsMkqNlaPsz",
    "outputId": "1acb3336-ffe5-49b9-d354-7af9b99aaddd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.732420</td>\n",
       "      <td>0.776897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.738584</td>\n",
       "      <td>0.778029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.718586</td>\n",
       "      <td>0.763307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.761010</td>\n",
       "      <td>0.797282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.738191</td>\n",
       "      <td>0.788222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.712232</td>\n",
       "      <td>0.763307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.649213</td>\n",
       "      <td>0.728199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.638702</td>\n",
       "      <td>0.730464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.653027</td>\n",
       "      <td>0.728199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>NB</td>\n",
       "      <td>0.689861</td>\n",
       "      <td>0.753968</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold Model  F1_macro  Accuracy\n",
       "0     0    NB  0.732420  0.776897\n",
       "1     1    NB  0.738584  0.778029\n",
       "2     2    NB  0.718586  0.763307\n",
       "3     3    NB  0.761010  0.797282\n",
       "4     4    NB  0.738191  0.788222\n",
       "5     5    NB  0.712232  0.763307\n",
       "6     6    NB  0.649213  0.728199\n",
       "7     7    NB  0.638702  0.730464\n",
       "8     8    NB  0.653027  0.728199\n",
       "9     9    NB  0.689861  0.753968"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Dataframe for t-test\n",
    "folds = [0,1,2,3,4,5,6,7,8,9]\n",
    "NB_data = pd.DataFrame(folds, columns=['Fold'])\n",
    "#NB_f1_macro = pd.DataFrame(scores_f1_macro, columns=['F1_macro'])\n",
    "NB_data['Model']='NB'\n",
    "NB_data['F1_macro']=nb_scores_f1_macro\n",
    "NB_data['Accuracy']= nb_scores_accuracy\n",
    "NB_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lBebmGIgViPs"
   },
   "source": [
    "**Logistic Regression**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8kVyztqaViPs",
    "outputId": "0fbccb33-0fe5-468f-fcdc-9e248e4b0d5f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.63      0.75      1706\n",
      "           1       0.41      0.83      0.55       529\n",
      "\n",
      "    accuracy                           0.68      2235\n",
      "   macro avg       0.67      0.73      0.65      2235\n",
      "weighted avg       0.80      0.68      0.70      2235\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.6472267926838602"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticRegr = LogisticRegression()\n",
    "\n",
    "logisticRegr.fit(X_train_vec, y_train)\n",
    "\n",
    "\n",
    "predictions = logisticRegr.predict(X_test_vec)\n",
    "\n",
    "\n",
    "# Measuring Model Performance\n",
    "print(classification_report(predictions,y_test))\n",
    "\n",
    "\n",
    "f1_score(predictions,y_test, average='macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ENfMHotyViPt"
   },
   "source": [
    "k-fold cross validation for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qsWhJdkcViPt",
    "outputId": "3087876a-9067-4e08-b502-b9030a3d125b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.80 accuracy with a standard deviation of 0.02\n",
      "0.75 f1_macro with a standard deviation of 0.03\n"
     ]
    }
   ],
   "source": [
    "X  = all_data.clean_tweet.values\n",
    "X_vec = vectorizer.transform(X)\n",
    "X_vec = X_vec.toarray()\n",
    "\n",
    "y = all_data.Insult.values\n",
    "\n",
    "clf = logisticRegr.fit(X_train_vec, y_train)\n",
    "clf.score(X_test_vec, y_test)\n",
    "\n",
    "scores_accuracy = cross_val_score(clf, X_vec, y, cv=10)\n",
    "#scores\n",
    "\n",
    "print(\"%0.2f accuracy with a standard deviation of %0.2f\" % (scores_accuracy.mean(), scores_accuracy.std()))\n",
    "\n",
    "# computing cross-validated f1_macro\n",
    "scores_f1_macro = cross_val_score(clf, X_vec, y, cv=10, scoring='f1_macro')\n",
    "print(\"%0.2f f1_macro with a standard deviation of %0.2f\" % (scores_f1_macro.mean(), scores_f1_macro.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_scores_accuracy = []\n",
    "for x in range(10):\n",
    "    lr_scores_accuracy.append(scores_accuracy[x])\n",
    "lr_scores_f1_macro = []\n",
    "for x in range(10):\n",
    "    lr_scores_f1_macro.append(scores_f1_macro[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lr.all-folds-cv.f1_macro.results.json', 'w') as fp:\n",
    "  json.dump(lr_scores_f1_macro, fp)\n",
    "with open('lr.all-folds-cv.acc.results.json', 'w') as fp:\n",
    "  json.dump(lr_scores_accuracy, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "id": "D4ZEtzExdUn8",
    "outputId": "c72aa922-0876-4270-8b59-d6a744b90188"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fold</th>\n",
       "      <th>Model</th>\n",
       "      <th>F1_macro</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.771229</td>\n",
       "      <td>0.814270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.766739</td>\n",
       "      <td>0.807475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.789175</td>\n",
       "      <td>0.825595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.776299</td>\n",
       "      <td>0.821065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.762890</td>\n",
       "      <td>0.806342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.770112</td>\n",
       "      <td>0.813137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.740467</td>\n",
       "      <td>0.796149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.743066</td>\n",
       "      <td>0.799547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.708808</td>\n",
       "      <td>0.763307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.706425</td>\n",
       "      <td>0.765306</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Fold               Model  F1_macro  Accuracy\n",
       "0     0  LogisticRegression  0.771229  0.814270\n",
       "1     1  LogisticRegression  0.766739  0.807475\n",
       "2     2  LogisticRegression  0.789175  0.825595\n",
       "3     3  LogisticRegression  0.776299  0.821065\n",
       "4     4  LogisticRegression  0.762890  0.806342\n",
       "5     5  LogisticRegression  0.770112  0.813137\n",
       "6     6  LogisticRegression  0.740467  0.796149\n",
       "7     7  LogisticRegression  0.743066  0.799547\n",
       "8     8  LogisticRegression  0.708808  0.763307\n",
       "9     9  LogisticRegression  0.706425  0.765306"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create Dataframe for t-test\n",
    "folds = [0,1,2,3,4,5,6,7,8,9]\n",
    "LogisticRegression_data = pd.DataFrame(folds, columns=['Fold'])\n",
    "#NB_f1_macro = pd.DataFrame(scores_f1_macro, columns=['F1_macro'])\n",
    "LogisticRegression_data['Model']='LogisticRegression'\n",
    "LogisticRegression_data['F1_macro']=lr_scores_f1_macro\n",
    "LogisticRegression_data['Accuracy']= lr_scores_accuracy\n",
    "LogisticRegression_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2y5TFRT6ViPu"
   },
   "source": [
    "Comparing Logistic Regression & Bernoulli Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ioDHI29Reh9W",
    "outputId": "b29ea24d-414d-4d0d-9ea0-896cd52329e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-3.08912642352205, pvalue=0.006328010687660841)\n",
      "Difference between mean performance is probably real\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_ind(NB_data['F1_macro'], LogisticRegression_data['F1_macro']))\n",
    "p = stats.ttest_ind(NB_data['F1_macro'], LogisticRegression_data['F1_macro']).pvalue\n",
    "if p <= 0.05:\n",
    "\tprint('Difference between mean performance is probably real')\n",
    "else:\n",
    "\tprint('Algorithms probably have the same performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ttest_indResult(statistic=-3.8617845165089433, pvalue=0.0011427048986234005)\n",
      "Difference between mean performance is probably real\n"
     ]
    }
   ],
   "source": [
    "print(stats.ttest_ind(NB_data['Accuracy'], LogisticRegression_data['Accuracy']))\n",
    "p = stats.ttest_ind(NB_data['Accuracy'], LogisticRegression_data['Accuracy']).pvalue\n",
    "if p <= 0.05:\n",
    "\tprint('Difference between mean performance is probably real')\n",
    "else:\n",
    "\tprint('Algorithms probably have the same performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCDIJErIViPu"
   },
   "source": [
    "Comparing Logistic Regression & SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.ttest_ind(SVM_data['Accuracy'], LogisticRegression_data['Accuracy']))\n",
    "p = stats.ttest_ind(SVM_data['Accuracy'], LogisticRegression_data['Accuracy']).pvalue\n",
    "if p <= 0.05:\n",
    "\tprint('Difference between mean performance is probably real')\n",
    "else:\n",
    "\tprint('Algorithms probably have the same performance')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.ttest_ind(SVM_data['F1_macro'], LogisticRegression_data['F1_macro']))\n",
    "p = stats.ttest_ind(SVM_data['F1_macro'], LogisticRegression_data['F1_macro']).pvalue\n",
    "if p <= 0.05:\n",
    "\tprint('Difference between mean performance is probably real')\n",
    "else:\n",
    "\tprint('Algorithms probably have the same performance')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concatenating Dataframes for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [SVM_data, NB_data, LogisticRegression_data]\n",
    "\n",
    "result = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#baseline_no_resampling = baseline_data[baseline_data['resampled']==False]\n",
    "nb = result[result['Model'] == 'NB']\n",
    "lr = result[result['Model'] == 'LogisticRegression']\n",
    "svm1 = result[result['Model'] == 'SVM']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "model_plot = sns.catplot(x=\"Model\", y = \"Accuracy\", \n",
    "                         hue=\"Model\", \n",
    "                         kind=\"bar\", \n",
    "                         data=result,\n",
    "                         height=7,\n",
    "                         capsize=.1)\n",
    "model_plot.set_axis_labels(\"Model\", \"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style='darkgrid')\n",
    "model_plot = sns.catplot(x=\"Model\", y = \"F1_macro\", \n",
    "                         hue=\"Model\", \n",
    "                         kind=\"bar\", \n",
    "                         data=result,\n",
    "                         height=7,\n",
    "                         capsize=.1)\n",
    "model_plot.set_axis_labels(\"Model\", \"F1_macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "InfoLing2_Projekt_scikit-learn.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
